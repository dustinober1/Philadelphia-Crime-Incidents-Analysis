# Crime Incidents — Philadelphia

A reproducible analysis project and interactive dashboard for Philadelphia crime incidents. This repository contains data ingestion and cleaning utilities, exploratory notebooks, domain-specific analyses (temporal, spatial, categorical, correlation), automated report generation, and a small Dash/Flask-based dashboard for interactive exploration and presentation.

## Highlights
- Reproducible data processing and cleaning pipelines.
- Analyses for temporal patterns, spatial hotspots, crime-type profiling, and correlation reports.
- Automated report generation into Markdown and HTML under `reports/`.
- Interactive dashboard in `dashboard/` for exploration and presentation.

## Requirements
- Python 3.9+ recommended
- A virtual environment (venv, conda) for dependency isolation

If a `requirements.txt` file is present, install with:

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

If there is no `requirements.txt`, install commonly used packages (example):

```bash
pip install pandas numpy geopandas matplotlib plotly flask dash jupyter
```

## Quickstart

1. Prepare the environment and dependencies (see Requirements).
2. Place any raw data files in `data/raw/` and external reference files in `data/external/`.
3. Run the main report generation script (this orchestrates analyses and writes to `reports/`):

```bash
python analysis/06_generate_report.py
```

4. Run the interactive dashboard (development):

```bash
python dashboard/app.py
```

Or run via Flask (if configured):

```bash
FLASK_APP=dashboard.app flask run
```

## Repository Layout

- `analysis/` — analysis scripts, reporting orchestration, and shared utilities (e.g., `utils.py`, `config.py`).
  - Notable scripts: `06_generate_report.py`, `temporal_analysis.py`, `spatial_analysis.py`, `data_quality.py`.
- `dashboard/` — interactive app and UI components.
  - `dashboard/app.py` is the app entrypoint.
  - `dashboard/components/` contains UI helpers and `dashboard/filters/` contains filtering logic.
- `data/` — data storage (split into `raw/`, `processed/`, and `external/`).
- `notebooks/` — exploratory analysis and data-quality notebooks.
- `reports/` — autogenerated reports and visual exports (Markdown/HTML maps and summaries).

## Notebook Standards

This project follows a strict notebook standard to ensure reproducibility and reviewability. A full set of rules is maintained in `AGENTS.md` under the "Notebook Rules" section — please review that file for complete requirements. Key expectations summarized here:

- Notebooks live in `notebooks/` and publication-ready exports go to `reports/`.
- The `crime` conda environment (see `environment.yml`) must be used; prefer `conda install` over `pip` when adding packages.
- Every notebook must include a reproducibility cell (first code cell) that records Python version, environment name, and key package versions.
- Run notebooks start-to-finish with no errors before committing. Commit notebooks with outputs cleared; save and commit exported figures (PNG/HTML/PDF) separately to `reports/`.
- Keep heavy processing in `analysis/` helper modules; notebooks should orchestrate analysis and visualization.
- Notebooks must be runnable headless for CI (e.g., `jupyter nbconvert --execute`) and should include a fast/sampled dev path for long-running steps.

See `AGENTS.md` for the full checklist and additional guidance (data validation, visualization standards, privacy/PII rules, and completion checklist).

## Data & Privacy
- Keep raw datasets with personally-identifiable information (PII) out of version control. Put raw inputs under `data/raw/` locally and add appropriate `.gitignore` rules.
- Document data provenance and licenses in `data/external/` or in `analysis/external_data.py` when applicable.

## Common Workflows
- Regenerate all reports:

```bash
python analysis/06_generate_report.py
```

## Running Phase 1 Analyses

Phase 1 answers three key questions about Philadelphia crime:
1. **Is Philadelphia getting safer?** (Annual trends analysis - CHIEF-01)
2. **Is there a summer crime spike?** (Seasonality analysis - CHIEF-02)
3. **How did COVID change the crime landscape?** (Pre/during/post comparison - CHIEF-03)

### Quick Start

```bash
# Full run (takes ~3-5 minutes)
./run_phase1.sh

# Fast mode for testing (takes ~30 seconds, 10% sample)
./run_phase1.sh v1.0 --fast

# Run with validation
./run_phase1.sh v1.0 --fast --validate
```

### Manual Execution

```bash
# Run all notebooks
python analysis/orchestrate_phase1.py --version v1.0

# Run with fast sampling
python analysis/orchestrate_phase1.py --version v1.0 --fast

# Run single notebook
python analysis/orchestrate_phase1.py --notebook annual_trend

# Continue on errors
python analysis/orchestrate_phase1.py --continue-on-error

# Use custom config
python analysis/orchestrate_phase1.py --config-path config/custom.yaml
```

### Output Artifacts

All outputs are saved to `reports/` with versioned filenames:

| Artifact | Description |
|----------|-------------|
| `annual_trend_v*.png` | 10-year crime trend visualization |
| `annual_trend_comprehensive_v*.png` | Detailed trend with statistics |
| `violent_vs_property_v*.png` | Crime category comparison |
| `seasonality_boxplot_v*.png` | Monthly crime distribution boxplot |
| `monthly_trend_v*.png` | Monthly averages with confidence intervals |
| `covid_timeline_v*.png` | COVID period comparison timeline |
| `burglary_displacement_v*.png` | Residential vs commercial burglary shift |
| `*_report_v*.md` | Academic-style analysis reports |
| `*_manifest_v*.json` | Artifact metadata with hashes |
| `execution.log` | Orchestration run log |

### Validate Artifacts

```bash
python analysis/validate_artifacts.py
```

### Configuration

Phase 1 parameters are stored in `config/phase1_config.yaml`:

```yaml
version: "v1.0"
notebooks:
  annual_trend:
    start_year: 2015
    end_year: 2024
  seasonality:
    summer_months: [6, 7, 8]
    winter_months: [1, 2, 3]
  covid:
    lockdown_date: "2020-03-01"
    before_years: [2018, 2019]
    during_years: [2020, 2021]
```

### Troubleshooting

**Config not found:** Run `ls config/phase1_config.yaml` to verify
**Papermill errors:** Check `reports/execution.log` for details
**Missing data:** Ensure `data/crime_incidents_combined.parquet` exists

- Run a single analysis (example: summer spike):

```bash
python analysis/summer_spike.py
```

- Inspect data quality interactively:

```bash
jupyter notebook notebooks/data_quality_audit_notebook.ipynb
```

## Development & Testing
- Use `black` for formatting and `flake8` or `ruff` for linting.
- Add unit tests for reusable helpers where appropriate. There is no test harness included by default—add `pytest` and a `tests/` folder if you want CI.

## Contribution Guidelines
- Fork, create a feature branch, add tests and documentation for any non-trivial change, then open a pull request.
- Keep commits small and focused; document data assumptions and required external datasets.

## Troubleshooting
- Missing dependencies: ensure your virtual environment is active and `pip install -r requirements.txt` completed successfully.
- Scripts fail due to missing data files: verify expected files are in `data/raw/` and any required external keys/env vars referenced in `dashboard/config.py` are set.

## License & Contact
- Add a `LICENSE` file at the project root to state your preferred license.
- For questions or collaboration, open an issue or contact the repository owner.

---

This `README.md` gives an overview and practical steps to run and extend the analyses and dashboard included in this repository. If you want, I can:

- add a `requirements.txt` by scanning imports,
- add a short `CONTRIBUTING.md` with PR checklist,
- or wire up a minimal `Makefile` or `pyproject.toml` for reproducible runs.
