# Crime Incidents — Philadelphia

A reproducible analysis project and interactive dashboard for Philadelphia crime incidents. This repository contains data ingestion and cleaning utilities, exploratory notebooks, domain-specific analyses (temporal, spatial, categorical, correlation), automated report generation, and a small Dash/Flask-based dashboard for interactive exploration and presentation.

## Highlights
- Reproducible data processing and cleaning pipelines.
- Analyses for temporal patterns, spatial hotspots, crime-type profiling, and correlation reports.
- Automated report generation into Markdown and HTML under `reports/`.
- Interactive dashboard in `dashboard/` for exploration and presentation.

## Requirements
- Python 3.9+ recommended
- A virtual environment (venv, conda) for dependency isolation

If a `requirements.txt` file is present, install with:

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

If there is no `requirements.txt`, install commonly used packages (example):

```bash
pip install pandas numpy geopandas matplotlib plotly flask dash jupyter
```

## Quickstart

1. Prepare the environment and dependencies (see Requirements).
2. Place any raw data files in `data/raw/` and external reference files in `data/external/`.
3. Run the main report generation script (this orchestrates analyses and writes to `reports/`):

```bash
python analysis/06_generate_report.py
```

4. Run the interactive dashboard (development):

```bash
python dashboard/app.py
```

Or run via Flask (if configured):

```bash
FLASK_APP=dashboard.app flask run
```

## Repository Layout

- `analysis/` — analysis scripts, reporting orchestration, and shared utilities (e.g., `utils.py`, `config.py`).
  - Notable scripts: `06_generate_report.py`, `temporal_analysis.py`, `spatial_analysis.py`, `data_quality.py`.
- `dashboard/` — interactive app and UI components.
  - `dashboard/app.py` is the app entrypoint.
  - `dashboard/components/` contains UI helpers and `dashboard/filters/` contains filtering logic.
- `data/` — data storage (split into `raw/`, `processed/`, and `external/`).
- `notebooks/` — exploratory analysis and data-quality notebooks.
- `reports/` — autogenerated reports and visual exports (Markdown/HTML maps and summaries).

## Notebook Standards

This project follows a strict notebook standard to ensure reproducibility and reviewability. A full set of rules is maintained in `AGENTS.md` under the "Notebook Rules" section — please review that file for complete requirements. Key expectations summarized here:

- Notebooks live in `notebooks/` and publication-ready exports go to `reports/`.
- The `crime` conda environment (see `environment.yml`) must be used; prefer `conda install` over `pip` when adding packages.
- Every notebook must include a reproducibility cell (first code cell) that records Python version, environment name, and key package versions.
- Run notebooks start-to-finish with no errors before committing. Commit notebooks with outputs cleared; save and commit exported figures (PNG/HTML/PDF) separately to `reports/`.
- Keep heavy processing in `analysis/` helper modules; notebooks should orchestrate analysis and visualization.
- Notebooks must be runnable headless for CI (e.g., `jupyter nbconvert --execute`) and should include a fast/sampled dev path for long-running steps.

See `AGENTS.md` for the full checklist and additional guidance (data validation, visualization standards, privacy/PII rules, and completion checklist).

## Data & Privacy
- Keep raw datasets with personally-identifiable information (PII) out of version control. Put raw inputs under `data/raw/` locally and add appropriate `.gitignore` rules.
- Document data provenance and licenses in `data/external/` or in `analysis/external_data.py` when applicable.

## Common Workflows
- Regenerate all reports:

```bash
python analysis/06_generate_report.py
```

## Running Phase 1 Analyses

### Quick Start
python analysis/orchestrate_phase1.py --version v1.0

### Options
- `--fast`: Run with 10% sample for quick testing
- `--notebook annual_trend`: Run single notebook
- `--config-path custom.yaml`: Use custom configuration

### Outputs
All artifacts are saved to `reports/` with versioned filenames.

- Run a single analysis (example: summer spike):

```bash
python analysis/summer_spike.py
```

- Inspect data quality interactively:

```bash
jupyter notebook notebooks/data_quality_audit_notebook.ipynb
```

## Development & Testing
- Use `black` for formatting and `flake8` or `ruff` for linting.
- Add unit tests for reusable helpers where appropriate. There is no test harness included by default—add `pytest` and a `tests/` folder if you want CI.

## Contribution Guidelines
- Fork, create a feature branch, add tests and documentation for any non-trivial change, then open a pull request.
- Keep commits small and focused; document data assumptions and required external datasets.

## Troubleshooting
- Missing dependencies: ensure your virtual environment is active and `pip install -r requirements.txt` completed successfully.
- Scripts fail due to missing data files: verify expected files are in `data/raw/` and any required external keys/env vars referenced in `dashboard/config.py` are set.

## License & Contact
- Add a `LICENSE` file at the project root to state your preferred license.
- For questions or collaboration, open an issue or contact the repository owner.

---

This `README.md` gives an overview and practical steps to run and extend the analyses and dashboard included in this repository. If you want, I can:

- add a `requirements.txt` by scanning imports,
- add a short `CONTRIBUTING.md` with PR checklist,
- or wire up a minimal `Makefile` or `pyproject.toml` for reproducible runs.
