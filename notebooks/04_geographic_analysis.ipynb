{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 04: Geographic Analysis\n",
    "\n",
    "**Purpose:** Comprehensive geographic analysis of Philadelphia crime data including hotspot identification, district profiles, KDE heatmaps, and spatial autocorrelation testing.\n",
    "\n",
    "**Requirements Addressed:**\n",
    "- GEO-01: Hotspot identification\n",
    "- GEO-02: District-level analysis\n",
    "- GEO-03: Crime rate calculations\n",
    "- GEO-04: Spatial autocorrelation\n",
    "- GEO-05: Geographic visualization\n",
    "- GEO-06: Stability testing\n",
    "- GEO-07: MAUP documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import gaussian_kde\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Spatial statistics\n",
    "try:\n",
    "    from esda import Moran\n",
    "    from libpysal.weights import Queen\n",
    "    SPATIAL_STATS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SPATIAL_STATS_AVAILABLE = False\n",
    "    print(\"Warning: PySAL not available. Spatial autocorrelation analysis will be skipped.\")\n",
    "\n",
    "# Configuration\n",
    "from config import (\n",
    "    PROCESSED_DATA_DIR, FIGURES_DIR, TABLES_DIR,\n",
    "    CRS_LATLON, CRS_PHILLY,\n",
    "    COL_ID, COL_DATE, COL_DISTRICT, COL_UCR_GENERAL,\n",
    "    COL_TEXT_GENERAL, COL_LAT, COL_LON\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure matplotlib for publication quality\n",
    "plt.rcParams.update({\n",
    "    'figure.dpi': 300,\n",
    "    'savefig.dpi': 300,\n",
    "    'font.size': 10,\n",
    "    'axes.labelsize': 11,\n",
    "    'axes.titlesize': 12,\n",
    "    'xtick.labelsize': 9,\n",
    "    'ytick.labelsize': 9,\n",
    "    'legend.fontsize': 9,\n",
    "})\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data\n",
    "df = pd.read_parquet(PROCESSED_DATA_DIR / 'crime_incidents_cleaned.parquet')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nDate range: {df[COL_DATE].min()} to {df[COL_DATE].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Geographic Data Coverage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze coordinate coverage\n",
    "coord_coverage = df[COL_LAT].notna().sum() / len(df) * 100\n",
    "print(f\"Overall geocoding coverage: {coord_coverage:.2f}%\")\n",
    "\n",
    "# Coverage by crime type\n",
    "coverage_by_type = df.groupby(COL_TEXT_GENERAL).apply(\n",
    "    lambda x: x[COL_LAT].notna().sum() / len(x) * 100\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nGeocoding coverage by crime type (top 10):\")\n",
    "print(coverage_by_type.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to records with valid coordinates for geographic analysis\n",
    "df_geo = df[df[COL_LAT].notna() & df[COL_LON].notna()].copy()\n",
    "\n",
    "print(f\"Records with valid coordinates: {len(df_geo):,} ({len(df_geo)/len(df)*100:.1f}%)\")\n",
    "print(f\"\\nCoordinate bounds:\")\n",
    "print(f\"  Latitude: {df_geo[COL_LAT].min():.4f} to {df_geo[COL_LAT].max():.4f}\")\n",
    "print(f\"  Longitude: {df_geo[COL_LON].min():.4f} to {df_geo[COL_LON].max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create GeoDataFrame with Proper Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create geometry from lat/lon\n",
    "geometry = [Point(xy) for xy in zip(df_geo[COL_LON], df_geo[COL_LAT])]\n",
    "\n",
    "# Create GeoDataFrame in WGS84 (EPSG:4326)\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df_geo,\n",
    "    geometry=geometry,\n",
    "    crs=CRS_LATLON\n",
    ")\n",
    "\n",
    "print(f\"GeoDataFrame created with {len(gdf):,} records\")\n",
    "print(f\"CRS: {gdf.crs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project to PA South State Plane (EPSG:2272) for accurate distance calculations\n",
    "# This is critical for KDE - distances in degrees (lat/lon) are not accurate\n",
    "gdf_projected = gdf.to_crs(CRS_PHILLY)\n",
    "\n",
    "print(f\"Projected to {CRS_PHILLY}\")\n",
    "print(f\"New CRS: {gdf_projected.crs}\")\n",
    "\n",
    "# Extract projected coordinates for KDE\n",
    "gdf_projected['x_proj'] = gdf_projected.geometry.x\n",
    "gdf_projected['y_proj'] = gdf_projected.geometry.y\n",
    "\n",
    "print(f\"\\nProjected coordinate bounds:\")\n",
    "print(f\"  X: {gdf_projected['x_proj'].min():.0f} to {gdf_projected['x_proj'].max():.0f} ft\")\n",
    "print(f\"  Y: {gdf_projected['y_proj'].min():.0f} to {gdf_projected['y_proj'].max():.0f} ft\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. District-Level Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate district-level statistics\n",
    "district_stats = df.groupby(COL_DISTRICT).agg({\n",
    "    COL_ID: 'count',\n",
    "    COL_LAT: 'mean',\n",
    "    COL_LON: 'mean'\n",
    "}).rename(columns={COL_ID: 'crime_count', COL_LAT: 'avg_lat', COL_LON: 'avg_lng'})\n",
    "\n",
    "district_stats = district_stats.reset_index()\n",
    "district_stats = district_stats.sort_values('crime_count', ascending=False)\n",
    "\n",
    "print(f\"Number of districts: {len(district_stats)}\")\n",
    "print(\"\\nTop 10 districts by crime count:\")\n",
    "print(district_stats.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate top offense types per district\n",
    "district_offenses = df.groupby([COL_DISTRICT, COL_TEXT_GENERAL]).size().reset_index(name='count')\n",
    "district_top_offenses = district_offenses.sort_values(['dc_dist', 'count'], ascending=[True, False])\n",
    "district_top_offenses = district_top_offenses.groupby(COL_DISTRICT).head(3)\n",
    "\n",
    "print(\"Top 3 offense types per district (sample):\")\n",
    "print(district_top_offenses.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Note on District Boundaries\n",
    "\n",
    "**Important:** For complete district-level spatial analysis with choropleth maps and Moran's I, we need Philadelphia Police District boundary shapefiles.\n",
    "\n",
    "**Options for obtaining boundaries:**\n",
    "1. OpenDataPhilly (opendataphilly.org) - Philadelphia Police Districts\n",
    "2. City of Philadelphia GIS Portal\n",
    "3. Manual download and placement in `data/processed/philly_police_districts.shp`\n",
    "\n",
    "**Without boundaries, we can still perform:**\n",
    "- Point-based KDE hotspot analysis\n",
    "- District-level statistical summaries\n",
    "- Coordinate-based visualizations\n",
    "\n",
    "**Note on MAUP:** District boundaries are arbitrary administrative divisions. Crime patterns may differ at neighborhood or census tract levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to load district boundaries if available\n",
    "district_boundaries_path = PROCESSED_DATA_DIR / 'philly_police_districts.shp'\n",
    "\n",
    "if district_boundaries_path.exists():\n",
    "    districts_gdf = gpd.read_file(district_boundaries_path)\n",
    "    print(f\"Loaded district boundaries: {len(districts_gdf)} districts\")\n",
    "    print(f\"Columns: {list(districts_gdf.columns)}\")\n",
    "    BOUNDARIES_AVAILABLE = True\n",
    "else:\n",
    "    print(\"District boundaries not found.\")\n",
    "    print(f\"Expected at: {district_boundaries_path}\")\n",
    "    print(\"\\nTo obtain boundaries:\")\n",
    "    print(\"  1. Visit https://opendataphilly.org\")\n",
    "    print(\"  2. Search for 'Police Districts'\")\n",
    "    print(\"  3. Download shapefile\")\n",
    "    print(f\"  4. Save to: {district_boundaries_path}\")\n",
    "    BOUNDARIES_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save District Profiles\n",
    "\n",
    "Save comprehensive district statistics for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive district profiles\n",
    "district_profiles = district_stats.copy()\n",
    "\n",
    "# Add crime rate (per year)\n",
    "date_range_years = (df[COL_DATE].max() - df[COL_DATE].min()).days / 365.25\n",
    "district_profiles['crimes_per_year'] = district_profiles['crime_count'] / date_range_years\n",
    "\n",
    "# Add percentage of total crimes\n",
    "total_crimes = district_profiles['crime_count'].sum()\n",
    "district_profiles['pct_of_total'] = district_profiles['crime_count'] / total_crimes * 100\n",
    "\n",
    "# Add rank\n",
    "district_profiles['rank'] = district_profiles['crime_count'].rank(ascending=False, method='min').astype(int)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = TABLES_DIR / 'geographic' / 'district_profiles.csv'\n",
    "district_profiles.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved district profiles to: {output_path}\")\n",
    "print(f\"\\nDistrict profiles summary:\")\n",
    "print(district_profiles.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Task 1 Complete:** Geographic data prepared with proper projections, district statistics calculated, and data coverage documented.\n",
    "\n",
    "**Key Findings:**\n",
    "- Geocoding coverage is high overall\n",
    "- Data projected to EPSG:2272 for accurate distance calculations\n",
    "- District-level statistics calculated\n",
    "- District boundaries need to be obtained for full choropleth analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
