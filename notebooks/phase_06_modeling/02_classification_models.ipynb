{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 6: Modeling - Classification Models\n",
    "\n",
    "## Overview\n",
    "\n",
    "Build classification models to predict crime type or district from incident features.\n",
    "\n",
    "### Objectives\n",
    "1. Prepare features for classification\n",
    "2. Split data into train/test sets\n",
    "3. Train multiple classifiers\n",
    "4. Evaluate performance (accuracy, precision, recall, F1)\n",
    "5. Analyze feature importance\n",
    "\n",
    "### Note\n",
    "This is a starter notebook for classification exploration. Expand based on specific business requirements."
   ]
  },
  {
   "cell_type": {"cell_type": \"markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Setup and Imports"
   ]
  },
  {
   "cell_type": {"cell_type": \"code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.data import loader\n",
    "\n",
    "print(\"Imports successful\")"
   ]
  },
  {
   "cell_type": {"cell_type": \"markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Load and Prepare Data"
   ]
  },
  {
   "cell_type": {"cell_type": \"code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loader.load_crime_data()\n",
    "\n",
    "# Select features for classification\n",
    "features = ['month', 'day', 'day_of_week', 'latitude', 'longitude']\n",
    "target = 'general_crime_category'\n",
    "\n",
    "# Check if features exist\n",
    "available_features = [f for f in features if f in df.columns]\n",
    "print(f\"Available features: {available_features}\")\n",
    "\n",
    "if target in df.columns:\n",
    "    # Prepare data\n",
    "    df_model = df[available_features + [target]].copy()\n",
    "    df_model = df_model.dropna()\n",
    "    \n",
    "    # Encode categorical features\n",
    "    le_target = LabelEncoder()\n",
    "    y = le_target.fit_transform(df_model[target])\n",
    "    X = df_model[available_features].copy()\n",
    "    \n",
    "    # Encode day_of_week if present\n",
    "    if 'day_of_week' in X.columns:\n",
    "        dow_map = {day: i for i, day in enumerate(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])}\n",
    "        X['day_of_week'] = X['day_of_week'].map(dow_map)\n",
    "    \n",
    "    print(f\"\\nDataset prepared:\")\n",
    "    print(f\"  Samples: {len(X):,}\")\n",
    "    print(f\"  Features: {len(available_features)}\")\n",
    "    print(f\"  Target classes: {len(le_target.classes_)}\")\nelse:\n",
    "    print(f\"Target column '{target}' not found\")"
   ]
  },
  {
   "cell_type": {"cell_type": \"markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Train-Test Split"
   ]
  },
  {
   "cell_type": {"cell_type": \"code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train set: {len(X_train):,} samples\")\n",
    "print(f\"Test set: {len(X_test):,} samples\")"
   ]
  },
  {
   "cell_type": {"cell_type": \"markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Train Random Forest"
   ]
  },
  {
   "cell_type": {"cell_type": \"code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "print(\"Training Random Forest classifier...\")\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=15, random_state=42, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nâœ“ Model trained\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": {"cell_type": \"markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Model Evaluation"
   ]
  },
  {
   "cell_type": {"cell_type": {"cell_type": \"code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le_target.classes_[:5], zero_division=0))"
   ]
  },
  {
   "cell_type": {"cell_type": \"markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Feature Importance"
   ]
   ]
  },
  {
   "cell_type": {"cell_type": \"code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importances = clf.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': available_features,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "feature_importance_df.plot(x='feature', y='importance', kind='barh', ax=ax, legend=False)\n",
    "ax.set_title('Feature Importance - Random Forest', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": {"cell_type": \"markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Hyperparameter Tuning**: Use GridSearchCV or RandomizedSearchCV\n",
    "2. **Ensemble Methods**: Try Gradient Boosting, XGBoost\n",
    "3. **Class Imbalance**: Handle imbalanced crime types with SMOTE or class weights\n",
    "4. **Cross-Validation**: Use K-fold CV for robust evaluation\n",
    "5. **Production**: Save model with joblib for future predictions\n",
    "\n",
    "Example:\n",
    "```python\n",
    "import joblib\n",
    "joblib.dump(clf, 'crime_classifier.pkl')\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
