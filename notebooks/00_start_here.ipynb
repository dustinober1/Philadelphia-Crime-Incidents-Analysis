{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crime Incidents Philadelphia - Analysis Notebook Suite\n",
    "\n",
    "Welcome to the Crime Incidents Philadelphia analysis platform. This notebook suite provides an interactive, step-by-step analysis of crime trends, patterns, and hotspots across Philadelphia from 2006 to present.\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "**Data Source**: [OpenDataPhilly](https://opendataphilly.org/) - Carto API for Philadelphia Police Department crime incidents\n",
    "\n",
    "**Time Range**: 2006 to present (continuously updated)\n",
    "\n",
    "**Goal**: Identify temporal and spatial patterns of crime to support data-driven public safety analysis.\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "This analysis is organized into 6 phases, each with dedicated notebooks:\n",
    "\n",
    "### Phase 1: Data Ingestion\n",
    "- **Purpose**: Download and consolidate monthly crime data from OpenDataPhilly API\n",
    "- **Notebook**: `phase_01_data_ingestion/01_scrape_and_consolidate.ipynb`\n",
    "- **Output**: Consolidated Parquet file with optimized data types\n",
    "\n",
    "### Phase 2: Exploration\n",
    "- **Purpose**: Understand data structure, identify quality issues, and profile distributions\n",
    "- **Notebooks**:\n",
    "  - `phase_02_exploration/01_data_overview.ipynb` — Basic data shape, types, and distributions\n",
    "  - `phase_02_exploration/02_data_quality_assessment.ipynb` — Duplicates, missing values, outliers\n",
    "\n",
    "### Phase 3: Processing\n",
    "- **Purpose**: Clean data and create analytical features\n",
    "- **Notebooks**:\n",
    "  - `phase_03_processing/01_data_cleaning.ipynb` — Handle missing values, remove duplicates, standardize formats\n",
    "  - `phase_03_processing/02_feature_engineering.ipynb` — Temporal, spatial, and aggregate features\n",
    "\n",
    "### Phase 4: Analysis\n",
    "- **Purpose**: Discover temporal trends, categorical patterns, and statistical relationships\n",
    "- **Notebooks**:\n",
    "  - `phase_04_analysis/01_temporal_analysis.ipynb` — Time-series trends, seasonality\n",
    "  - `phase_04_analysis/02_categorical_analysis.ipynb` — Crime types, districts, cross-tabulations\n",
    "  - `phase_04_analysis/03_statistical_summaries.ipynb` — Correlations, distributions, summary reports\n",
    "\n",
    "### Phase 5: Visualization\n",
    "- **Purpose**: Create interactive maps, dashboards, and visual reports\n",
    "- **Notebooks**:\n",
    "  - `phase_05_visualization/01_crime_maps_and_hotspots.ipynb` — Folium maps, KDE hotspot detection\n",
    "  - `phase_05_visualization/02_trend_analysis_dashboards.ipynb` — Plotly dashboards, heatmaps\n",
    "\n",
    "### Phase 6: Modeling (Future)\n",
    "- **Purpose**: Build predictive and classification models\n",
    "- **Notebooks**:\n",
    "  - `phase_06_modeling/01_forecasting_exploration.ipynb` — Time-series forecasting\n",
    "  - `phase_06_modeling/02_classification_models.ipynb` — Crime type/district prediction\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "### First Time Setup\n",
    "\n",
    "1. **Install dependencies** (if not already done):\n",
    "   ```bash\n",
    "   pip install -r requirements.txt\n",
    "   ```\n",
    "\n",
    "2. **Run Phase 1** to download and consolidate data:\n",
    "   - Open: `notebooks/phase_01_data_ingestion/01_scrape_and_consolidate.ipynb`\n",
    "   - Follow the cells to scrape monthly data and create the consolidated Parquet file\n",
    "\n",
    "3. **Proceed sequentially** through phases 2-5 for analysis and visualization.\n",
    "\n",
    "### Regular Analysis Sessions\n",
    "\n",
    "- **To update data**: Run Phase 1 notebook (or execute the refresh steps)\n",
    "- **To skip to analysis**: Assume data is current and jump directly to Phase 2\n",
    "- **To focus on visuals**: Jump to Phase 5 if data and processing are complete\n",
    "\n",
    "## Data Refresh Strategy\n",
    "\n",
    "Choose one approach:\n",
    "\n",
    "**Option A (Recommended)**: Run Phase 1 notebook at the start of each analysis session\n",
    "- Ensure latest data is available\n",
    "- Simple cell at top: `python scripts/helper/refresh_data.py` or direct import\n",
    "\n",
    "**Option B**: External scheduled refresh (e.g., GitHub Actions, cron)\n",
    "- Data is refreshed automatically\n",
    "- Notebooks always work with current data\n",
    "- Requires infrastructure setup\n",
    "\n",
    "**Option C**: Manual refresh on-demand\n",
    "- Users explicitly choose when to refresh\n",
    "- Lower data freshness but less overhead\n",
    "\n",
    "## Project Structure\n",
    "\n",
    "```\n",
    ".\n",
    "├── config.ini                  # Configuration (API endpoints, paths)\n",
    "├── data/                       # Data storage\n",
    "│   ├── raw/                    # Original downloads\n",
    "│   └── processed/              # Consolidated Parquet files\n",
    "├── notebooks/                  # Jupyter notebook suite (THIS IS YOU!)\n",
    "│   ├── 00_start_here.ipynb     # Master index\n",
    "│   ├── phase_01_data_ingestion/\n",
    "│   ├── phase_02_exploration/\n",
    "│   ├── phase_03_processing/\n",
    "│   ├── phase_04_analysis/\n",
    "│   ├── phase_05_visualization/\n",
    "│   └── phase_06_modeling/\n",
    "├── scripts/\n",
    "│   └── helper/                 # ETL/helper scripts (scrape, consolidate)\n",
    "├── src/                        # Reusable library code\n",
    "│   ├── data/                   # Data loading and utilities\n",
    "│   ├── analysis/               # Statistical profiling and analysis\n",
    "│   ├── geospatial/             # Spatial analysis and mapping\n",
    "│   └── utils/                  # Configuration and general utilities\n",
    "├── visualizations/             # Generated maps and charts\n",
    "├── requirements.txt            # Python dependencies\n",
    "└── README.md                   # Project documentation\n",
    "```\n",
    "\n",
    "## Reusable Modules\n",
    "\n",
    "Notebooks leverage these reusable components from `src/`:\n",
    "\n",
    "- **`src.data.loader`**: Load Parquet files and datasets\n",
    "- **`src.analysis.profiler`**: Data profiling, statistical summaries, cross-tabulations\n",
    "- **`src.geospatial.analyzer`**: GeoDataFrame conversion, hotspot detection, map generation\n",
    "- **`src.utils.config`**: Configuration management and path resolution\n",
    "\n",
    "## Key Dependencies\n",
    "\n",
    "- **pandas**: Data manipulation and analysis\n",
    "- **geopandas**: Spatial data handling\n",
    "- **folium**: Interactive mapping\n",
    "- **plotly**: Interactive dashboards and charts\n",
    "- **scikit-learn**: Machine learning (future modeling)\n",
    "- **requests**: API calls for data ingestion\n",
    "- **pyarrow**: Parquet file support\n",
    "\n",
    "## Tips for Effective Use\n",
    "\n",
    "1. **Run cells sequentially** within each notebook to maintain state\n",
    "2. **Review markdown cells** for context and explanations\n",
    "3. **Modify parameters** (date ranges, filtering criteria) to customize analyses\n",
    "4. **Export outputs** as needed (CSV, HTML, PNG)\n",
    "5. **Keep notebooks focused** on their phase—complex custom analysis can be added as new notebooks\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "### To get started immediately:\n",
    "1. Navigate to: `notebooks/phase_01_data_ingestion/01_scrape_and_consolidate.ipynb`\n",
    "2. Run all cells to download and consolidate data\n",
    "3. Move to Phase 2 for initial data exploration\n",
    "\n",
    "### To skip data ingestion (if data already exists):\n",
    "1. Jump to: `notebooks/phase_02_exploration/01_data_overview.ipynb`\n",
    "2. Verify data is loaded correctly\n",
    "3. Proceed through subsequent phases\n",
    "\n",
    "---\n",
    "\n",
    "**Version**: 1.0  \n",
    "**Last Updated**: 2026-01-27  \n",
    "**Contact**: For questions or issues, refer to the project README or documentation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
