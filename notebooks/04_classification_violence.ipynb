{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Violence Classification Model\n",
    "\n",
    "**Objective:** Build a classification model to predict whether crime incidents are violent vs non-violent\n",
    "\n",
    "**Purpose:** Support resource allocation decisions by identifying violent incident patterns\n",
    "\n",
    "**Methodology:**\n",
    "- Binary classification: Violent (1) vs Non-Violent (0)\n",
    "- Time-aware validation to prevent data leakage\n",
    "- Feature importance analysis using built-in methods and SHAP\n",
    "- Model card documenting performance and limitations\n",
    "\n",
    "**Requirements:** FORECAST-02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "# Ensure repo root is in path for imports\n",
    "config_path = Path.cwd().parent / 'analysis' / 'phase1_config.yaml'\n",
    "if config_path.exists():\n",
    "    repo_root = config_path.parent.parent\n",
    "else:\n",
    "    repo_root = Path.cwd().parent\n",
    "\n",
    "sys.path.insert(0, str(repo_root))\n",
    "\n",
    "# Project imports\n",
    "from analysis.config import CRIME_DATA_PATH, REPORTS_DIR\n",
    "from analysis.utils import load_data, classify_crime_category\n",
    "from analysis.models.classification import (\n",
    "    create_time_aware_split,\n",
    "    train_random_forest,\n",
    "    train_xgboost,\n",
    "    extract_feature_importance,\n",
    "    evaluate_classifier,\n",
    ")\n",
    "from analysis.models.validation import create_model_card, validate_temporal_split\n",
    "\n",
    "# Ensure reports directory exists\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "print(f\"✓ Notebook initialized\")\n",
    "print(f\"✓ Random seed: {RANDOM_SEED}\")\n",
    "print(f\"✓ Data path: {CRIME_DATA_PATH}\")\n",
    "print(f\"✓ Reports directory: {REPORTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preparation\n",
    "\n",
    "Load crime data and create binary target variable for violent vs non-violent classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load crime data\n",
    "df = load_data(clean=True)\n",
    "\n",
    "# Classify crimes into categories\n",
    "df = classify_crime_category(df)\n",
    "\n",
    "# Create binary target: Violent (1) vs Non-Violent (0)\n",
    "df['is_violent'] = (df['crime_category'] == 'Violent').astype(int)\n",
    "\n",
    "# Sort by date to maintain temporal order (critical for time-aware validation)\n",
    "df = df.sort_values('dispatch_date').reset_index(drop=True)\n",
    "\n",
    "print(f\"Total incidents: {len(df):,}\")\n",
    "print(f\"Date range: {df['dispatch_date'].min()} to {df['dispatch_date'].max()}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df['is_violent'].value_counts())\n",
    "print(f\"\\nViolent crime percentage: {df['is_violent'].mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis: Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot\n",
    "class_counts = df['is_violent'].value_counts()\n",
    "axes[0].bar(['Non-Violent', 'Violent'], class_counts.values, color=['#457B9D', '#E63946'])\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Class Distribution: Violent vs Non-Violent')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(class_counts.values):\n",
    "    axes[0].text(i, v, f'{v:,}', ha='center', va='bottom')\n",
    "\n",
    "# Time series of violent crime percentage\n",
    "monthly_violent = df.groupby(df['dispatch_date'].dt.to_period('M'))['is_violent'].mean() * 100\n",
    "monthly_violent.index = monthly_violent.index.to_timestamp()\n",
    "axes[1].plot(monthly_violent.index, monthly_violent.values, linewidth=1.5, color='#E63946')\n",
    "axes[1].axhline(df['is_violent'].mean() * 100, color='gray', linestyle='--', alpha=0.5, label='Overall mean')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Violent Crime %')\n",
    "axes[1].set_title('Violent Crime Percentage Over Time (Monthly)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / '04_classification_class_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Class distribution visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "Create features suitable for classification while preserving temporal order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract datetime features\n",
    "df['year'] = df['dispatch_date'].dt.year\n",
    "df['month'] = df['dispatch_date'].dt.month\n",
    "df['day_of_week'] = df['dispatch_date'].dt.dayofweek\n",
    "df['hour'] = df['dispatch_date'].dt.hour\n",
    "df['day_of_year'] = df['dispatch_date'].dt.dayofyear\n",
    "df['week_of_year'] = df['dispatch_date'].dt.isocalendar().week\n",
    "df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "\n",
    "# Time of day categories\n",
    "df['time_of_day'] = pd.cut(\n",
    "    df['hour'],\n",
    "    bins=[0, 6, 12, 18, 24],\n",
    "    labels=['Night', 'Morning', 'Afternoon', 'Evening'],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# District features (if available)\n",
    "if 'dc_dist' in df.columns:\n",
    "    # Clean district codes\n",
    "    df['district'] = pd.to_numeric(df['dc_dist'], errors='coerce').fillna(0).astype(int)\n",
    "else:\n",
    "    df['district'] = 0\n",
    "\n",
    "# UCR code features\n",
    "if 'ucr_general' in df.columns:\n",
    "    df['ucr_code'] = pd.to_numeric(df['ucr_general'], errors='coerce').fillna(0).astype(int)\n",
    "    df['ucr_category'] = (df['ucr_code'] // 100).astype(int)  # Hundred-bands\n",
    "else:\n",
    "    df['ucr_code'] = 0\n",
    "    df['ucr_category'] = 0\n",
    "\n",
    "# Location features (if available)\n",
    "if 'point_x' in df.columns and 'point_y' in df.columns:\n",
    "    df['location_x'] = pd.to_numeric(df['point_x'], errors='coerce').fillna(0)\n",
    "    df['location_y'] = pd.to_numeric(df['point_y'], errors='coerce').fillna(0)\n",
    "else:\n",
    "    df['location_x'] = 0\n",
    "    df['location_y'] = 0\n",
    "\n",
    "print(\"✓ Temporal features extracted\")\n",
    "print(f\"\\nFeature summary:\")\n",
    "print(f\"  - Temporal: year, month, day_of_week, hour, day_of_year, week_of_year, is_weekend, time_of_day\")\n",
    "print(f\"  - Location: district, location_x, location_y\")\n",
    "print(f\"  - Crime type: ucr_code, ucr_category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for modeling\n",
    "feature_columns = [\n",
    "    'year',\n",
    "    'month',\n",
    "    'day_of_week',\n",
    "    'hour',\n",
    "    'day_of_year',\n",
    "    'week_of_year',\n",
    "    'is_weekend',\n",
    "    'district',\n",
    "    'location_x',\n",
    "    'location_y',\n",
    "]\n",
    "\n",
    "# Encode categorical time_of_day\n",
    "time_dummies = pd.get_dummies(df['time_of_day'], prefix='time', drop_first=True)\n",
    "df = pd.concat([df, time_dummies], axis=1)\n",
    "feature_columns.extend(time_dummies.columns.tolist())\n",
    "\n",
    "# Prepare feature matrix and target\n",
    "X = df[feature_columns].copy()\n",
    "y = df['is_violent'].copy()\n",
    "\n",
    "# Add dispatch_date as index for temporal split\n",
    "X.index = df['dispatch_date']\n",
    "y.index = df['dispatch_date']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target distribution: {y.value_counts().to_dict()}\")\n",
    "print(f\"\\nFeatures: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Time-Aware Train/Test Split\n",
    "\n",
    "Use temporal splitting (no shuffling) to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time-aware split (80/20)\n",
    "X_train, X_test, y_train, y_test = create_time_aware_split(\n",
    "    X, y, test_size=0.2, ensure_sorted=True\n",
    ")\n",
    "\n",
    "# Validate temporal split\n",
    "split_validation = validate_temporal_split(\n",
    "    pd.Series(X_train.index),\n",
    "    pd.Series(X_test.index),\n",
    "    min_gap_days=0\n",
    ")\n",
    "\n",
    "print(\"Time-aware split created:\")\n",
    "print(f\"  Training period: {X_train.index.min()} to {X_train.index.max()}\")\n",
    "print(f\"  Testing period: {X_test.index.min()} to {X_test.index.max()}\")\n",
    "print(f\"  Train size: {len(X_train):,} ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"  Test size: {len(X_test):,} ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "print(f\"\\nTrain class distribution: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Test class distribution: {y_test.value_counts().to_dict()}\")\n",
    "print(f\"\\nValidation:\")\n",
    "print(f\"  Temporal order preserved: {split_validation['valid_temporal_order']}\")\n",
    "print(f\"  Gap between train and test: {split_validation['gap_days']} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training: Random Forest\n",
    "\n",
    "Train a Random Forest classifier with time-aware validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest model\n",
    "print(\"Training Random Forest classifier...\")\n",
    "\n",
    "rf_model, rf_scaler = train_random_forest(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=RANDOM_SEED,\n",
    "    scale_features=True,\n",
    ")\n",
    "\n",
    "print(\"✓ Random Forest model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "X_test_scaled = rf_scaler.transform(X_test) if rf_scaler else X_test\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "y_prob_rf = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate Random Forest\n",
    "rf_metrics = evaluate_classifier(\n",
    "    y_test,\n",
    "    y_pred_rf,\n",
    "    y_prob_rf,\n",
    "    target_names=['Non-Violent', 'Violent']\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RANDOM FOREST PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nROC-AUC Score: {rf_metrics['roc_auc']:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(pd.DataFrame(rf_metrics['classification_report']).T)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(rf_metrics['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training: XGBoost\n",
    "\n",
    "Train an XGBoost classifier for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost model\n",
    "print(\"Training XGBoost classifier...\")\n",
    "\n",
    "xgb_model, xgb_scaler = train_xgboost(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=RANDOM_SEED,\n",
    "    scale_features=False,  # XGBoost doesn't need scaling\n",
    ")\n",
    "\n",
    "print(\"✓ XGBoost model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_prob_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate XGBoost\n",
    "xgb_metrics = evaluate_classifier(\n",
    "    y_test,\n",
    "    y_pred_xgb,\n",
    "    y_prob_xgb,\n",
    "    target_names=['Non-Violent', 'Violent']\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"XGBOOST PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nROC-AUC Score: {xgb_metrics['roc_auc']:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(pd.DataFrame(xgb_metrics['classification_report']).T)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(xgb_metrics['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis\n",
    "\n",
    "Extract and visualize feature importance from both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importance from Random Forest\n",
    "rf_importance = extract_feature_importance(\n",
    "    rf_model,\n",
    "    feature_names=X_train.columns.tolist(),\n",
    "    top_n=15\n",
    ")\n",
    "\n",
    "# Extract feature importance from XGBoost\n",
    "xgb_importance = extract_feature_importance(\n",
    "    xgb_model,\n",
    "    feature_names=X_train.columns.tolist(),\n",
    "    top_n=15\n",
    ")\n",
    "\n",
    "print(\"Top 10 Features (Random Forest):\")\n",
    "print(rf_importance.head(10))\n",
    "print(\"\\nTop 10 Features (XGBoost):\")\n",
    "print(xgb_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Random Forest importance\n",
    "axes[0].barh(range(len(rf_importance)), rf_importance['importance'], color='#457B9D')\n",
    "axes[0].set_yticks(range(len(rf_importance)))\n",
    "axes[0].set_yticklabels(rf_importance['feature'])\n",
    "axes[0].set_xlabel('Importance')\n",
    "axes[0].set_title('Random Forest: Top 15 Feature Importances')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# XGBoost importance\n",
    "axes[1].barh(range(len(xgb_importance)), xgb_importance['importance'], color='#E63946')\n",
    "axes[1].set_yticks(range(len(xgb_importance)))\n",
    "axes[1].set_yticklabels(xgb_importance['feature'])\n",
    "axes[1].set_xlabel('Importance')\n",
    "axes[1].set_title('XGBoost: Top 15 Feature Importances')\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / '04_classification_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Feature importance visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. SHAP Analysis for Interpretability\n",
    "\n",
    "Use SHAP values to understand model decisions (using XGBoost model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SHAP values for a sample of test data\n",
    "print(\"Computing SHAP values (this may take a minute)...\")\n",
    "\n",
    "# Sample 500 instances for SHAP analysis (to speed up computation)\n",
    "X_test_sample = X_test.sample(min(500, len(X_test)), random_state=RANDOM_SEED)\n",
    "\n",
    "# Create SHAP explainer\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "shap_values = explainer.shap_values(X_test_sample)\n",
    "\n",
    "print(\"✓ SHAP values computed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP summary plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values, X_test_sample, show=False)\n",
    "plt.title('SHAP Feature Importance Summary', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / '04_classification_shap_summary.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ SHAP summary visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Performance Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves and Precision-Recall curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ROC Curve\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_prob_xgb)\n",
    "\n",
    "axes[0].plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC={rf_metrics[\"roc_auc\"]:.3f})', linewidth=2, color='#457B9D')\n",
    "axes[0].plot(fpr_xgb, tpr_xgb, label=f'XGBoost (AUC={xgb_metrics[\"roc_auc\"]:.3f})', linewidth=2, color='#E63946')\n",
    "axes[0].plot([0, 1], [0, 1], 'k--', alpha=0.3, label='Random Classifier')\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].set_title('ROC Curves')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision_rf, recall_rf, _ = precision_recall_curve(y_test, y_prob_rf)\n",
    "precision_xgb, recall_xgb, _ = precision_recall_curve(y_test, y_prob_xgb)\n",
    "\n",
    "axes[1].plot(recall_rf, precision_rf, label='Random Forest', linewidth=2, color='#457B9D')\n",
    "axes[1].plot(recall_xgb, precision_xgb, label='XGBoost', linewidth=2, color='#E63946')\n",
    "axes[1].axhline(y_test.mean(), color='k', linestyle='--', alpha=0.3, label='Baseline')\n",
    "axes[1].set_xlabel('Recall')\n",
    "axes[1].set_ylabel('Precision')\n",
    "axes[1].set_title('Precision-Recall Curves')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / '04_classification_performance_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Performance curves saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Card: Documentation and Limitations\n",
    "\n",
    "Create comprehensive model documentation including performance metrics and known limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model cards for both models\n",
    "rf_card = create_model_card(\n",
    "    model_name=\"Violence Classification - Random Forest\",\n",
    "    model_type=\"RandomForestClassifier\",\n",
    "    features=X_train.columns.tolist(),\n",
    "    train_metrics={\n",
    "        \"accuracy\": rf_model.score(rf_scaler.transform(X_train) if rf_scaler else X_train, y_train),\n",
    "    },\n",
    "    test_metrics={\n",
    "        \"accuracy\": rf_metrics['classification_report']['accuracy'],\n",
    "        \"roc_auc\": rf_metrics['roc_auc'],\n",
    "        \"precision_violent\": rf_metrics['classification_report']['Violent']['precision'],\n",
    "        \"recall_violent\": rf_metrics['classification_report']['Violent']['recall'],\n",
    "        \"f1_violent\": rf_metrics['classification_report']['Violent']['f1-score'],\n",
    "    },\n",
    "    limitations=[\n",
    "        \"Model trained on historical data; performance may degrade with changing crime patterns\",\n",
    "        f\"Class imbalance: {(1-y.mean())*100:.1f}% non-violent vs {y.mean()*100:.1f}% violent\",\n",
    "        \"Temporal features may not capture sudden policy changes or external events\",\n",
    "        \"Limited to features available at time of dispatch (no investigation outcomes)\",\n",
    "        \"Geographic coverage limited to Philadelphia; not generalizable to other cities\",\n",
    "        \"Model should be retrained periodically as new data becomes available\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "xgb_card = create_model_card(\n",
    "    model_name=\"Violence Classification - XGBoost\",\n",
    "    model_type=\"XGBClassifier\",\n",
    "    features=X_train.columns.tolist(),\n",
    "    train_metrics={\n",
    "        \"accuracy\": xgb_model.score(X_train, y_train),\n",
    "    },\n",
    "    test_metrics={\n",
    "        \"accuracy\": xgb_metrics['classification_report']['accuracy'],\n",
    "        \"roc_auc\": xgb_metrics['roc_auc'],\n",
    "        \"precision_violent\": xgb_metrics['classification_report']['Violent']['precision'],\n",
    "        \"recall_violent\": xgb_metrics['classification_report']['Violent']['recall'],\n",
    "        \"f1_violent\": xgb_metrics['classification_report']['Violent']['f1-score'],\n",
    "    },\n",
    "    limitations=[\n",
    "        \"Model trained on historical data; performance may degrade with changing crime patterns\",\n",
    "        f\"Class imbalance: {(1-y.mean())*100:.1f}% non-violent vs {y.mean()*100:.1f}% violent\",\n",
    "        \"Temporal features may not capture sudden policy changes or external events\",\n",
    "        \"Limited to features available at time of dispatch (no investigation outcomes)\",\n",
    "        \"Geographic coverage limited to Philadelphia; not generalizable to other cities\",\n",
    "        \"Model should be retrained periodically as new data becomes available\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Model Cards Created\\n\")\n",
    "print(\"=\"*80)\n",
    "print(\"RANDOM FOREST MODEL CARD\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Model: {rf_card['model_name']}\")\n",
    "print(f\"Type: {rf_card['model_type']}\")\n",
    "print(f\"Features: {rf_card['n_features']}\")\n",
    "print(f\"\\nTest Performance:\")\n",
    "for metric, value in rf_card['test_performance'].items():\n",
    "    print(f\"  {metric}: {value:.4f}\")\n",
    "print(f\"\\nLimitations:\")\n",
    "for i, limitation in enumerate(rf_card['limitations'], 1):\n",
    "    print(f\"  {i}. {limitation}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"XGBOOST MODEL CARD\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Model: {xgb_card['model_name']}\")\n",
    "print(f\"Type: {xgb_card['model_type']}\")\n",
    "print(f\"Features: {xgb_card['n_features']}\")\n",
    "print(f\"\\nTest Performance:\")\n",
    "for metric, value in xgb_card['test_performance'].items():\n",
    "    print(f\"  {metric}: {value:.4f}\")\n",
    "print(f\"\\nLimitations:\")\n",
    "for i, limitation in enumerate(xgb_card['limitations'], 1):\n",
    "    print(f\"  {i}. {limitation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model cards to JSON\n",
    "import json\n",
    "\n",
    "with open(REPORTS_DIR / '04_classification_rf_model_card.json', 'w') as f:\n",
    "    json.dump(rf_card, f, indent=2)\n",
    "\n",
    "with open(REPORTS_DIR / '04_classification_xgb_model_card.json', 'w') as f:\n",
    "    json.dump(xgb_card, f, indent=2)\n",
    "\n",
    "print(\"✓ Model cards saved to reports directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary and Recommendations\n",
    "\n",
    "Key findings and operational recommendations for resource allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "summary = f\"\"\"\n",
    "VIOLENCE CLASSIFICATION MODEL SUMMARY\n",
    "{'='*80}\n",
    "\n",
    "OBJECTIVE:\n",
    "  Predict whether crime incidents are violent vs non-violent to support\n",
    "  resource allocation and operational planning.\n",
    "\n",
    "DATA:\n",
    "  Total incidents: {len(df):,}\n",
    "  Date range: {df['dispatch_date'].min()} to {df['dispatch_date'].max()}\n",
    "  Violent incidents: {y.sum():,} ({y.mean()*100:.2f}%)\n",
    "  Non-violent incidents: {(~y.astype(bool)).sum():,} ({(1-y.mean())*100:.2f}%)\n",
    "\n",
    "METHODOLOGY:\n",
    "  - Time-aware train/test split (80/20) - no shuffling to prevent data leakage\n",
    "  - Training period: {X_train.index.min()} to {X_train.index.max()}\n",
    "  - Testing period: {X_test.index.min()} to {X_test.index.max()}\n",
    "  - Random seed: {RANDOM_SEED} (for reproducibility)\n",
    "\n",
    "MODELS TRAINED:\n",
    "  1. Random Forest (n_estimators=200, max_depth=10)\n",
    "  2. XGBoost (n_estimators=200, max_depth=6, lr=0.1)\n",
    "\n",
    "PERFORMANCE (Test Set):\n",
    "  Random Forest:\n",
    "    - ROC-AUC: {rf_metrics['roc_auc']:.4f}\n",
    "    - Accuracy: {rf_metrics['classification_report']['accuracy']:.4f}\n",
    "    - Violent Precision: {rf_metrics['classification_report']['Violent']['precision']:.4f}\n",
    "    - Violent Recall: {rf_metrics['classification_report']['Violent']['recall']:.4f}\n",
    "    - Violent F1: {rf_metrics['classification_report']['Violent']['f1-score']:.4f}\n",
    "\n",
    "  XGBoost:\n",
    "    - ROC-AUC: {xgb_metrics['roc_auc']:.4f}\n",
    "    - Accuracy: {xgb_metrics['classification_report']['accuracy']:.4f}\n",
    "    - Violent Precision: {xgb_metrics['classification_report']['Violent']['precision']:.4f}\n",
    "    - Violent Recall: {xgb_metrics['classification_report']['Violent']['recall']:.4f}\n",
    "    - Violent F1: {xgb_metrics['classification_report']['Violent']['f1-score']:.4f}\n",
    "\n",
    "TOP 5 PREDICTIVE FEATURES:\n",
    "  Random Forest:\n",
    "{chr(10).join([f'    {i+1}. {row[\"feature\"]}: {row[\"importance\"]:.4f}' for i, row in rf_importance.head(5).iterrows()])}\n",
    "\n",
    "  XGBoost:\n",
    "{chr(10).join([f'    {i+1}. {row[\"feature\"]}: {row[\"importance\"]:.4f}' for i, row in xgb_importance.head(5).iterrows()])}\n",
    "\n",
    "KEY LIMITATIONS:\n",
    "  - Class imbalance may affect minority class predictions\n",
    "  - Model performance depends on stable crime patterns\n",
    "  - Limited to features available at dispatch time\n",
    "  - Requires periodic retraining with new data\n",
    "\n",
    "OPERATIONAL RECOMMENDATIONS:\n",
    "  1. Use model predictions to prioritize violent incident response\n",
    "  2. Monitor model performance monthly; retrain quarterly\n",
    "  3. Combine predictions with officer judgment for final decisions\n",
    "  4. Track false positives/negatives to identify improvement areas\n",
    "  5. Consider ensemble of both models for robust predictions\n",
    "\n",
    "ARTIFACTS GENERATED:\n",
    "  - reports/04_classification_class_distribution.png\n",
    "  - reports/04_classification_feature_importance.png\n",
    "  - reports/04_classification_shap_summary.png\n",
    "  - reports/04_classification_performance_curves.png\n",
    "  - reports/04_classification_rf_model_card.json\n",
    "  - reports/04_classification_xgb_model_card.json\n",
    "\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "# Save summary to file\n",
    "with open(REPORTS_DIR / '04_classification_summary.txt', 'w') as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(\"✓ Summary report saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility Cell\n",
    "\n",
    "This notebook can be re-run end-to-end to reproduce all results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment information for reproducibility\n",
    "import sys\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"\\nKey package versions:\")\n",
    "import pandas, numpy, sklearn, xgboost, shap, matplotlib, seaborn\n",
    "print(f\"  pandas: {pandas.__version__}\")\n",
    "print(f\"  numpy: {numpy.__version__}\")\n",
    "print(f\"  scikit-learn: {sklearn.__version__}\")\n",
    "print(f\"  xgboost: {xgboost.__version__}\")\n",
    "print(f\"  shap: {shap.__version__}\")\n",
    "print(f\"  matplotlib: {matplotlib.__version__}\")\n",
    "print(f\"  seaborn: {seaborn.__version__}\")\n",
    "print(f\"\\nRandom seed: {RANDOM_SEED}\")\n",
    "print(f\"\\nAll results are reproducible by re-running this notebook with the same seed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
