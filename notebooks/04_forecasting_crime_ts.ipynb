{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0232cec7",
   "metadata": {},
   "source": [
    "# Crime Incidents Time Series Forecasting\n",
    "*Requirement: FORECAST-01*\n",
    "\n",
    "**Objective:** Forecast daily crime incidents for the next 60 days using Prophet with 95% confidence intervals and anomaly detection.\n",
    "\n",
    "**Key Outputs:**\n",
    "- 60-day forecast with prediction intervals\n",
    "- Anomaly detection thresholds\n",
    "- Model performance metrics\n",
    "- Operational recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662fd4e4",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Reproducibility parameters\n",
    "VERSION = \"v1.0\"\n",
    "FORECAST_HORIZON_DAYS = 60\n",
    "VALIDATION_DAYS = 30\n",
    "RANDOM_SEED = 42\n",
    "CONFIDENCE_INTERVAL = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0b6779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Robust repo_root detection\n",
    "cwd = Path.cwd()\n",
    "if (cwd / 'config' / 'phase1_config.yaml').exists():\n",
    "    repo_root = cwd\n",
    "elif (cwd.parent / 'config' / 'phase1_config.yaml').exists():\n",
    "    repo_root = cwd.parent\n",
    "else:\n",
    "    raise RuntimeError(f\"Cannot find config from cwd={cwd}\")\n",
    "\n",
    "sys.path.insert(0, str(repo_root))\n",
    "print(f\"Repository root: {repo_root}\")\n",
    "\n",
    "# Define paths\n",
    "DATA_DIR = repo_root / 'data'\n",
    "REPORTS_DIR = repo_root / 'reports'\n",
    "REPORTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Record execution metadata\n",
    "start_time = time.time()\n",
    "run_timestamp = time.strftime('%Y%m%d_%H%M%S')\n",
    "print(f\"\\nExecution started: {run_timestamp}\")\n",
    "print(f\"Version: {VERSION}\")\n",
    "print(f\"Forecast horizon: {FORECAST_HORIZON_DAYS} days\")\n",
    "print(f\"Confidence interval: {CONFIDENCE_INTERVAL*100}%\")\n",
    "print(f\"Random seed: {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lib_imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from prophet import Prophet\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Import custom utilities\n",
    "from analysis.models.time_series import (\n",
    "    prepare_prophet_data,\n",
    "    create_train_test_split,\n",
    "    get_prophet_config,\n",
    "    evaluate_forecast,\n",
    "    detect_anomalies\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Configure plotting\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_load",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preparation\n",
    "\n",
    "Load crime incidents and aggregate by date to create daily time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load crime incidents\n",
    "crime_file = DATA_DIR / 'crime_incidents_combined.parquet'\n",
    "print(f\"Loading data from: {crime_file}\")\n",
    "df_raw = pd.read_parquet(crime_file)\n",
    "\n",
    "# Convert categorical dispatch_date to datetime for aggregation\n",
    "df_raw['dispatch_date'] = pd.to_datetime(df_raw['dispatch_date'].astype(str))\n",
    "\n",
    "print(f\"\\nRaw data shape: {df_raw.shape}\")\n",
    "print(f\"Date range: {df_raw['dispatch_date'].min().date()} to {df_raw['dispatch_date'].max().date()}\")\n",
    "print(f\"Total incidents: {len(df_raw):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate_daily",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate incidents by date\n",
    "df_daily = df_raw.groupby('dispatch_date').size().reset_index(name='incident_count')\n",
    "df_daily.columns = ['date', 'count']\n",
    "df_daily['date'] = pd.to_datetime(df_daily['date'])\n",
    "df_daily = df_daily.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nDaily aggregation complete\")\n",
    "print(f\"Time series length: {len(df_daily)} days\")\n",
    "print(f\"Date range: {df_daily['date'].min().date()} to {df_daily['date'].max().date()}\")\n",
    "print(f\"\\nDaily incident statistics:\")\n",
    "print(df_daily['count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare_prophet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data in Prophet format (ds, y)\n",
    "df_prophet = prepare_prophet_data(df_daily, 'date', 'count')\n",
    "\n",
    "print(\"\\nProphet format data:\")\n",
    "print(df_prophet.head())\n",
    "print(f\"\\nShape: {df_prophet.shape}\")\n",
    "print(f\"Missing values: {df_prophet.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz_ts",
   "metadata": {},
   "source": [
    "## 2. Exploratory Time Series Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_ts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot full time series\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.plot(df_prophet['ds'], df_prophet['y'], linewidth=0.8, alpha=0.7)\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Daily Incident Count', fontsize=12)\n",
    "ax.set_title('Daily Crime Incidents Over Time', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / 'forecast_timeseries_raw.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Time series visualization saved to reports/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolling_stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling statistics\n",
    "df_prophet['rolling_mean_7'] = df_prophet['y'].rolling(window=7, center=True).mean()\n",
    "df_prophet['rolling_mean_30'] = df_prophet['y'].rolling(window=30, center=True).mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.plot(df_prophet['ds'], df_prophet['y'], linewidth=0.5, alpha=0.4, label='Daily')\n",
    "ax.plot(df_prophet['ds'], df_prophet['rolling_mean_7'], linewidth=1.5, label='7-day MA')\n",
    "ax.plot(df_prophet['ds'], df_prophet['rolling_mean_30'], linewidth=2, label='30-day MA')\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Incident Count', fontsize=12)\n",
    "ax.set_title('Daily Incidents with Moving Averages', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='best')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / 'forecast_timeseries_smoothed.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Clean up rolling stats columns for Prophet\n",
    "df_prophet = df_prophet[['ds', 'y']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split_section",
   "metadata": {},
   "source": [
    "## 3. Train/Validation Split\n",
    "\n",
    "Create temporal split for model validation before generating future forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/validation split\n",
    "train_df, validation_df = create_train_test_split(df_prophet, test_days=VALIDATION_DAYS)\n",
    "\n",
    "print(f\"Train set: {len(train_df)} days ({train_df['ds'].min().date()} to {train_df['ds'].max().date()})\")\n",
    "print(f\"Validation set: {len(validation_df)} days ({validation_df['ds'].min().date()} to {validation_df['ds'].max().date()})\")\n",
    "print(f\"\\nTrain set statistics:\")\n",
    "print(train_df['y'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metadata_capture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture execution metadata\n",
    "metadata = {\n",
    "    'version': VERSION,\n",
    "    'execution_timestamp': run_timestamp,\n",
    "    'forecast_horizon_days': FORECAST_HORIZON_DAYS,\n",
    "    'validation_days': VALIDATION_DAYS,\n",
    "    'confidence_interval': CONFIDENCE_INTERVAL,\n",
    "    'random_seed': RANDOM_SEED,\n",
    "    'data_source': str(crime_file),\n",
    "    'total_observations': len(df_prophet),\n",
    "    'train_observations': len(train_df),\n",
    "    'validation_observations': len(validation_df),\n",
    "    'date_range_start': str(df_prophet['ds'].min().date()),\n",
    "    'date_range_end': str(df_prophet['ds'].max().date()),\n",
    "    'mean_daily_incidents': float(df_prophet['y'].mean()),\n",
    "    'std_daily_incidents': float(df_prophet['y'].std())\n",
    "}\n",
    "\n",
    "print(\"\\nExecution metadata captured\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
