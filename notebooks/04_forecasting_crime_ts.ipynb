{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0232cec7",
   "metadata": {},
   "source": [
    "# Crime Incidents Time Series Forecasting\n",
    "*Requirement: FORECAST-01*\n",
    "\n",
    "**Objective:** Forecast daily crime incidents for the next 60 days using Prophet with 95% confidence intervals and anomaly detection.\n",
    "\n",
    "**Key Outputs:**\n",
    "- 60-day forecast with prediction intervals\n",
    "- Anomaly detection thresholds\n",
    "- Model performance metrics\n",
    "- Operational recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662fd4e4",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Reproducibility parameters\n",
    "VERSION = \"v1.0\"\n",
    "FORECAST_HORIZON_DAYS = 60\n",
    "VALIDATION_DAYS = 30\n",
    "RANDOM_SEED = 42\n",
    "CONFIDENCE_INTERVAL = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0b6779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Robust repo_root detection\n",
    "cwd = Path.cwd()\n",
    "if (cwd / 'config' / 'phase1_config.yaml').exists():\n",
    "    repo_root = cwd\n",
    "elif (cwd.parent / 'config' / 'phase1_config.yaml').exists():\n",
    "    repo_root = cwd.parent\n",
    "else:\n",
    "    raise RuntimeError(f\"Cannot find config from cwd={cwd}\")\n",
    "\n",
    "sys.path.insert(0, str(repo_root))\n",
    "print(f\"Repository root: {repo_root}\")\n",
    "\n",
    "# Define paths\n",
    "DATA_DIR = repo_root / 'data'\n",
    "REPORTS_DIR = repo_root / 'reports'\n",
    "REPORTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Record execution metadata\n",
    "start_time = time.time()\n",
    "run_timestamp = time.strftime('%Y%m%d_%H%M%S')\n",
    "print(f\"\\nExecution started: {run_timestamp}\")\n",
    "print(f\"Version: {VERSION}\")\n",
    "print(f\"Forecast horizon: {FORECAST_HORIZON_DAYS} days\")\n",
    "print(f\"Confidence interval: {CONFIDENCE_INTERVAL*100}%\")\n",
    "print(f\"Random seed: {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lib_imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from prophet import Prophet\n",
    "\n",
    "# Import custom utilities\n",
    "from analysis.models.time_series import (\n",
    "    create_train_test_split,\n",
    "    detect_anomalies,\n",
    "    evaluate_forecast,\n",
    "    get_prophet_config,\n",
    "    prepare_prophet_data,\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Configure plotting\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_load",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preparation\n",
    "\n",
    "Load crime incidents and aggregate by date to create daily time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load crime incidents\n",
    "crime_file = DATA_DIR / 'crime_incidents_combined.parquet'\n",
    "print(f\"Loading data from: {crime_file}\")\n",
    "df_raw = pd.read_parquet(crime_file)\n",
    "\n",
    "# Convert categorical dispatch_date to datetime for aggregation\n",
    "df_raw['dispatch_date'] = pd.to_datetime(df_raw['dispatch_date'].astype(str))\n",
    "\n",
    "print(f\"\\nRaw data shape: {df_raw.shape}\")\n",
    "print(f\"Date range: {df_raw['dispatch_date'].min().date()} to {df_raw['dispatch_date'].max().date()}\")\n",
    "print(f\"Total incidents: {len(df_raw):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate_daily",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate incidents by date\n",
    "df_daily = df_raw.groupby('dispatch_date').size().reset_index(name='incident_count')\n",
    "df_daily.columns = ['date', 'count']\n",
    "df_daily['date'] = pd.to_datetime(df_daily['date'])\n",
    "df_daily = df_daily.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "print(\"\\nDaily aggregation complete\")\n",
    "print(f\"Time series length: {len(df_daily)} days\")\n",
    "print(f\"Date range: {df_daily['date'].min().date()} to {df_daily['date'].max().date()}\")\n",
    "print(\"\\nDaily incident statistics:\")\n",
    "print(df_daily['count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare_prophet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data in Prophet format (ds, y)\n",
    "df_prophet = prepare_prophet_data(df_daily, 'date', 'count')\n",
    "\n",
    "print(\"\\nProphet format data:\")\n",
    "print(df_prophet.head())\n",
    "print(f\"\\nShape: {df_prophet.shape}\")\n",
    "print(f\"Missing values: {df_prophet.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz_ts",
   "metadata": {},
   "source": [
    "## 2. Exploratory Time Series Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_ts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot full time series\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.plot(df_prophet['ds'], df_prophet['y'], linewidth=0.8, alpha=0.7)\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Daily Incident Count', fontsize=12)\n",
    "ax.set_title('Daily Crime Incidents Over Time', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / 'forecast_timeseries_raw.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Time series visualization saved to reports/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolling_stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling statistics\n",
    "df_prophet['rolling_mean_7'] = df_prophet['y'].rolling(window=7, center=True).mean()\n",
    "df_prophet['rolling_mean_30'] = df_prophet['y'].rolling(window=30, center=True).mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.plot(df_prophet['ds'], df_prophet['y'], linewidth=0.5, alpha=0.4, label='Daily')\n",
    "ax.plot(df_prophet['ds'], df_prophet['rolling_mean_7'], linewidth=1.5, label='7-day MA')\n",
    "ax.plot(df_prophet['ds'], df_prophet['rolling_mean_30'], linewidth=2, label='30-day MA')\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Incident Count', fontsize=12)\n",
    "ax.set_title('Daily Incidents with Moving Averages', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='best')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / 'forecast_timeseries_smoothed.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Clean up rolling stats columns for Prophet\n",
    "df_prophet = df_prophet[['ds', 'y']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split_section",
   "metadata": {},
   "source": [
    "## 3. Train/Validation Split\n",
    "\n",
    "Create temporal split for model validation before generating future forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/validation split\n",
    "train_df, validation_df = create_train_test_split(df_prophet, test_days=VALIDATION_DAYS)\n",
    "\n",
    "print(f\"Train set: {len(train_df)} days ({train_df['ds'].min().date()} to {train_df['ds'].max().date()})\")\n",
    "print(f\"Validation set: {len(validation_df)} days ({validation_df['ds'].min().date()} to {validation_df['ds'].max().date()})\")\n",
    "print(\"\\nTrain set statistics:\")\n",
    "print(train_df['y'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prophet_model_section",
   "metadata": {},
   "source": [
    "## 4. Prophet Model Training\n",
    "\n",
    "Train Prophet model on historical data with appropriate seasonality settings for crime data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configure_prophet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Prophet configuration for crime forecasting\n",
    "prophet_config = get_prophet_config(\n",
    "    seasonality_mode='multiplicative',  # Crime patterns scale with overall level\n",
    "    yearly=True,                         # Capture annual seasonality\n",
    "    weekly=True,                         # Capture day-of-week patterns\n",
    "    daily=False,                         # Daily data, no intraday patterns\n",
    "    changepoint_prior_scale=0.05,       # Moderate flexibility for trend changes\n",
    "    interval_width=CONFIDENCE_INTERVAL  # 95% prediction intervals\n",
    ")\n",
    "\n",
    "print(\"Prophet Configuration:\")\n",
    "for key, value in prophet_config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_prophet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train Prophet model on training data\n",
    "print(\"Training Prophet model...\")\n",
    "model = Prophet(**prophet_config)\n",
    "\n",
    "# Fit model on training set\n",
    "model.fit(train_df)\n",
    "\n",
    "print(f\"‚úì Model trained on {len(train_df)} days\")\n",
    "print(f\"  Date range: {train_df['ds'].min().date()} to {train_df['ds'].max().date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "validate_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on validation set\n",
    "validation_forecast = model.predict(validation_df[['ds']])\n",
    "\n",
    "# Evaluate model performance on validation set (use .values to avoid index mismatch)\n",
    "val_metrics = evaluate_forecast(\n",
    "    actual=validation_df['y'].values,\n",
    "    predicted=validation_forecast['yhat'].values,\n",
    "    lower=validation_forecast['yhat_lower'].values,\n",
    "    upper=validation_forecast['yhat_upper'].values\n",
    ")\n",
    "\n",
    "print(\"\\nValidation Set Performance:\")\n",
    "print(f\"  MAE: {val_metrics['mae']:.2f} incidents/day\")\n",
    "print(f\"  RMSE: {val_metrics['rmse']:.2f} incidents/day\")\n",
    "print(f\"  MAPE: {val_metrics['mape']:.2f}%\")\n",
    "print(f\"  R¬≤: {val_metrics['r2']:.4f}\")\n",
    "print(f\"  95% CI Coverage: {val_metrics['coverage']*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation results\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "# Plot actual values\n",
    "ax.plot(validation_df['ds'], validation_df['y'],\n",
    "        'o', markersize=3, label='Actual', alpha=0.6, color='black')\n",
    "\n",
    "# Plot predictions\n",
    "ax.plot(validation_forecast['ds'], validation_forecast['yhat'],\n",
    "        '-', linewidth=2, label='Predicted', color='blue')\n",
    "\n",
    "# Plot confidence intervals\n",
    "ax.fill_between(validation_forecast['ds'],\n",
    "                validation_forecast['yhat_lower'],\n",
    "                validation_forecast['yhat_upper'],\n",
    "                alpha=0.2, color='blue', label='95% CI')\n",
    "\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Daily Incident Count', fontsize=12)\n",
    "ax.set_title('Validation Set: Actual vs Predicted', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='best')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / 'forecast_validation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future_forecast_section",
   "metadata": {},
   "source": [
    "## 5. Generate Future Forecast\n",
    "\n",
    "Retrain on all available data and generate 60-day future forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_final_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on ALL data for future forecasting\n",
    "print(\"Training final model on all available data...\")\n",
    "final_model = Prophet(**prophet_config)\n",
    "final_model.fit(df_prophet)\n",
    "\n",
    "print(f\"‚úì Final model trained on {len(df_prophet)} days\")\n",
    "print(f\"  Date range: {df_prophet['ds'].min().date()} to {df_prophet['ds'].max().date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generate_forecast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create future dataframe for 60-day forecast\n",
    "future = final_model.make_future_dataframe(periods=FORECAST_HORIZON_DAYS, freq='D')\n",
    "\n",
    "print(f\"\\nGenerating {FORECAST_HORIZON_DAYS}-day forecast...\")\n",
    "forecast = final_model.predict(future)\n",
    "\n",
    "# Extract forecast period only\n",
    "forecast_future = forecast[forecast['ds'] > df_prophet['ds'].max()].copy()\n",
    "\n",
    "print(\"‚úì Forecast generated\")\n",
    "print(f\"  Forecast period: {forecast_future['ds'].min().date()} to {forecast_future['ds'].max().date()}\")\n",
    "print(f\"  Forecast days: {len(forecast_future)}\")\n",
    "print(\"\\nForecast Summary:\")\n",
    "print(f\"  Mean predicted incidents/day: {forecast_future['yhat'].mean():.1f}\")\n",
    "print(f\"  Range: {forecast_future['yhat'].min():.1f} to {forecast_future['yhat'].max():.1f}\")\n",
    "print(f\"  Lower bound (95% CI): {forecast_future['yhat_lower'].mean():.1f}\")\n",
    "print(f\"  Upper bound (95% CI): {forecast_future['yhat_upper'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metadata_capture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture execution metadata\n",
    "metadata = {\n",
    "    'version': VERSION,\n",
    "    'execution_timestamp': run_timestamp,\n",
    "    'forecast_horizon_days': FORECAST_HORIZON_DAYS,\n",
    "    'validation_days': VALIDATION_DAYS,\n",
    "    'confidence_interval': CONFIDENCE_INTERVAL,\n",
    "    'random_seed': RANDOM_SEED,\n",
    "    'data_source': str(crime_file),\n",
    "    'total_observations': len(df_prophet),\n",
    "    'train_observations': len(train_df),\n",
    "    'validation_observations': len(validation_df),\n",
    "    'date_range_start': str(df_prophet['ds'].min().date()),\n",
    "    'date_range_end': str(df_prophet['ds'].max().date()),\n",
    "    'mean_daily_incidents': float(df_prophet['y'].mean()),\n",
    "    'std_daily_incidents': float(df_prophet['y'].std())\n",
    "}\n",
    "\n",
    "print(\"\\nExecution metadata captured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anomaly_section",
   "metadata": {},
   "source": [
    "## 6. Anomaly Detection\n",
    "\n",
    "Define anomaly detection thresholds based on prediction intervals and identify unusual periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detect_anomalies_historical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate forecast for historical period to detect anomalies\n",
    "historical_forecast = final_model.predict(df_prophet[['ds']])\n",
    "\n",
    "# Merge actual values with forecast\n",
    "anomaly_df = df_prophet.merge(\n",
    "    historical_forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']],\n",
    "    on='ds'\n",
    ")\n",
    "\n",
    "# Detect anomalies\n",
    "anomaly_df['is_anomaly'] = detect_anomalies(\n",
    "    anomaly_df,\n",
    "    actual_col='y',\n",
    "    predicted_col='yhat',\n",
    "    lower_col='yhat_lower',\n",
    "    upper_col='yhat_upper',\n",
    "    threshold_std=2.0\n",
    ")\n",
    "\n",
    "# Summary statistics\n",
    "n_anomalies = anomaly_df['is_anomaly'].sum()\n",
    "anomaly_rate = (n_anomalies / len(anomaly_df)) * 100\n",
    "\n",
    "print(\"\\nAnomaly Detection Results:\")\n",
    "print(f\"  Total anomalies detected: {n_anomalies} days ({anomaly_rate:.2f}%)\")\n",
    "print(\"  Expected anomaly rate (outside 95% CI): ~5%\")\n",
    "\n",
    "# Show most extreme anomalies\n",
    "anomaly_df['residual'] = anomaly_df['y'] - anomaly_df['yhat']\n",
    "top_anomalies = anomaly_df[anomaly_df['is_anomaly']].nlargest(10, 'residual')[['ds', 'y', 'yhat', 'residual']]\n",
    "print(\"\\nTop 10 positive anomalies (higher than expected):\")\n",
    "for idx, row in top_anomalies.iterrows():\n",
    "    print(f\"  {row['ds'].date()}: {row['y']:.0f} incidents (expected {row['yhat']:.0f}, +{row['residual']:.0f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anomaly_thresholds",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define operational anomaly detection thresholds\n",
    "threshold_definitions = {\n",
    "    'Level 1 - Information': {\n",
    "        'description': 'Incident count above 95% upper bound',\n",
    "        'threshold': 'yhat_upper',\n",
    "        'action': 'Monitor - no immediate action required'\n",
    "    },\n",
    "    'Level 2 - Alert': {\n",
    "        'description': 'Incident count > 10% above upper bound',\n",
    "        'threshold': 'yhat_upper * 1.10',\n",
    "        'action': 'Review resource allocation for affected areas'\n",
    "    },\n",
    "    'Level 3 - Critical': {\n",
    "        'description': 'Incident count > 20% above upper bound',\n",
    "        'threshold': 'yhat_upper * 1.20',\n",
    "        'action': 'Immediate operational response - investigate root cause'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\nOperational Anomaly Detection Thresholds:\")\n",
    "print(\"=\"*70)\n",
    "for level, details in threshold_definitions.items():\n",
    "    print(f\"\\n{level}:\")\n",
    "    print(f\"  Definition: {details['description']}\")\n",
    "    print(f\"  Threshold: {details['threshold']}\")\n",
    "    print(f\"  Action: {details['action']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization_section",
   "metadata": {},
   "source": [
    "## 7. Final Forecast Visualization\n",
    "\n",
    "Create comprehensive visualization showing historical data, forecast, and confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_final_forecast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive forecast plot\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "# Plot last 180 days of historical data\n",
    "recent_days = 180\n",
    "df_recent = df_prophet.tail(recent_days)\n",
    "ax.plot(df_recent['ds'], df_recent['y'],\n",
    "        'o', markersize=2, label='Historical (last 180 days)', alpha=0.6, color='black')\n",
    "\n",
    "# Plot forecast period\n",
    "ax.plot(forecast_future['ds'], forecast_future['yhat'],\n",
    "        '-', linewidth=2.5, label='Forecast (60 days)', color='blue')\n",
    "\n",
    "# Plot 95% confidence intervals\n",
    "ax.fill_between(forecast_future['ds'],\n",
    "                forecast_future['yhat_lower'],\n",
    "                forecast_future['yhat_upper'],\n",
    "                alpha=0.3, color='blue', label='95% Confidence Interval')\n",
    "\n",
    "# Add vertical line at forecast start\n",
    "forecast_start = df_prophet['ds'].max()\n",
    "ax.axvline(forecast_start, color='red', linestyle='--', linewidth=1.5,\n",
    "           label='Forecast Start', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Date', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Daily Incident Count', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Crime Incidents: 60-Day Forecast with 95% Confidence Intervals',\n",
    "            fontsize=16, fontweight='bold', pad=20)\n",
    "ax.legend(loc='best', fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / 'forecast_60day_final.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Final forecast visualization saved to reports/forecast_60day_final.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_components",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot forecast components (trend and seasonality)\n",
    "fig = final_model.plot_components(forecast, figsize=(14, 10))\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORTS_DIR / 'forecast_components.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Forecast components visualization saved to reports/forecast_components.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_section",
   "metadata": {},
   "source": [
    "## 8. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final_summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final summary\n",
    "print(\"=\"*80)\n",
    "print(\"CRIME INCIDENTS FORECASTING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä DATA SUMMARY:\")\n",
    "print(f\"  Historical period: {df_prophet['ds'].min().date()} to {df_prophet['ds'].max().date()}\")\n",
    "print(f\"  Total observations: {len(df_prophet):,} days\")\n",
    "print(f\"  Average daily incidents: {df_prophet['y'].mean():.1f}\")\n",
    "print(f\"  Std deviation: {df_prophet['y'].std():.1f}\")\n",
    "\n",
    "print(\"\\nüîÆ FORECAST SUMMARY:\")\n",
    "print(f\"  Forecast horizon: {FORECAST_HORIZON_DAYS} days\")\n",
    "print(f\"  Forecast period: {forecast_future['ds'].min().date()} to {forecast_future['ds'].max().date()}\")\n",
    "print(f\"  Predicted avg daily incidents: {forecast_future['yhat'].mean():.1f}\")\n",
    "print(f\"  95% CI range: [{forecast_future['yhat_lower'].mean():.1f}, {forecast_future['yhat_upper'].mean():.1f}]\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  ANOMALY DETECTION:\")\n",
    "print(f\"  Anomalies detected: {n_anomalies} days ({anomaly_rate:.2f}%)\")\n",
    "print(\"  Operational thresholds: 3 levels defined (Info, Alert, Critical)\")\n",
    "\n",
    "print(\"\\nüìà MODEL PERFORMANCE (Validation Set):\")\n",
    "try:\n",
    "    print(f\"  MAE: {val_metrics['mae']:.2f} incidents/day\")\n",
    "    print(f\"  RMSE: {val_metrics['rmse']:.2f} incidents/day\")\n",
    "    print(f\"  MAPE: {val_metrics['mape']:.2f}%\")\n",
    "    print(f\"  R¬≤: {val_metrics['r2']:.4f}\")\n",
    "    print(f\"  95% CI Coverage: {val_metrics['coverage']*100:.1f}%\")\n",
    "except:\n",
    "    print(\"  (Validation metrics available in validation cells above)\")\n",
    "\n",
    "print(\"\\nüí° OPERATIONAL RECOMMENDATIONS:\")\n",
    "print(\"  1. Monitor daily incident counts against forecast upper bound\")\n",
    "print(\"  2. Investigate any Level 2+ anomalies (>10% above upper bound)\")\n",
    "print(\"  3. Update forecast weekly with new data for rolling predictions\")\n",
    "print(\"  4. Review forecast components for seasonal patterns in resource planning\")\n",
    "\n",
    "print(\"\\n‚úÖ REPRODUCIBILITY:\")\n",
    "print(f\"  Version: {VERSION}\")\n",
    "print(f\"  Random seed: {RANDOM_SEED}\")\n",
    "print(\"  Prophet config: multiplicative seasonality, yearly+weekly\")\n",
    "print(f\"  Confidence interval: {CONFIDENCE_INTERVAL*100}%\")\n",
    "\n",
    "execution_time = time.time() - start_time\n",
    "print(f\"\\n‚è±Ô∏è  EXECUTION TIME: {execution_time:.1f} seconds\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
