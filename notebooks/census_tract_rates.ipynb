{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title-cell",
   "metadata": {},
   "source": [
    "# Census Tract Crime Rates (HYP-SOCIO)\n",
    "\n",
    "**Objective:** Compute population-normalized crime rates at census tract level for socioeconomic hypothesis testing.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements census tract crime rate analysis to:\n",
    "1. Spatially join crime incidents to Census tract boundaries\n",
    "2. Compute per-100,000-resident crime rates (FBI UCR convention)\n",
    "3. Flag tracts with unreliable population data for future analysis exclusion\n",
    "4. Generate choropleth map showing crime rate distribution\n",
    "\n",
    "**Outputs:**\n",
    "- `reports/tract_crime_rates.png` - Choropleth map of crime rates by tract\n",
    "- `reports/tract_crime_rates.csv` - Summary statistics with rates and counts\n",
    "- `reports/tracts_with_rates.geojson` - GeoJSON for interactive mapping\n",
    "- `reports/flagged_tracts_report.md` - Documentation of unreliable tracts\n",
    "- `data/processed/tract_crime_rates.parquet` - Analysis-ready dataset for downstream use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parameters-cell",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters (can be injected by papermill)\n",
    "VERSION = \"v1.0\"\n",
    "FAST_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Robust repo_root detection: works from notebooks/ dir or project root\n",
    "cwd = Path.cwd()\n",
    "if (cwd / 'config' / 'phase2_config.yaml').exists():\n",
    "    repo_root = cwd  # Running from project root (papermill)\n",
    "elif (cwd.parent / 'config' / 'phase2_config.yaml').exists():\n",
    "    repo_root = cwd.parent  # Running from notebooks/ dir\n",
    "else:\n",
    "    raise RuntimeError(f\"Cannot find config from cwd={cwd}\")\n",
    "\n",
    "print(f\"DEBUG repo_root: {repo_root}\")\n",
    "sys.path.insert(0, str(repo_root))\n",
    "\n",
    "REPORTS_DIR = (repo_root / 'reports').resolve()\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PROCESSED_DIR = (repo_root / 'data' / 'processed').resolve()\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Reports dir: {REPORTS_DIR}\")\n",
    "print(f\"Processed data dir: {PROCESSED_DIR}\")\n",
    "\n",
    "artifacts = []\n",
    "RUNTIME_START = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reproducibility-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import platform\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from shapely.geometry import Point\n",
    "\n",
    "print(\"Reproducibility Info\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Timestamp (local): {datetime.now().isoformat()}\")\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"GeoPandas: {gpd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading-header",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-loading-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.utils import load_data, classify_crime_category\n",
    "from analysis.spatial_utils import load_boundaries, clean_coordinates\n",
    "from analysis.phase2_config_loader import load_phase2_config\n",
    "\n",
    "# Load configuration\n",
    "config = load_phase2_config()\n",
    "pop_col = config.census.population_column  # 'total_pop'\n",
    "rate_per = config.census.rate_per  # 100000 per UCR convention\n",
    "min_pop = config.census.min_population  # 100\n",
    "\n",
    "print(f\"Census Configuration:\")\n",
    "print(f\"  - Population column: {pop_col}\")\n",
    "print(f\"  - Rate per: {rate_per:,} (FBI UCR convention)\")\n",
    "print(f\"  - Minimum population threshold: {min_pop}\")\n",
    "\n",
    "# Load crime data\n",
    "df = load_data(clean=True)\n",
    "df = classify_crime_category(df)\n",
    "print(f\"\\nLoaded {len(df):,} crime records\")\n",
    "print(f\"Crime categories: {df['crime_category'].value_counts().to_dict()}\")\n",
    "\n",
    "# Load tract boundaries with population\n",
    "tracts_gdf = load_boundaries('census_tracts')\n",
    "print(f\"\\nCensus tracts loaded: {len(tracts_gdf)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "population-validation-header",
   "metadata": {},
   "source": [
    "## 2. Validate Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "population-validation-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Population column: {pop_col}\")\n",
    "print(f\"\\nPopulation statistics:\")\n",
    "print(tracts_gdf[pop_col].describe())\n",
    "\n",
    "# Check for missing/zero population\n",
    "zero_pop = (tracts_gdf[pop_col] == 0).sum()\n",
    "low_pop_count = (tracts_gdf[pop_col] < min_pop).sum()\n",
    "null_pop = tracts_gdf[pop_col].isna().sum()\n",
    "\n",
    "print(f\"\\nTracts with zero population: {zero_pop}\")\n",
    "print(f\"Tracts with population < {min_pop}: {low_pop_count}\")\n",
    "print(f\"Tracts with null population: {null_pop}\")\n",
    "\n",
    "total_pop = tracts_gdf[pop_col].sum()\n",
    "print(f\"\\nTotal population across all tracts: {total_pop:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-join-header",
   "metadata": {},
   "source": [
    "## 3. Spatial Join - Crimes to Census Tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-prep-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean coordinates (filter to valid Philadelphia bounds)\n",
    "df_coords = clean_coordinates(df, x_col='point_x', y_col='point_y')\n",
    "print(f\"Records with valid coordinates: {len(df_coords):,} ({len(df_coords)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Create GeoDataFrame from crime data\n",
    "geometry = [Point(xy) for xy in zip(df_coords['point_x'], df_coords['point_y'])]\n",
    "crimes_gdf = gpd.GeoDataFrame(df_coords, geometry=geometry, crs=\"EPSG:4326\")\n",
    "print(f\"\\nCreated GeoDataFrame with {len(crimes_gdf):,} crime points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-join-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both have same CRS\n",
    "if tracts_gdf.crs != crimes_gdf.crs:\n",
    "    tracts_gdf = tracts_gdf.to_crs(crimes_gdf.crs)\n",
    "\n",
    "# Perform spatial join - join crimes to tracts\n",
    "print(\"Performing spatial join (this may take a moment)...\")\n",
    "crimes_with_tract = gpd.sjoin(\n",
    "    crimes_gdf, \n",
    "    tracts_gdf[['GEOID', pop_col, 'geometry']], \n",
    "    how='left', \n",
    "    predicate='within'\n",
    ")\n",
    "\n",
    "# Check join success rate\n",
    "joined_count = crimes_with_tract['GEOID'].notna().sum()\n",
    "joined_pct = joined_count / len(crimes_with_tract) * 100\n",
    "print(f\"\\nCrimes joined to tracts: {joined_count:,} ({joined_pct:.1f}%)\")\n",
    "\n",
    "# Handle unjoined (may be outside Philadelphia boundaries or in water)\n",
    "unjoined = crimes_with_tract['GEOID'].isna().sum()\n",
    "if unjoined > 0:\n",
    "    print(f\"Unjoined crimes (outside tract boundaries): {unjoined:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregation-header",
   "metadata": {},
   "source": [
    "## 4. Calculate Crime Counts by Tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregation-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total crimes per tract\n",
    "tract_crimes = crimes_with_tract.groupby('GEOID').size().reset_index(name='total_crimes')\n",
    "\n",
    "# Crimes by category\n",
    "tract_category = crimes_with_tract.groupby(['GEOID', 'crime_category']).size().unstack(fill_value=0)\n",
    "tract_category.columns = [f'{col.lower()}_crimes' for col in tract_category.columns]\n",
    "tract_category = tract_category.reset_index()\n",
    "\n",
    "# Merge total and category counts\n",
    "tract_stats = tract_crimes.merge(tract_category, on='GEOID', how='left')\n",
    "\n",
    "print(f\"Tracts with crime data: {len(tract_stats)}\")\n",
    "print(f\"\\nTotal crimes by category:\")\n",
    "for col in [c for c in tract_stats.columns if c.endswith('_crimes') and c != 'total_crimes']:\n",
    "    print(f\"  - {col}: {tract_stats[col].sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rate-calculation-header",
   "metadata": {},
   "source": [
    "## 5. Calculate Crime Rates (per 100,000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rate-calculation-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge population data\n",
    "tract_stats = tract_stats.merge(\n",
    "    tracts_gdf[['GEOID', pop_col]], \n",
    "    on='GEOID', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calculate rate per 100,000\n",
    "tract_stats['crime_rate'] = (tract_stats['total_crimes'] / tract_stats[pop_col]) * rate_per\n",
    "\n",
    "# Calculate category-specific rates\n",
    "for col in [c for c in tract_stats.columns if c.endswith('_crimes') and c != 'total_crimes']:\n",
    "    rate_col = col.replace('_crimes', '_rate')\n",
    "    tract_stats[rate_col] = (tract_stats[col] / tract_stats[pop_col]) * rate_per\n",
    "\n",
    "print(f\"Crime rate statistics (per {rate_per:,}):\")\n",
    "print(tract_stats['crime_rate'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flagging-header",
   "metadata": {},
   "source": [
    "## 6. Flag Unreliable Tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flagging-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag tracts below minimum population threshold\n",
    "tract_stats['low_population'] = tract_stats[pop_col] < min_pop\n",
    "tract_stats['zero_population'] = tract_stats[pop_col] == 0\n",
    "\n",
    "# Calculate reliability flag\n",
    "tract_stats['rate_reliable'] = ~tract_stats['low_population']\n",
    "\n",
    "unreliable_count = tract_stats['low_population'].sum()\n",
    "print(f\"Tracts flagged as unreliable (pop < {min_pop}): {unreliable_count}\")\n",
    "\n",
    "# Handle infinite rates from zero population\n",
    "tract_stats.loc[tract_stats['zero_population'], 'crime_rate'] = np.nan\n",
    "for col in [c for c in tract_stats.columns if c.endswith('_rate')]:\n",
    "    tract_stats.loc[tract_stats['zero_population'], col] = np.nan\n",
    "\n",
    "# Document flagged tracts\n",
    "flagged_tracts = tract_stats[tract_stats['low_population']][['GEOID', pop_col, 'total_crimes']].copy()\n",
    "if len(flagged_tracts) > 0:\n",
    "    print(f\"\\nFlagged tracts (unreliable rates):\")\n",
    "    print(flagged_tracts.to_string(index=False))\n",
    "else:\n",
    "    print(f\"\\nNo tracts flagged as unreliable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choropleth-header",
   "metadata": {},
   "source": [
    "## 7. Choropleth Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "merge-rates-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge rates to boundaries for mapping\n",
    "tracts_with_rates = tracts_gdf.merge(tract_stats, on='GEOID', how='left')\n",
    "\n",
    "# Fill NaN for tracts with no crimes\n",
    "tracts_with_rates['total_crimes'] = tracts_with_rates['total_crimes'].fillna(0)\n",
    "tracts_with_rates['crime_rate'] = tracts_with_rates['crime_rate'].fillna(0)\n",
    "tracts_with_rates['rate_reliable'] = tracts_with_rates['rate_reliable'].fillna(True)\n",
    "tracts_with_rates['low_population'] = tracts_with_rates['low_population'].fillna(False)\n",
    "\n",
    "print(f\"Merged {len(tracts_with_rates)} tracts with rate data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choropleth-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 12))\n",
    "\n",
    "# Filter to reliable tracts for color scaling\n",
    "reliable_mask = tracts_with_rates['rate_reliable'] == True\n",
    "reliable_rates = tracts_with_rates.loc[reliable_mask, 'crime_rate']\n",
    "\n",
    "# Use quantiles for robust color scaling (avoid outlier influence)\n",
    "vmin = reliable_rates.quantile(0.05)\n",
    "vmax = reliable_rates.quantile(0.95)\n",
    "\n",
    "# Yellow-Orange-Red colormap\n",
    "colors = ['#FFFFE0', '#FFEDA0', '#FED976', '#FEB24C', '#FD8D3C', '#FC4E2A', '#E31A1C', '#B10026']\n",
    "cmap = LinearSegmentedColormap.from_list('YlOrRd', colors)\n",
    "\n",
    "# Plot reliable tracts with color scale\n",
    "tracts_with_rates[reliable_mask].plot(\n",
    "    column='crime_rate', \n",
    "    cmap=cmap, \n",
    "    linewidth=0.3, \n",
    "    edgecolor='gray', \n",
    "    legend=True, \n",
    "    ax=ax,\n",
    "    vmin=vmin, \n",
    "    vmax=vmax,\n",
    "    legend_kwds={'label': f'Crime Rate (per {rate_per:,})', 'orientation': 'horizontal'}\n",
    ")\n",
    "\n",
    "# Plot unreliable tracts in gray\n",
    "unreliable_mask = tracts_with_rates['rate_reliable'] == False\n",
    "if unreliable_mask.sum() > 0:\n",
    "    tracts_with_rates[unreliable_mask].plot(\n",
    "        color='lightgray', \n",
    "        linewidth=0.3, \n",
    "        edgecolor='gray', \n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "ax.set_title('Philadelphia Crime Rates by Census Tract\\n(Gray = low population, rates unreliable)', fontsize=14)\n",
    "ax.set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "png_path = REPORTS_DIR / 'tract_crime_rates.png'\n",
    "plt.savefig(png_path, dpi=300, bbox_inches='tight')\n",
    "artifacts.append(('tract_crime_rates.png', 'Census tract crime rate choropleth'))\n",
    "print(f\"\\nSaved: {png_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "top-bottom-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to reliable tracts only\n",
    "reliable_tracts = tract_stats[tract_stats['rate_reliable'] == True].copy()\n",
    "\n",
    "print(\"Top 10 Tracts by Crime Rate:\")\n",
    "top_10 = reliable_tracts.nlargest(10, 'crime_rate')[['GEOID', pop_col, 'total_crimes', 'crime_rate']]\n",
    "print(top_10.to_string(index=False))\n",
    "\n",
    "print(\"\\nBottom 10 Tracts by Crime Rate (lowest crime areas):\")\n",
    "bottom_10 = reliable_tracts.nsmallest(10, 'crime_rate')[['GEOID', pop_col, 'total_crimes', 'crime_rate']]\n",
    "print(bottom_10.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distribution-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rate distribution for reliable tracts\n",
    "rate_stats = {\n",
    "    'Total tracts': len(tracts_gdf),\n",
    "    'Tracts with crimes': len(tract_stats),\n",
    "    'Reliable tracts': len(reliable_tracts),\n",
    "    'Flagged tracts': unreliable_count,\n",
    "    'Mean rate': reliable_tracts['crime_rate'].mean(),\n",
    "    'Median rate': reliable_tracts['crime_rate'].median(),\n",
    "    'Std rate': reliable_tracts['crime_rate'].std(),\n",
    "    'Min rate': reliable_tracts['crime_rate'].min(),\n",
    "    'Max rate': reliable_tracts['crime_rate'].max()\n",
    "}\n",
    "\n",
    "print(\"\\nRate Distribution Summary:\")\n",
    "for k, v in rate_stats.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"  {k}: {v:,.1f}\")\n",
    "    else:\n",
    "        print(f\"  {k}: {v:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export-header",
   "metadata": {},
   "source": [
    "## 9. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-csv-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export full results\n",
    "output_cols = ['GEOID', pop_col, 'total_crimes', 'crime_rate', \n",
    "               'violent_crimes', 'violent_rate', 'property_crimes', 'property_rate',\n",
    "               'other_crimes', 'other_rate',\n",
    "               'low_population', 'rate_reliable']\n",
    "               \n",
    "# Filter to columns that exist\n",
    "output_cols = [c for c in output_cols if c in tract_stats.columns]\n",
    "tract_export = tract_stats[output_cols].copy()\n",
    "\n",
    "# Save CSV\n",
    "csv_path = REPORTS_DIR / 'tract_crime_rates.csv'\n",
    "tract_export.to_csv(csv_path, index=False)\n",
    "artifacts.append(('tract_crime_rates.csv', 'Tract crime rates and counts'))\n",
    "print(f\"Saved: {csv_path}\")\n",
    "print(f\"  - Rows: {len(tract_export)}\")\n",
    "print(f\"  - Columns: {output_cols}\")\n",
    "\n",
    "# Save as parquet for downstream analysis\n",
    "parquet_path = PROCESSED_DIR / 'tract_crime_rates.parquet'\n",
    "tract_export.to_parquet(parquet_path)\n",
    "artifacts.append(('data/processed/tract_crime_rates.parquet', 'Parquet for downstream analysis'))\n",
    "print(f\"\\nSaved: {parquet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-geojson-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as GeoJSON for interactive mapping\n",
    "# Select relevant columns for export\n",
    "geojson_cols = ['GEOID', 'NAME_x', pop_col, 'total_crimes', 'crime_rate', \n",
    "                'rate_reliable', 'geometry']\n",
    "geojson_cols = [c for c in geojson_cols if c in tracts_with_rates.columns]\n",
    "\n",
    "geojson_path = REPORTS_DIR / 'tracts_with_rates.geojson'\n",
    "tracts_with_rates[geojson_cols].to_file(geojson_path, driver='GeoJSON')\n",
    "artifacts.append(('tracts_with_rates.geojson', 'GeoJSON with crime rates'))\n",
    "print(f\"Saved: {geojson_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-flagged-report-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate flagged tracts report\n",
    "flagged_report = f\"\"\"# Flagged Census Tracts Report\n",
    "\n",
    "## Summary\n",
    "\n",
    "- Total census tracts: {len(tracts_gdf)}\n",
    "- Tracts with reliable population (>= {min_pop}): {len(reliable_tracts)}\n",
    "- Tracts flagged as unreliable: {unreliable_count}\n",
    "\n",
    "## Methodology\n",
    "\n",
    "Crime rates are calculated per {rate_per:,} residents (FBI UCR convention).\n",
    "Tracts with population below {min_pop} are flagged as unreliable because:\n",
    "- Small population denominators produce unstable rates\n",
    "- May represent non-residential areas (parks, industrial zones)\n",
    "- Statistical inference unreliable with small populations\n",
    "\n",
    "## Flagged Tracts (population < {min_pop})\n",
    "\n",
    "| GEOID | Population | Total Crimes | Note |\n",
    "|-------|------------|--------------|------|\n",
    "\"\"\"\n",
    "\n",
    "for _, row in flagged_tracts.iterrows():\n",
    "    pop_val = row[pop_col]\n",
    "    note = \"Zero pop\" if pop_val == 0 else f\"Low pop ({int(pop_val)})\"\n",
    "    flagged_report += f\"| {row['GEOID']} | {int(pop_val)} | {int(row['total_crimes'])} | {note} |\\n\"\n",
    "\n",
    "if len(flagged_tracts) == 0:\n",
    "    flagged_report += \"| (none) | - | - | All tracts have reliable population |\\n\"\n",
    "\n",
    "flagged_report += f\"\"\"\n",
    "## Recommendation\n",
    "\n",
    "Exclude flagged tracts from rate-based analyses. Use raw counts instead for these tracts.\n",
    "For socioeconomic hypothesis testing, focus on the {len(reliable_tracts)} reliable tracts.\n",
    "\n",
    "---\n",
    "*Generated: {datetime.now().isoformat()}*\n",
    "\"\"\"\n",
    "\n",
    "report_path = REPORTS_DIR / 'flagged_tracts_report.md'\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(flagged_report)\n",
    "    \n",
    "artifacts.append(('flagged_tracts_report.md', 'Unreliable tract documentation'))\n",
    "print(f\"Saved: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusions-header",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conclusions-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CENSUS TRACT CRIME RATE ANALYSIS FINDINGS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n**Data Coverage:**\")\n",
    "print(f\"  - Total crime records: {len(df):,}\")\n",
    "print(f\"  - Records with valid coordinates: {len(df_coords):,} ({len(df_coords)/len(df)*100:.1f}%)\")\n",
    "print(f\"  - Successfully joined to tracts: {joined_count:,} ({joined_pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\n**Census Tract Summary:**\")\n",
    "print(f\"  - Total census tracts: {len(tracts_gdf)}\")\n",
    "print(f\"  - Tracts with crime data: {len(tract_stats)}\")\n",
    "print(f\"  - Reliable tracts (pop >= {min_pop}): {len(reliable_tracts)}\")\n",
    "print(f\"  - Flagged tracts: {unreliable_count}\")\n",
    "\n",
    "print(f\"\\n**Crime Rate Distribution (per {rate_per:,}, reliable tracts only):**\")\n",
    "print(f\"  - Mean: {reliable_tracts['crime_rate'].mean():,.1f}\")\n",
    "print(f\"  - Median: {reliable_tracts['crime_rate'].median():,.1f}\")\n",
    "print(f\"  - Std Dev: {reliable_tracts['crime_rate'].std():,.1f}\")\n",
    "print(f\"  - Range: {reliable_tracts['crime_rate'].min():,.1f} to {reliable_tracts['crime_rate'].max():,.1f}\")\n",
    "\n",
    "# Calculate coefficient of variation for rate disparity\n",
    "cv = reliable_tracts['crime_rate'].std() / reliable_tracts['crime_rate'].mean() * 100\n",
    "print(f\"  - Coefficient of variation: {cv:.1f}%\")\n",
    "\n",
    "print(f\"\\n**Recommendations for Socioeconomic Analysis (HYP-SOCIO):**\")\n",
    "print(f\"  1. Use the {len(reliable_tracts)} reliable tracts for correlation analysis\")\n",
    "print(f\"  2. Exclude {unreliable_count} flagged tracts from rate-based comparisons\")\n",
    "print(f\"  3. Consider log-transforming rates for normality in statistical tests\")\n",
    "print(f\"  4. High CV ({cv:.1f}%) suggests significant spatial inequality for policy analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completion-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NOTEBOOK COMPLETE: Census Tract Crime Rates (HYP-SOCIO)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nArtifacts generated:\")\n",
    "for name, desc in artifacts:\n",
    "    print(f\"  - {name}: {desc}\")\n",
    "print(f\"\\nRuntime: {time.time() - RUNTIME_START:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validation-cell",
   "metadata": {},
   "source": [
    "## Validation Checklist\n",
    "\n",
    "- [x] Notebook executes end-to-end without errors\n",
    "- [x] Reproducibility cell present with version info\n",
    "- [x] `reports/tract_crime_rates.png` exists at 300 DPI\n",
    "- [x] Choropleth shows reliable tracts in color, unreliable in gray\n",
    "- [x] `reports/tract_crime_rates.csv` contains GEOID, population, counts, and rates\n",
    "- [x] `data/processed/tract_crime_rates.parquet` exists for downstream use\n",
    "- [x] `reports/flagged_tracts_report.md` documents unreliable tracts\n",
    "- [x] Rate per 100,000 used (matching FBI UCR convention)\n",
    "- [x] Spatial join success rate > 95%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
