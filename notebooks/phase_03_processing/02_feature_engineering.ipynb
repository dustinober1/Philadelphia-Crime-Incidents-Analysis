{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Processing - Feature Engineering\n",
    "\n",
    "## Overview\n",
    "\n",
    "Create analytical features for robust analysis and modeling.\n",
    "\n",
    "### Objectives\n",
    "1. Extract temporal features (month, day of week, season, holidays)\n",
    "2. Create spatial features (zone classification, distance to center)\n",
    "3. Generate aggregate lookup tables\n",
    "4. Create time-based resampling (daily/weekly/monthly)\n",
    "5. Prepare enriched dataset for analysis phases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.data import loader\n",
    "from src.utils.config import get_processed_data_path\n",
    "\n",
    "print(\"Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned data\n",
    "processed_path = get_processed_data_path()\n",
    "cleaned_file = processed_path / \"crime_incidents_cleaned.parquet\"\n",
    "\n",
    "if cleaned_file.exists():\n",
    "    df = pd.read_parquet(cleaned_file)\n    print(f\"Loaded {len(df):,} cleaned records\")\nelse:\n",
    "    # Fallback to combined data\n",
    "    df = loader.load_crime_data()\n    print(f\"Using combined data: {len(df):,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Extract Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating temporal features...\\n\")\n",
    "\n",
    "if 'date' in df.columns:\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Extract basic temporal features\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['quarter'] = df['date'].dt.quarter\n",
    "    df['day_of_week'] = df['date'].dt.day_name()\n",
    "    df['week_number'] = df['date'].dt.isocalendar().week.astype('int16')\n",
    "    \n",
    "    # Create derived features\n",
    "    df['is_weekend'] = df['day_of_week'].isin(['Saturday', 'Sunday']).astype('int8')\n",
    "    \n",
    "    # Season mapping\n",
    "    season_map = {\n",
    "        12: 'Winter', 1: 'Winter', 2: 'Winter',\n",
    "        3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
    "        6: 'Summer', 7: 'Summer', 8: 'Summer',\n",
    "        9: 'Fall', 10: 'Fall', 11: 'Fall'\n",
    "    }\n",
    "    df['season'] = df['month'].map(season_map)\n",
    "    \n",
    "    # Year-month combination\n",
    "    df['year_month'] = df['date'].dt.strftime('%Y-%m')\n",
    "    \n",
    "    print(\"✓ Temporal features created:\")\n",
    "    print(f\"  - year, month, day, quarter, week_number\")\n",
    "    print(f\"  - day_of_week, is_weekend, season\")\n",
    "    print(f\"  - year_month\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Create Spatial Features"
   ]
  },
  {
   "cell_type": {"cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Create Spatial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCreating spatial features...\\n\")\n",
    "\n",
    "if 'latitude' in df.columns and 'longitude' in df.columns:\n",
    "    # Philadelphia city center (approximate)\n",
    "    CENTER_LAT, CENTER_LON = 39.95, -75.17\n",
    "    \n",
    "    # Calculate distance to center (simple Euclidean, for grouping)\n",
    "    df['dist_to_center'] = np.sqrt(\n",
    "        (df['latitude'] - CENTER_LAT)**2 + \n",
    "        (df['longitude'] - CENTER_LON)**2\n",
    "    )\n",
    "    \n",
    "    # Create zone classification based on distance\n",
    "    df['zone'] = pd.cut(df['dist_to_center'], \n",
    "                        bins=[0, 0.02, 0.04, 0.06, np.inf],\n",
    "                        labels=['Inner', 'Middle', 'Outer', 'Fringe'])\n",
    "    \n",
    "    print(\"✓ Spatial features created:\")\n",
    "    print(f\"  - dist_to_center\")\n",
    "    print(f\"  - zone (Inner, Middle, Outer, Fringe)\")\n",
    "    print(f\"\\nZone distribution:\")\n",
    "    print(df['zone'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Create Aggregates and Lookup Tables"
   ]
  },
  {
   "cell_type": {"cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Create Aggregates and Lookup Tables"
   ]
  },
  {
   "cell_type": {"cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Create Aggregates and Lookup Tables"
   ]
  },
  {
   "cell_type": {"cell_type": {"cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Create Aggregates and Lookup Tables"
   ]
  },
  {
   "cell_type": {"cell_type": {"cell_type": {"cell_type": {"cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Create Aggregates and Lookup Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCreating aggregates...\\n\")\n",
    "\n",
    "# Daily crime counts\n",
    "if 'date' in df.columns:\n",
    "    daily_crimes = df.groupby('date').size().to_frame('incident_count')\n",
    "    daily_crimes_file = processed_path / \"daily_crime_counts.parquet\"\n",
    "    daily_crimes.to_parquet(daily_crimes_file)\n",
    "    print(f\"✓ Daily aggregates: {len(daily_crimes)} days\")\n",
    "\n",
    "# Monthly totals by crime type\n",
    "if 'general_crime_category' in df.columns and 'year_month' in df.columns:\n",
    "    monthly_by_type = df.groupby(['year_month', 'general_crime_category']).size().reset_index(name='count')\n",
    "    monthly_by_type_file = processed_path / \"monthly_crime_by_type.parquet\"\n",
    "    monthly_by_type.to_parquet(monthly_by_type_file)\n",
    "    print(f\"✓ Monthly by crime type: {len(monthly_by_type)} records\")\n",
    "\n",
    "# District statistics\n",
    "if 'district' in df.columns:\n",
    "    district_stats = df.groupby('district').agg({\n",
    "        'date': 'count',\n",
    "        'latitude': 'mean',\n",
    "        'longitude': 'mean'\n",
    "    }).rename(columns={'date': 'total_incidents'})\n",
    "    district_stats_file = processed_path / \"district_stats.parquet\"\n",
    "    district_stats.to_parquet(district_stats_file)\n",
    "    print(f\"✓ District statistics: {len(district_stats)} districts\")\n\nprint(\"\\n✓ Aggregates created and saved\")"
   ]
  },
  {
   "cell_type": {"cell_type": \"markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Save Enriched Dataset"
   ]
  },
  {
   "cell_type": {"cell_type": \"code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the enriched dataset\n",
    "enriched_file = processed_path / \"crime_incidents_enriched.parquet\"\n",
    "\n",
    "df.to_parquet(enriched_file, engine='pyarrow', compression='snappy')\n",
    "\n",
    "file_size_mb = enriched_file.stat().st_size / 1024**2\n",
    "print(f\"✓ Enriched data saved to {enriched_file}\")\n",
    "print(f\"  File size: {file_size_mb:.2f} MB\")\n",
    "print(f\"  Records: {len(df):,}\")\n",
    "print(f\"  Columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": {"cell_type": \"markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "✓ **Feature engineering complete!**\n",
    "\n",
    "### Features Created\n",
    "- **Temporal**: year, month, day, quarter, week, day_of_week, is_weekend, season, year_month\n",
    "- **Spatial**: dist_to_center, zone\n",
    "- **Aggregates**: daily counts, monthly by type, district statistics\n",
    "\n",
    "### Output Files\n",
    "- `crime_incidents_enriched.parquet` — Main enriched dataset\n",
    "- `daily_crime_counts.parquet` — Daily time series\n",
    "- `monthly_crime_by_type.parquet` — Monthly aggregates by crime type\n",
    "- `district_stats.parquet` — District-level statistics\n",
    "\n",
    "### Next Steps\n",
    "- Proceed to **Phase 4: Analysis** for temporal, categorical, and statistical exploration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
