{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Exploration - Data Quality Assessment\n",
    "\n",
    "## Overview\n",
    "\n",
    "Assess data quality, identify issues, and document findings for cleaning.\n",
    "\n",
    "### Objectives\n",
    "1. Identify missing values\n",
    "2. Detect duplicate records\n",
    "3. Find outliers and anomalies\n",
    "4. Validate geographic coordinates\n",
    "5. Check categorical consistency\n",
    "6. Document quality issues for Phase 3 cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.data import loader\n",
    "from src.analysis import profiler\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loader.load_crime_data()\n",
    "print(f\"Loaded {len(df):,} crime records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (df.isnull().sum() / len(df) * 100).round(2)\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing.index,\n",
    "    'Missing Count': missing.values,\n",
    "    'Missing %': missing_pct.values\n",
    "}).sort_values('Missing Count', ascending=False)\n",
    "\n",
    "print(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "if missing_df['Missing Count'].max() == 0:\n",
    "    print(\"\\n✓ No missing values found\")\n",
    "else:\n",
    "    print(f\"\\n⚠ Found {(missing > 0).sum()} columns with missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Duplicate Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DUPLICATE DETECTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total_rows = len(df)\n",
    "duplicate_rows = df.duplicated().sum()\n",
    "duplicate_pct = (duplicate_rows / total_rows * 100) if total_rows > 0 else 0\n",
    "\n",
    "print(f\"Total rows: {total_rows:,}\")\n",
    "print(f\"Duplicate rows: {duplicate_rows:,} ({duplicate_pct:.2f}%)\")\n",
    "\n",
    "# Check for duplicates across specific columns\n",
    "if 'id' in df.columns:\n",
    "    duplicate_ids = df['id'].duplicated().sum()\n",
    "    print(f\"Duplicate IDs: {duplicate_ids:,}\")\n",
    "\n",
    "if duplicate_rows == 0:\n",
    "    print(\"\\n✓ No complete duplicates found\")\n",
    "else:\n",
    "    print(f\"\\n⚠ Found {duplicate_rows:,} duplicate rows to investigate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Outlier Detection (Numeric Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"OUTLIER DETECTION (IQR Method)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "for col in numeric_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    \n",
    "    if len(outliers) > 0:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Range: {df[col].min()} to {df[col].max()}\")\n",
    "        print(f\"  IQR bounds: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "        print(f\"  Outliers: {len(outliers):,} ({len(outliers)/len(df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Geographic Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"GEOGRAPHIC COORDINATE VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Philadelphia geographic bounds (approximate)\n",
    "PHI_LAT_MIN, PHI_LAT_MAX = 39.8, 40.1\n",
    "PHI_LON_MIN, PHI_LON_MAX = -75.3, -74.9\n",
    "\n",
    "if 'latitude' in df.columns and 'longitude' in df.columns:\n",
    "    print(f\"Latitude range: {df['latitude'].min():.4f} to {df['latitude'].max():.4f}\")\n",
    "    print(f\"Longitude range: {df['longitude'].min():.4f} to {df['longitude'].max():.4f}\")\n",
    "    \n",
    "    invalid_coords = df[\n",
    "        (df['latitude'] < PHI_LAT_MIN) | (df['latitude'] > PHI_LAT_MAX) |\n",
    "        (df['longitude'] < PHI_LON_MIN) | (df['longitude'] > PHI_LON_MAX)\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nPhiladelphia bounds: Lat [{PHI_LAT_MIN}, {PHI_LAT_MAX}], Lon [{PHI_LON_MIN}, {PHI_LON_MAX}]\")\n",
    "    print(f\"Records outside bounds: {len(invalid_coords):,} ({len(invalid_coords)/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    if len(invalid_coords) > 0:\n",
    "        print(f\"\\n⚠ Found {len(invalid_coords):,} records with invalid coordinates\")\n",
    "    else:\n",
    "        print(\"\\n✓ All coordinates within Philadelphia bounds\")\nelse:\n",
    "    print(\"⚠ Latitude/longitude columns not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Categorical Consistency"
   ]
  },
  {
   "cell_type": {"cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Categorical Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CATEGORICAL CONSISTENCY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check key categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "for col in categorical_cols:\n",
    "    unique_count = df[col].nunique()\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Unique values: {unique_count}\")\n",
    "    \n",
    "    # Show top values\n",
    "    top_values = df[col].value_counts().head(5)\n",
    "    for val, count in top_values.items():\n",
    "        print(f\"    {val}: {count:,}\")\n",
    "    \n",
    "    if unique_count > 5:\n",
    "        print(f\"    ... and {unique_count - 5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA QUALITY SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "quality_issues = []\n",
    "\n",
    "# Check for issues\n",
    "if df.isnull().sum().sum() > 0:\n",
    "    quality_issues.append(\"✗ Missing values detected\")\nelse:\n",
    "    quality_issues.append(\"✓ No missing values\")\n",
    "\n",
    "if df.duplicated().sum() > 0:\n",
    "    quality_issues.append(f\"✗ {df.duplicated().sum():,} duplicate rows found\")\nelse:\n",
    "    quality_issues.append(\"✓ No duplicates\")\n",
    "\n",
    "print(\"\\n\".join(quality_issues))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"✓ Quality assessment complete\")\n",
    "print(\"→ Proceed to Phase 3: Processing (01_data_cleaning.ipynb)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
