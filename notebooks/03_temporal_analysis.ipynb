{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Analysis of Philadelphia Crime Incidents (2006-2026)\n",
    "\n",
    "**Purpose:** Comprehensive temporal analysis including 20-year trends, seasonal decomposition, day/hour patterns, and crime-type-specific trends.\n",
    "\n",
    "**Requirements Addressed:** TEMP-01 through TEMP-07\n",
    "\n",
    "**Notebook Structure:**\n",
    "1. Data Preparation and Time Series Construction\n",
    "2. STL Decomposition and Seasonal Analysis\n",
    "3. Day/Hour Patterns and Crime-Type Trends\n",
    "4. Summary and Key Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation and Time Series Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Statistical libraries\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from scipy import stats\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Configuration\n",
    "sys.path.append('../scripts')\n",
    "from config import (\n",
    "    PROCESSED_DATA_DIR, FIGURES_DIR, TABLES_DIR,\n",
    "    COL_DATE, COL_UCR_GENERAL, COL_TEXT_GENERAL,\n",
    "    PALETTE_SEQUENTIAL, FIG_SIZE_FULL, FIG_SIZE_HALF\n",
    ")\n",
    "\n",
    "# Ensure output directories exist\n",
    "output_figures = Path('../output/figures/temporal')\n",
    "output_tables = Path('../output/tables/temporal')\n",
    "output_figures.mkdir(parents=True, exist_ok=True)\n",
    "output_tables.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"✓ Imports and configuration loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure matplotlib for publication quality\n",
    "plt.rcParams.update({\n",
    "    'figure.dpi': 300,\n",
    "    'savefig.dpi': 300,\n",
    "    'font.size': 10,\n",
    "    'axes.labelsize': 11,\n",
    "    'axes.titlesize': 12,\n",
    "    'xtick.labelsize': 9,\n",
    "    'ytick.labelsize': 9,\n",
    "    'legend.fontsize': 9,\n",
    "    'figure.figsize': (12, 8),\n",
    "})\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "print(\"✓ Matplotlib configured for publication quality (300 DPI)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data\n",
    "df = pd.read_parquet(PROCESSED_DATA_DIR / 'crime_incidents_cleaned.parquet')\n",
    "\n",
    "print(f\"✓ Loaded {len(df):,} records\")\n",
    "print(f\"\\nData columns: {list(df.columns)}\")\n",
    "print(f\"\\nDate range: {df[COL_DATE].min()} to {df[COL_DATE].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure datetime format and exclude last 30 days (reporting lag)\n",
    "df[COL_DATE] = pd.to_datetime(df[COL_DATE])\n",
    "\n",
    "# Exclude last 30 days to avoid under-reporting bias\n",
    "cutoff_date = df[COL_DATE].max() - pd.Timedelta(days=30)\n",
    "df_analysis = df[df[COL_DATE] <= cutoff_date].copy()\n",
    "\n",
    "print(f\"Original records: {len(df):,}\")\n",
    "print(f\"After excluding last 30 days: {len(df_analysis):,}\")\n",
    "print(f\"Analysis period: {df_analysis[COL_DATE].min().strftime('%Y-%m-%d')} to {df_analysis[COL_DATE].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"Excluded {len(df) - len(df_analysis):,} recent records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiple time series aggregations\n",
    "\n",
    "# Set datetime as index for resampling\n",
    "df_ts = df_analysis.set_index(COL_DATE)\n",
    "\n",
    "# 1. Monthly counts (for STL decomposition)\n",
    "monthly_counts = df_ts.resample('ME').size()\n",
    "monthly_counts.name = 'crime_count'\n",
    "\n",
    "# 2. Annual counts (for long-term trends)\n",
    "annual_counts = df_ts.resample('YE').size()\n",
    "annual_counts.name = 'crime_count'\n",
    "\n",
    "# 3. Weekly counts (for medium-term patterns)\n",
    "weekly_counts = df_ts.resample('W').size()\n",
    "weekly_counts.name = 'crime_count'\n",
    "\n",
    "print(\"Time series created:\")\n",
    "print(f\"  Monthly: {len(monthly_counts)} observations ({monthly_counts.index.min().strftime('%Y-%m')} to {monthly_counts.index.max().strftime('%Y-%m')})\")\n",
    "print(f\"  Annual: {len(annual_counts)} observations ({annual_counts.index.min().year} to {annual_counts.index.max().year})\")\n",
    "print(f\"  Weekly: {len(weekly_counts)} observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing dates - ensure complete time series\n",
    "\n",
    "# For monthly series\n",
    "full_month_range = pd.date_range(\n",
    "    start=monthly_counts.index.min(),\n",
    "    end=monthly_counts.index.max(),\n",
    "    freq='ME'\n",
    ")\n",
    "monthly_counts = monthly_counts.reindex(full_month_range, fill_value=0)\n",
    "\n",
    "# For weekly series\n",
    "full_week_range = pd.date_range(\n",
    "    start=weekly_counts.index.min(),\n",
    "    end=weekly_counts.index.max(),\n",
    "    freq='W'\n",
    ")\n",
    "weekly_counts = weekly_counts.reindex(full_week_range, fill_value=0)\n",
    "\n",
    "# Check for gaps\n",
    "monthly_gaps = (monthly_counts == 0).sum()\n",
    "weekly_gaps = (weekly_counts == 0).sum()\n",
    "\n",
    "print(f\"After reindexing:\")\n",
    "print(f\"  Monthly series: {len(monthly_counts)} observations ({monthly_gaps} gaps filled with 0)\")\n",
    "print(f\"  Weekly series: {len(weekly_counts)} observations ({weekly_gaps} gaps filled with 0)\")\n",
    "\n",
    "if monthly_gaps > 0:\n",
    "    print(f\"\\nWarning: {monthly_gaps} months with zero incidents detected\")\n",
    "    gap_months = monthly_counts[monthly_counts == 0].index\n",
    "    print(f\"Gap months: {list(gap_months.strftime('%Y-%m'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create crime-type-specific time series\n",
    "\n",
    "# Examine UCR codes in the data\n",
    "print(\"UCR General Code Distribution:\")\n",
    "ucr_dist = df_analysis[COL_UCR_GENERAL].value_counts().sort_index()\n",
    "print(ucr_dist)\n",
    "\n",
    "print(\"\\nText General Code Distribution (top 10):\")\n",
    "text_dist = df_analysis[COL_TEXT_GENERAL].value_counts().head(10)\n",
    "print(text_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define crime categories based on UCR codes\n",
    "# UCR codes (General):\n",
    "# 100-400: Violent crimes (Homicide, Rape, Robbery, Aggravated Assault)\n",
    "# 500-700: Property crimes (Burglary, Theft, Motor Vehicle Theft)\n",
    "# 800+: Other/Quality of life\n",
    "\n",
    "def categorize_crime(ucr_code):\n",
    "    \"\"\"Categorize crime by UCR general code.\"\"\"\n",
    "    if pd.isna(ucr_code):\n",
    "        return 'Unknown'\n",
    "    ucr = int(ucr_code)\n",
    "    if 100 <= ucr < 500:\n",
    "        return 'Violent'\n",
    "    elif 500 <= ucr < 800:\n",
    "        return 'Property'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Apply categorization\n",
    "df_analysis['crime_category'] = df_analysis[COL_UCR_GENERAL].apply(categorize_crime)\n",
    "\n",
    "# Create category time series\n",
    "monthly_by_category = df_analysis.groupby([\n",
    "    pd.Grouper(key=COL_DATE, freq='ME'),\n",
    "    'crime_category'\n",
    "]).size().unstack(fill_value=0)\n",
    "\n",
    "# Ensure all categories are present\n",
    "for cat in ['Violent', 'Property', 'Other', 'Unknown']:\n",
    "    if cat not in monthly_by_category.columns:\n",
    "        monthly_by_category[cat] = 0\n",
    "\n",
    "print(\"Crime category distribution:\")\n",
    "print(df_analysis['crime_category'].value_counts())\n",
    "print(f\"\\nMonthly by category shape: {monthly_by_category.shape}\")\n",
    "print(f\"Categories: {list(monthly_by_category.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save intermediate time series for potential reuse\n",
    "\n",
    "# Save monthly counts\n",
    "monthly_counts.to_frame().to_csv(output_tables / 'monthly_crime_counts.csv')\n",
    "\n",
    "# Save annual counts\n",
    "annual_counts.to_frame().to_csv(output_tables / 'annual_crime_counts.csv')\n",
    "\n",
    "# Save weekly counts\n",
    "weekly_counts.to_frame().to_csv(output_tables / 'weekly_crime_counts.csv')\n",
    "\n",
    "# Save category breakdown\n",
    "monthly_by_category.to_csv(output_tables / 'monthly_by_category.csv')\n",
    "\n",
    "print(\"✓ Time series saved to output/tables/temporal/:\")\n",
    "print(\"  - monthly_crime_counts.csv\")\n",
    "print(\"  - annual_crime_counts.csv\")\n",
    "print(\"  - weekly_crime_counts.csv\")\n",
    "print(\"  - monthly_by_category.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1 Complete:** Time series created with no missing months; monthly, annual, and weekly aggregations complete; crime-type splits validated.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
