{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Philadelphia Crime Incidents: Temporal Analysis\n",
    "\n",
    "This notebook conducts comprehensive temporal analysis of Philadelphia crime data (2006-2026) including 20-year trends, seasonal decomposition, day/hour patterns, and crime-type-specific trends.\n",
    "\n",
    "Purpose: Answer TEMP-01 through TEMP-07 requirements; establish temporal baseline for dashboard and report; validate against known Philadelphia patterns (summer peaks, weekday variation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import configuration\n",
    "import sys\n",
    "sys.path.append('scripts/')\n",
    "from config import *\n",
    "\n",
    "# Configure matplotlib for publication quality\n",
    "plt.rcParams.update({\n",
    "    'figure.dpi': 300,\n",
    "    'savefig.dpi': 300,\n",
    "    'font.size': 10,\n",
    "    'axes.labelsize': 11,\n",
    "    'axes.titlesize': 12,\n",
    "    'xtick.labelsize': 9,\n",
    "    'ytick.labelsize': 9,\n",
    "    'legend.fontsize': 9,\n",
    "    'figure.figsize': (12, 8),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data from data/processed/crime_incidents_cleaned.parquet\n",
    "df = pd.read_parquet('data/processed/crime_incidents_cleaned.parquet')\n",
    "\n",
    "# Ensure datetime format\n",
    "df['dispatch_date_time'] = pd.to_datetime(df['dispatch_date_time'])\n",
    "\n",
    "# Exclude last 30 days (reporting lag)\n",
    "cutoff_date = df['dispatch_date_time'].max() - pd.Timedelta(days=30)\n",
    "df_analysis = df[df['dispatch_date_time'] <= cutoff_date].copy()\n",
    "\n",
    "# Print data info\n",
    "print(f\"Original data: {len(df)} records\")\n",
    "print(f\"Analysis data: {len(df_analysis)} records after excluding last 30 days\")\n",
    "print(f\"Analysis date range: {df_analysis['dispatch_date_time'].min()} to {df_analysis['dispatch_date_time'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define crime type mappings based on UCR codes\n",
    "# According to FBI UCR classification:\n",
    "# Violent crimes: 100 (Homicide), 200 (Criminal Homicide), 300 (Robbery), 400 (Aggravated Assault)\n",
    "# Property crimes: 500 (Burglary), 600 (Larceny), 700 (Motor Vehicle Theft), 800 (Arson)\n",
    "# Other crimes: Other UCR codes\n",
    "\n",
    "UCR_VIOLENT = [100, 200, 300, 400]\n",
    "UCR_PROPERTY = [500, 600, 700, 800]\n",
    "\n",
    "# Create crime type columns\n",
    "df_analysis['crime_type'] = df_analysis['ucr_general'].apply(lambda x: \n",
    "    'Violent' if x in UCR_VIOLENT \n",
    "    else 'Property' if x in UCR_PROPERTY \n",
    "    else 'Other'\n",
    ")\n",
    "\n",
    "print(\"Crime type distribution:\")\n",
    "print(df_analysis['crime_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiple time series aggregations\n",
    "# 1. Daily counts\n",
    "daily_counts = df_analysis.set_index('dispatch_date_time').resample('D').size()\n",
    "daily_counts.name = 'crime_count'\n",
    "\n",
    "# 2. Weekly counts\n",
    "weekly_counts = df_analysis.set_index('dispatch_date_time').resample('W-MON').size()\n",
    "weekly_counts.name = 'crime_count'\n",
    "\n",
    "# 3. Monthly counts (for STL decomposition)\n",
    "monthly_counts = df_analysis.set_index('dispatch_date_time').resample('ME').size()\n",
    "monthly_counts.name = 'crime_count'\n",
    "\n",
    "# 4. Annual counts\n",
    "annual_counts = df_analysis.set_index('dispatch_date_time').resample('YE').size()\n",
    "annual_counts.name = 'crime_count'\n",
    "\n",
    "# Handle missing dates by reindexing with fill_value=0 for complete time series\n",
    "full_daily_range = pd.date_range(start=daily_counts.index.min(), \n",
    "                                end=daily_counts.index.max(), \n",
    "                                freq='D')\n",
    "daily_counts = daily_counts.reindex(full_daily_range, fill_value=0)\n",
    "\n",
    "full_weekly_range = pd.date_range(start=weekly_counts.index.min(), \n",
    "                                 end=weekly_counts.index.max(), \n",
    "                                 freq='W-MON')\n",
    "weekly_counts = weekly_counts.reindex(full_weekly_range, fill_value=0)\n",
    "\n",
    "full_monthly_range = pd.date_range(start=monthly_counts.index.min(), \n",
    "                                  end=monthly_counts.index.max(), \n",
    "                                  freq='ME')\n",
    "monthly_counts = monthly_counts.reindex(full_monthly_range, fill_value=0)\n",
    "\n",
    "full_annual_range = pd.date_range(start=annual_counts.index.min(), \n",
    "                                 end=annual_counts.index.max(), \n",
    "                                 freq='YE')\n",
    "annual_counts = annual_counts.reindex(full_annual_range, fill_value=0)\n",
    "\n",
    "print(f\"Daily time series: {len(daily_counts)} days\")\n",
    "print(f\"Weekly time series: {len(weekly_counts)} weeks\")\n",
    "print(f\"Monthly time series: {len(monthly_counts)} months\")\n",
    "print(f\"Annual time series: {len(annual_counts)} years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create crime-type-specific time series\n",
    "\n",
    "# Filter data by crime type\n",
    "df_violent = df_analysis[df_analysis['crime_type'] == 'Violent']\n",
    "df_property = df_analysis[df_analysis['crime_type'] == 'Property']\n",
    "df_other = df_analysis[df_analysis['crime_type'] == 'Other']\n",
    "\n",
    "# Create monthly time series for each crime type\n",
    "monthly_violent = df_violent.set_index('dispatch_date_time').resample('ME').size()\n",
    "monthly_property = df_property.set_index('dispatch_date_time').resample('ME').size()\n",
    "monthly_other = df_other.set_index('dispatch_date_time').resample('ME').size()\n",
    "\n",
    "# Reindex to the full date range with fill_value=0\n",
    "monthly_violent = monthly_violent.reindex(full_monthly_range, fill_value=0)\n",
    "monthly_property = monthly_property.reindex(full_monthly_range, fill_value=0)\n",
    "monthly_other = monthly_other.reindex(full_monthly_range, fill_value=0)\n",
    "\n",
    "print(f\"Monthly violent crimes: {len(monthly_violent)} months\")\n",
    "print(f\"Monthly property crimes: {len(monthly_property)} months\")\n",
    "print(f\"Monthly other crimes: {len(monthly_other)} months\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save intermediate time series to output/tables/temporal/ for potential reuse\n",
    "import os\n",
    "os.makedirs('output/tables/temporal/', exist_ok=True)\n",
    "\n",
    "# Combine all time series into a DataFrame\n",
    "timeseries_df = pd.DataFrame({\n",
    "    'overall': monthly_counts,\n",
    "    'violent': monthly_violent,\n",
    "    'property': monthly_property,\n",
    "    'other': monthly_other\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "timeseries_df.to_csv('output/tables/temporal/monthly_timeseries.csv')\n",
    "print(\"Saved monthly time series to output/tables/temporal/monthly_timeseries.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: STL Decomposition and Seasonal Analysis\n",
    "\n",
    "Implement STL decomposition and seasonal analysis per 02-RESEARCH.md Pattern 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. STL Decomposition (overall crime):\n",
    "# Use STL(monthly_counts, period=12, robust=True)\n",
    "stl = STL(monthly_counts, period=12, robust=True)\n",
    "result = stl.fit()\n",
    "\n",
    "# Extract trend, seasonal, and residual components\n",
    "trend = result.trend\n",
    "seasonal = result.seasonal\n",
    "residual = result.resid\n",
    "\n",
    "# Create 4-panel decomposition plot (original, trend, seasonal, residual)\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 12), sharex=True)\n",
    "\n",
    "# Original\n",
    "axes[0].plot(monthly_counts.index, monthly_counts.values, color='gray', alpha=0.7)\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Original Time Series')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Trend\n",
    "axes[1].plot(trend.index, trend.values, color='steelblue', linewidth=2)\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Trend Component')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Seasonal\n",
    "axes[2].plot(seasonal.index, seasonal.values, color='green')\n",
    "axes[2].set_ylabel('Count')\n",
    "axes[2].set_title('Seasonal Component')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Residual\n",
    "axes[3].plot(residual.index, residual.values, color='red', alpha=0.7)\n",
    "axes[3].axhline(y=0, color='black', linestyle='--', linewidth=0.5)\n",
    "axes[3].set_ylabel('Count')\n",
    "axes[3].set_xlabel('Year')\n",
    "axes[3].set_title('Residual Component')\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/figures/temporal/stl_decomposition_overall.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"STL decomposition completed and 4-panel plot saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Seasonal factor calculation:\n",
    "# Group seasonal component by month\n",
    "seasonal_by_month = result.seasonal.groupby(result.seasonal.index.month).mean()\n",
    "\n",
    "# Calculate mean seasonal factor for each month\n",
    "monthly_seasonal_factors = seasonal_by_month.sort_index()\n",
    "\n",
    "# Compute seasonality magnitude: (summer peak - winter low) / overall mean * 100\n",
    "summer_peak = monthly_seasonal_factors[[6, 7, 8]].mean()  # Jun-Aug\n",
    "winter_low = monthly_seasonal_factors[[12, 1, 2]].mean()   # Dec-Feb\n",
    "seasonality_magnitude = (summer_peak - winter_low) / monthly_counts.mean() * 100\n",
    "\n",
    "# Create a DataFrame with seasonal factors\n",
    "seasonal_df = pd.DataFrame({\n",
    "    'month': range(1, 13),\n",
    "    'factor': monthly_seasonal_factors.values\n",
    "})\n",
    "\n",
    "# Save seasonal_factors.csv to output/tables/temporal/\n",
    "seasonal_df.to_csv('output/tables/temporal/seasonal_factors.csv', index=False)\n",
    "print(f\"Seasonal factors calculated and saved. Seasonality magnitude: {seasonality_magnitude:+.2f}%\")\n",
    "print(f\"Summer peak avg: {summer_peak:+.2f}, Winter low avg: {winter_low:+.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Crime-type-specific decomposition:\n",
    "# Repeat STL for violent, property, and other crime categories\n",
    "stl_violent = STL(monthly_violent, period=12, robust=True)\n",
    "result_violent = stl_violent.fit()\n",
    "\n",
    "stl_property = STL(monthly_property, period=12, robust=True)\n",
    "result_property = stl_property.fit()\n",
    "\n",
    "stl_other = STL(monthly_other, period=12, robust=True)\n",
    "result_other = stl_other.fit()\n",
    "\n",
    "# Create comparative seasonal plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Calculate seasonal factors for each crime type\n",
    "seasonal_violent_by_month = result_violent.seasonal.groupby(result_violent.seasonal.index.month).mean().sort_index()\n",
    "seasonal_property_by_month = result_property.seasonal.groupby(result_property.seasonal.index.month).mean().sort_index()\n",
    "seasonal_other_by_month = result_other.seasonal.groupby(result_other.seasonal.index.month).mean().sort_index()\n",
    "\n",
    "ax.plot(seasonal_by_month.index, seasonal_by_month.values, label='Overall', marker='o')\n",
    "ax.plot(seasonal_violent_by_month.index, seasonal_violent_by_month.values, label='Violent', marker='s')\n",
    "ax.plot(seasonal_property_by_month.index, seasonal_property_by_month.values, label='Property', marker='^')\n",
    "ax.plot(seasonal_other_by_month.index, seasonal_other_by_month.values, label='Other', marker='d')\n",
    "\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Seasonal Factor')\n",
    "ax.set_title('Seasonal Patterns by Crime Type')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/figures/temporal/seasonal_factors_by_type.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Crime-type-specific decomposition completed and comparative plot saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Trend quantification:\n",
    "# Fit linear regression to trend component\n",
    "x = np.arange(len(result.trend))\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x, result.trend.values)\n",
    "\n",
    "# Calculate annual change rate\n",
    "annual_change = slope * 12  # Convert monthly to annual change\n",
    "\n",
    "# Compute 95% confidence intervals for trend slope\n",
    "from scipy.stats import t\n",
    "alpha = 0.05\n",
    "t_critical = t.ppf(1-alpha/2, len(x)-2)\n",
    "slope_se = std_err\n",
    "slope_ci_lower = slope - t_critical * slope_se\n",
    "slope_ci_upper = slope + t_critical * slope_se\n",
    "\n",
    "# Annual change CI\n",
    "annual_change_ci_lower = slope_ci_lower * 12\n",
    "annual_change_ci_upper = slope_ci_upper * 12\n",
    "\n",
    "print(f\"Overall trend: Annual change = {annual_change:+.2f} incidents/year\")\n",
    "print(f\"95% CI for annual change: {annual_change_ci_lower:+.2f} to {annual_change_ci_upper:+.2f}\")\n",
    "print(f\"P-value: {p_value:.2e}\")\n",
    "print(f\"Significant at α=0.05: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "\n",
    "# Now do the same for each crime type\n",
    "def calculate_trend_stats(trend_series, name):\n",
    "    x = np.arange(len(trend_series))\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x, trend_series.values)\n",
    "    annual_change = slope * 12\n",
    "    \n",
    "    # Confidence intervals\n",
    "    alpha = 0.05\n",
    "    t_critical = t.ppf(1-alpha/2, len(x)-2)\n",
    "    slope_se = std_err\n",
    "    slope_ci_lower = slope - t_critical * slope_se\n",
    "    slope_ci_upper = slope + t_critical * slope_se\n",
    "    \n",
    "    # Annual change CI\n",
    "    annual_change_ci_lower = slope_ci_lower * 12\n",
    "    annual_change_ci_upper = slope_ci_upper * 12\n",
    "    \n",
    "    return {\n",
    "        'type': name,\n",
    "        'annual_change': annual_change,\n",
    "        'ci_lower': annual_change_ci_lower,\n",
    "        'ci_upper': annual_change_ci_upper,\n",
    "        'p_value': p_value,\n",
    "        'significant': p_value < 0.05\n",
    "    }\n",
    "\n",
    "# Calculate trend statistics for each crime type\n",
    "overall_stats = calculate_trend_stats(result.trend, 'Overall')\n",
    "violent_stats = calculate_trend_stats(result_violent.trend, 'Violent')\n",
    "property_stats = calculate_trend_stats(result_property.trend, 'Property')\n",
    "other_stats = calculate_trend_stats(result_other.trend, 'Other')\n",
    "\n",
    "# Combine into a DataFrame\n",
    "trend_stats_df = pd.DataFrame([\n",
    "    overall_stats, violent_stats, property_stats, other_stats\n",
    "])\n",
    "\n",
    "# Save trend_statistics.csv to output/tables/temporal/\n",
    "trend_stats_df.to_csv('output/tables/temporal/trend_statistics.csv', index=False)\n",
    "print(\"\\nTrend statistics calculated and saved to output/tables/temporal/trend_statistics.csv\")\n",
    "print(\"\\nTrend Statistics:\")\n",
    "print(trend_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Save figures: trend_comparison_by_type.png\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot trends for each crime type\n",
    "ax.plot(result.trend.index, result.trend.values, label='Overall', linewidth=2)\n",
    "ax.plot(result_violent.trend.index, result_violent.trend.values, label='Violent', linewidth=2)\n",
    "ax.plot(result_property.trend.index, result_property.trend.values, label='Property', linewidth=2)\n",
    "ax.plot(result_other.trend.index, result_other.trend.values, label='Other', linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Trend Component')\n",
    "ax.set_title('Trend Comparison by Crime Type')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/figures/temporal/trend_comparison_by_type.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Trend comparison figure saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Day/Hour Patterns and Crime-Type Trends\n",
    "\n",
    "Analyze day-of-week and hour-of-day patterns plus detailed crime-type trends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Day-of-week analysis:\n",
    "# Extract day of week from dispatch date time\n",
    "df_analysis['day_of_week'] = df_analysis['dispatch_date_time'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "df_analysis['day_name'] = df_analysis['dispatch_date_time'].dt.day_name()\n",
    "\n",
    "# Aggregate incidents by day of week\n",
    "day_of_week_counts = df_analysis.groupby('day_of_week')['cartodb_id'].count()\n",
    "day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "# Calculate weekend vs weekday difference\n",
    "weekend_days = [5, 6]  # Saturday, Sunday\n",
    "weekday_days = [0, 1, 2, 3, 4]  # Monday to Friday\n",
    "\n",
    "weekend_avg = day_of_week_counts[weekend_days].mean()\n",
    "weekday_avg = day_of_week_counts[weekday_days].mean()\n",
    "weekend_vs_weekday = (weekend_avg - weekday_avg) / weekday_avg * 100\n",
    "\n",
    "# Calculate 95% confidence intervals for each day\n",
    "# We'll estimate using bootstrap sampling\n",
    "bootstrap_samples = 1000\n",
    "bootstrapped_means = []\n",
    "\n",
    "for day in range(7):\n",
    "    day_data = df_analysis[df_analysis['day_of_week'] == day]['cartodb_id']\n",
    "    bootstraps = []\n",
    "    for _ in range(bootstrap_samples):\n",
    "        sample = day_data.sample(n=len(day_data), replace=True)\n",
    "        bootstraps.append(sample.count())\n",
    "    bootstraps = np.array(bootstraps)\n",
    "    ci_lower = np.percentile(bootstraps, 2.5)\n",
    "    ci_upper = np.percentile(bootstraps, 97.5)\n",
    "    bootstrapped_means.append((day, ci_lower, ci_upper))\n",
    "\n",
    "# Create day of week plot with error bars\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "days = range(7)\n",
    "counts = [day_of_week_counts[day] if day in day_of_week_counts.index else 0 for day in days]\n",
    "ci_lower = [bootstrapped_means[i][1] for i in range(7)]\n",
    "ci_upper = [bootstrapped_means[i][2] for i in range(7)]\n",
    "\n",
    "error_bars = [np.abs([ci_lower[i], ci_upper[i]] - counts[i]) for i in range(7)]\n",
    "\n",
    "bars = ax.bar(range(7), counts, yerr=error_bars, capsize=5, \n",
    "              tick_label=day_names, color=sns.color_palette(\"viridis\", 7))\n",
    "\n",
    "ax.set_xlabel('Day of Week')\n",
    "ax.set_ylabel('Number of Incidents')\n",
    "ax.set_title(f'Day-of-Week Crime Patterns (Weekend vs Weekday: {weekend_vs_weekday:+.1f}%)')\n",
    "plt.xticks(rotation=45)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/figures/temporal/day_of_week_patterns.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Test significance of weekend effect with Mann-Whitney U test\n",
    "weekend_data = df_analysis[df_analysis['day_of_week'].isin(weekend_days)]['cartodb_id']\n",
    "weekday_data = df_analysis[df_analysis['day_of_week'].isin(weekday_days)]['cartodb_id']\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "stat, p_val = mannwhitneyu(weekend_data, weekday_data, alternative='two-sided')\n",
    "\n",
    "print(f\"Weekend vs weekday difference: {weekend_vs_weekday:+.1f}%\")\n",
    "print(f\"Weekend avg: {weekend_avg:.0f}, Weekday avg: {weekday_avg:.0f}\")\n",
    "print(f\"Mann-Whitney U test p-value: {p_val:.2e}\")\n",
    "print(f\"Weekend effect significant: {'Yes' if p_val < 0.05 else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Hour-of-day analysis:\n",
    "# Aggregate incidents by hour (0-23)\n",
    "df_analysis['hour'] = df_analysis['dispatch_date_time'].dt.hour\n",
    "hourly_counts = df_analysis.groupby('hour')['cartodb_id'].count()\n",
    "\n",
    "# Identify peak hours by crime type\n",
    "hourly_violent = df_analysis[df_analysis['crime_type'] == 'Violent'].groupby('hour')['cartodb_id'].count()\n",
    "hourly_property = df_analysis[df_analysis['crime_type'] == 'Property'].groupby('hour')['cartodb_id'].count()\n",
    "hourly_other = df_analysis[df_analysis['crime_type'] == 'Other'].groupby('hour')['cartodb_id'].count()\n",
    "\n",
    "# Create line plot with multiple series (overall, violent, property)\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "hours = range(24)\n",
    "overall_hourly = [hourly_counts[hour] if hour in hourly_counts else 0 for hour in hours]\n",
    "violent_hourly = [hourly_violent[hour] if hour in hourly_violent else 0 for hour in hours]\n",
    "property_hourly = [hourly_property[hour] if hour in hourly_property else 0 for hour in hours]\n",
    "\n",
    "ax.plot(hours, overall_hourly, label='Overall', linewidth=2, marker='o')\n",
    "ax.plot(hours, violent_hourly, label='Violent', linewidth=2, marker='s')\n",
    "ax.plot(hours, property_hourly, label='Property', linewidth=2, marker='^')\n",
    "\n",
    "ax.set_xlabel('Hour of Day')\n",
    "ax.set_ylabel('Number of Incidents')\n",
    "ax.set_title('Hour-of-Day Crime Patterns by Crime Type')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/figures/temporal/hour_of_day_patterns.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Find peak hours\n",
    "overall_peak_hour = np.argmax(overall_hourly)\n",
    "violent_peak_hour = np.argmax(violent_hourly)\n",
    "property_peak_hour = np.argmax(property_hourly)\n",
    "\n",
    "print(f\"Peak hours: Overall={overall_peak_hour}, Violent={violent_peak_hour}, Property={property_peak_hour}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Day × Hour heatmap:\n",
    "# Create 7×24 heatmap (day of week × hour)\n",
    "hourly_daily = df_analysis.groupby(['day_of_week', 'hour']).size().unstack(fill_value=0)\n",
    "\n",
    "# Ensure all hours (0-23) and days (0-6) are represented\n",
    "for h in range(24):\n",
    "    if h not in hourly_daily.columns:\n",
    "        hourly_daily[h] = 0\n",
    "for d in range(7):\n",
    "    if d not in hourly_daily.index:\n",
    "        hourly_daily.loc[d] = [0] * 24\n",
    "\n",
    "hourly_daily = hourly_daily.reindex(columns=range(24)).reindex(index=range(7))\n",
    "\n",
    "# Sort rows to have Monday first\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "# Create heatmap\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "sns.heatmap(hourly_daily, cmap='YlOrRd', annot=False, fmt='g', \n",
    "            cbar_kws={'label': 'Number of Incidents'}, ax=ax)\n",
    "ax.set_xlabel('Hour of Day', fontweight='bold')\n",
    "ax.set_ylabel('Day of Week', fontweight='bold')\n",
    "ax.set_yticklabels(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
    "ax.set_title('Crime Incidents by Hour and Day of Week', fontweight='bold', pad=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/figures/temporal/hour_day_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Day × Hour heatmap created and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Crime-type-specific trends:\n",
    "# 20-year trend for each major UCR category\n",
    "df_analysis['year'] = df_analysis['dispatch_date_time'].dt.year\n",
    "\n",
    "# Yearly counts by crime type\n",
    "yearly_by_type = df_analysis.groupby(['year', 'crime_type']).size().unstack(fill_value=0)\n",
    "\n",
    "# Create multi-line trend plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for col in yearly_by_type.columns:\n",
    "    ax.plot(yearly_by_type.index, yearly_by_type[col], label=col, linewidth=2, marker='o')\n",
    "\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Number of Incidents')\n",
    "ax.set_title('20-Year Crime Trends by Type')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/figures/temporal/crime_type_trends_20yr.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calculate rate of change for each type\n",
    "for col in yearly_by_type.columns:\n",
    "    x = np.arange(len(yearly_by_type))\n",
    "    y = yearly_by_type[col].values\n",
    "    slope, _, _, p_val, stderr = stats.linregress(x, y)\n",
    "    annual_change = slope\n",
    "    print(f\"{col} trend: {annual_change:+.1f} incidents/year (p={p_val:.2e}, {'sig' if p_val < 0.05 else 'ns'})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Recent trend analysis (last 5 years):\n",
    "# Focus on 2020-2025 to identify recent patterns\n",
    "recent_years = df_analysis[df_analysis['year'] >= 2020]\n",
    "recent_yearly_by_type = recent_years.groupby(['year', 'crime_type']).size().unstack(fill_value=0)\n",
    "\n",
    "# Create recent trend plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for col in recent_yearly_by_type.columns:\n",
    "    ax.plot(recent_yearly_by_type.index, recent_yearly_by_type[col], label=col, linewidth=2, marker='o')\n",
    "\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Number of Incidents')\n",
    "ax.set_title('Recent Crime Trends (2020-2025) by Type')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output/figures/temporal/recent_trends_5yr.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Calculate recent trends\n",
    "for col in recent_yearly_by_type.columns:\n",
    "    if len(recent_yearly_by_type) > 1:  # Ensure we have enough data points\n",
    "        x = np.arange(len(recent_yearly_by_type))\n",
    "        y = recent_yearly_by_type[col].values\n",
    "        slope, _, _, p_val, stderr = stats.linregress(x, y)\n",
    "        annual_change = slope\n",
    "        print(f\"Recent {col} trend (2020-2025): {annual_change:+.1f} incidents/year (p={p_val:.2e}, {'sig' if p_val < 0.05 else 'ns'})\")\n",
    "\n",
    "# Document any structural breaks around COVID period\n",
    "# Compare 2019 to 2020 values\n",
    "pre_covid = df_analysis[df_analysis['year'] == 2019].groupby('crime_type').size()\n",
    "post_covid = df_analysis[df_analysis['year'] == 2020].groupby('crime_type').size()\n",
    "\n",
    "print('\\nCOVID-19 Period Changes:')\n",
    "for ct in pre_covid.index:\n",
    "    if ct in post_covid.index:\n",
    "        change = ((post_covid[ct] - pre_covid[ct]) / pre_covid[ct]) * 100\n",
    "        print(f'{ct}: {change:+.1f}% change from 2019 to 2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Save outputs: temporal_summary_stats.csv\n",
    "# Create a comprehensive summary of all calculated statistics\n",
    "summary_stats = []\n",
    "\n",
    "# Add trend statistics\n",
    "for idx, row in trend_stats_df.iterrows():\n",
    "    summary_stats.append({\n",
    "        'metric': f\"{row['type']} Annual Change\",\n",
    "        'value': row['annual_change'],\n",
    "        'ci_lower': row['ci_lower'],\n",
    "        'ci_upper': row['ci_upper'],\n",
    "        'p_value': row['p_value'],\n",
    "        'category': 'Trend Statistics'\n",
    "    })\n",
    "\n",
    "# Add seasonal statistics\n",
    "summary_stats.append({\n",
    "    'metric': 'Seasonality Magnitude (% difference Summer vs Winter)',\n",
    "    'value': seasonality_magnitude,\n",
    "    'ci_lower': None,\n",
    "    'ci_upper': None,\n",
    "    'p_value': None,\n",
    "    'category': 'Seasonal Statistics'\n",
    "})\n",
    "\n",
    "# Add day of week statistics\n",
    "summary_stats.append({\n",
    "    'metric': 'Weekend vs Weekday Difference (%)',\n",
    "    'value': weekend_vs_weekday,\n",
    "    'ci_lower': None,\n",
    "    'ci_upper': None,\n",
    "    'p_value': p_val,\n",
    "    'category': 'Day/Week Statistics'\n",
    "})\n",
    "\n",
    "# Add peak hour information\n",
    "summary_stats.extend([\n",
    "    {\n",
    "        'metric': 'Peak Hour - Overall',\n",
    "        'value': overall_peak_hour,\n",
    "        'ci_lower': None,\n",
    "        'ci_upper': None,\n",
    "        'p_value': None,\n",
    "        'category': 'Hour Statistics'\n",
    "    },\n",
    "    {\n",
    "        'metric': 'Peak Hour - Violent',\n",
    "        'value': violent_peak_hour,\n",
    "        'ci_lower': None,\n",
    "        'ci_upper': None,\n",
    "        'p_value': None,\n",
    "        'category': 'Hour Statistics'\n",
    "    },\n",
    "    {\n",
    "        'metric': 'Peak Hour - Property',\n",
    "        'value': property_peak_hour,\n",
    "        'ci_lower': None,\n",
    "        'ci_upper': None,\n",
    "        'p_value': None,\n",
    "        'category': 'Hour Statistics'\n",
    "    }\n",
    "])\n",
    "\n",
    "summary_df = pd.DataFrame(summary_stats)\n",
    "summary_df.to_csv('output/tables/temporal/temporal_summary_stats.csv', index=False)\n",
    "print(\"Summary statistics saved to output/tables/temporal/temporal_summary_stats.csv\")\n",
    "print(summary_df[['metric', 'value', 'category']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Notebook conclusion:\n",
    "# Executive summary of temporal findings\n",
    "print(\"\\n=== EXECUTIVE SUMMARY OF TEMPORAL FINDINGS ===\\n\")\n",
    "\n",
    "print(\"1. 20-YEAR TREND ANALYSIS:\")\n",
    "for idx, row in trend_stats_df.iterrows():\n",
    "    sig = \"SIGNIFICANT\" if row['significant'] else \"NS\"\n",
    "    print(f\"   - {row['type']}: {row['annual_change']:+.1f} incidents/year ({sig}, p={row['p_value']:.2e})\")\n",
    "\n",
    "print(f\"\\n2. SEASONALITY PATTERNS:\")\n",
    "print(f\"   - Seasonality magnitude: {seasonality_magnitude:+.1f}% (Summer vs Winter difference)\")\n",
    "print(f\"   - Summer peak months (Jun-Aug): Average {summer_peak:+.1f} incidents relative to trend\")\n",
    "print(f\"   - Winter low months (Dec-Feb): Average {winter_low:+.1f} incidents relative to trend\")\n",
    "\n",
    "print(f\"\\n3. DAY/HOUR PATTERNS:\")\n",
    "print(f\"   - Weekend vs weekday difference: {weekend_vs_weekday:+.1f}%\")\n",
    "print(f\"   - Peak overall hour: {overall_peak_hour}:00\")\n",
    "print(f\"   - Peak violent crime hour: {violent_peak_hour}:00\")\n",
    "print(f\"   - Peak property crime hour: {property_peak_hour}:00\")\n",
    "\n",
    "print(f\"\\n4. VALIDATION AGAINST KNOWN PATTERNS:\")\n",
    "# Check if patterns align with known Philadelphia crime patterns\n",
    "summer_peaks_known = seasonality_magnitude > 0  # Summer should have more crime\n",
    "weekend_effect_exists = abs(weekend_vs_weekday) > 5  # Meaningful weekend vs weekday difference\n",
    "\n",
    "print(f\"   - Summer peaks confirmed: {'Yes' if summer_peaks_known else 'No'}\")\n",
    "print(f\"   - Weekend vs weekday patterns: {'Yes' if weekend_effect_exists else 'No'}\")\n",
    "\n",
    "print(f\"\\n5. RECOMMENDATIONS FOR DASHBOARD VISUALIZATIONS:\")\n",
    "print(f\"   - Include 4-panel STL decomposition plot\")\n",
    "print(f\"   - Display seasonal patterns by crime type\")\n",
    "print(f\"   - Show 24-hour crime patterns with differentiation by crime type\")\n",
    "print(f\"   - Create day-of-week heat map\")\n",
    "print(f\"   - Include trend comparison by crime type\")\n",
    "\n",
    "print(f\"\\n=== TEMPORAL ANALYSIS COMPLETE ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 }
}