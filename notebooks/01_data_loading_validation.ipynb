{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Data Loading & Schema Validation\n",
    "\n",
    "**Objective:** Load the raw crime incidents data, validate its schema against expected types/constraints, and perform an initial audit of data quality (specifically missing values).\n",
    "\n",
    "**Inputs:** `data/crime_incidents_combined.parquet`\n",
    "**Outputs:** Schema validation report, Missing value analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T21:49:22.717157Z",
     "iopub.status.busy": "2026-01-27T21:49:22.717012Z",
     "iopub.status.idle": "2026-01-27T21:49:24.259661Z",
     "shell.execute_reply": "2026-01-27T21:49:24.258524Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dustinober/Projects/Crime Incidents Philadelphia/.venv/lib/python3.14/site-packages/pandera/_pandas_deprecated.py:146: FutureWarning: Importing pandas-specific classes and functions from the\n",
      "top-level pandera module will be **removed in a future version of pandera**.\n",
      "If you're using pandera to validate pandas objects, we highly recommend updating\n",
      "your import:\n",
      "\n",
      "```\n",
      "# old import\n",
      "import pandera as pa\n",
      "\n",
      "# new import\n",
      "import pandera.pandas as pa\n",
      "```\n",
      "\n",
      "If you're using pandera to validate objects from other compatible libraries\n",
      "like pyspark or polars, see the supported libraries section of the documentation\n",
      "for more information on how to import pandera:\n",
      "\n",
      "https://pandera.readthedocs.io/en/stable/supported_libraries.html\n",
      "\n",
      "To disable this warning, set the environment variable:\n",
      "\n",
      "```\n",
      "export DISABLE_PANDERA_IMPORT_WARNING=True\n",
      "```\n",
      "\n",
      "  warnings.warn(_future_warning, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "# Add project root to sys.path to allow importing scripts\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "import pandas as pd\n",
    "import pandera as pa\n",
    "from pandera import errors\n",
    "import scripts.config as config\n",
    "from scripts.data_loader import load_raw_data, Schema\n",
    "\n",
    "# Display settings\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "Using the centralized data loader which handles column renaming and standard type conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T21:49:24.282381Z",
     "iopub.status.busy": "2026-01-27T21:49:24.282095Z",
     "iopub.status.idle": "2026-01-27T21:49:29.181678Z",
     "shell.execute_reply": "2026-01-27T21:49:29.181049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /Users/dustinober/Projects/Crime Incidents Philadelphia/data/crime_incidents_combined.parquet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating schema...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema validation passed.\n",
      "Successfully loaded 3,496,353 records.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = load_raw_data(validate=True)\n",
    "    print(f\"Successfully loaded {len(df):,} records.\")\n",
    "except errors.SchemaErrors as err:\n",
    "    print(\"Schema validation failed with the following errors:\")\n",
    "    print(err.failure_cases)\n",
    "    # We continue with the dataframe available in the error object if needed, \n",
    "    # or usually we might stop. For this audit, we want to inspect the data even if it fails strict validation.\n",
    "    # The loader raises, so 'df' might not be assigned if we don't handle it.\n",
    "    # Let's catch and reload without validation to proceed with audit if validation fails.\n",
    "    print(\"Reloading without strict validation to continue audit...\")\n",
    "    df = load_raw_data(validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Schema Definition & Data Dictionary\n",
    "\n",
    "The data is validated against the following schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-27T21:49:29.185265Z",
     "iopub.status.busy": "2026-01-27T21:49:29.185088Z",
     "iopub.status.idle": "2026-01-27T21:49:29.188423Z",
     "shell.execute_reply": "2026-01-27T21:49:29.187732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Schema DataFrameSchema(\n",
      "    columns={\n",
      "        'cartodb_id': <Schema Column(name=cartodb_id, type=DataType(int64))>\n",
      "        'dispatch_date_time': <Schema Column(name=dispatch_date_time, type=DataType(datetime64[ns, UTC]))>\n",
      "        'dc_dist': <Schema Column(name=dc_dist, type=DataType(int64))>\n",
      "        'psa': <Schema Column(name=psa, type=DataType(str))>\n",
      "        'ucr_general': <Schema Column(name=ucr_general, type=DataType(int64))>\n",
      "        'text_general_code': <Schema Column(name=text_general_code, type=DataType(str))>\n",
      "        'location_block': <Schema Column(name=location_block, type=DataType(str))>\n",
      "        'lat': <Schema Column(name=lat, type=DataType(float64))>\n",
      "        'lng': <Schema Column(name=lng, type=DataType(float64))>\n",
      "    },\n",
      "    checks=[],\n",
      "    parsers=[],\n",
      "    coerce=True,\n",
      "    dtype=None,\n",
      "    index=None,\n",
      "    strict=False,\n",
      "    name=None,\n",
      "    ordered=False,\n",
      "    unique_column_names=False,\n",
      "    metadata=None, \n",
      "    add_missing_columns=False\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(Schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "\n",
    "| Column | Type | Description | Required |\n",
    "|---|---|---|---|\n",
    "| `cartodb_id` | int | Unique identifier | Yes |\n",
    "| `dispatch_date_time` | datetime | Date and time of the incident dispatch | Yes |\n",
    "| `dc_dist` | int | District Control Number (District ID) | Yes |\n",
    "| `psa` | str | Police Service Area | No |\n",
    "| `ucr_general` | int | Uniform Crime Reporting General Code | Yes |\n",
    "| `text_general_code` | str | Description of the crime type | No |\n",
    "| `location_block` | str | Block-level location address | No |\n",
    "| `lat` | float | Latitude | No |\n",
    "| `lng` | float | Longitude | No |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
