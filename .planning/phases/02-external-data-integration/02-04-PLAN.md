---
phase: 02-external-data-integration
plan: 04
type: execute
wave: 2
depends_on: [02-02]
files_modified:
  - analysis/external_data.py
  - analysis/config.py
autonomous: true

must_haves:
  truths:
    - "User can import align_temporal_data from analysis.external_data"
    - "User can aggregate crime data to daily, monthly, annual levels"
    - "User can merge crime data with weather (daily) and economic (monthly/annual) data"
    - "Temporal alignment issues are documented in function docstrings"
  artifacts:
    - path: "analysis/external_data.py"
      provides: "Temporal alignment utilities for correlation analysis"
      contains: "align_temporal_data", "aggregate_crime_by_period"
    - path: "analysis/config.py"
      contains: "TEMPORAL_CONFIG"
  key_links:
    - from: "analysis/correlation_analysis.py"
      to: "analysis/external_data.py"
      via: "from analysis.external_data import align_temporal_data"
      pattern: "from analysis.external_data import"
---

<objective>
Create temporal alignment utilities to handle the misalignment between data sources (crime: daily, weather: daily, FRED: monthly, Census: annual). Implement aggregation functions and document the temporal resolution trade-offs.

Purpose: Enable correlation analysis by properly aligning data sources with different temporal granularities. This addresses the success criterion "Temporal misalignment issues are documented and handled."

Output: Extended `analysis/external_data.py` with temporal alignment functions, TEMPORAL_CONFIG in `analysis/config.py`, and clear documentation of aggregation trade-offs.
</objective>

<execution_context>
@/Users/dustinober/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dustinober/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-external-data-integration/02-RESEARCH.md
@analysis/config.py
@analysis/external_data.py
@analysis/utils.py
@.planning/phases/02-external-data-integration/02-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Add TEMPORAL_CONFIG to config.py</name>
  <files>analysis/config.py</files>
  <action>
Add temporal alignment configuration to `analysis/config.py` after CACHE_CONFIG:

```python
# =============================================================================
# TEMPORAL ALIGNMENT CONFIGURATION
# =============================================================================

# Temporal resolution for different analysis types
# Higher resolution = more data points but requires more aligned data sources
TEMPORAL_CONFIG = {
    # Daily analysis: crime + weather (no economic data)
    "daily_start": "2006-01-01",
    "daily_end": "2025-12-31",  # Exclude 2026 (incomplete)

    # Monthly analysis: crime + weather + FRED unemployment
    "monthly_start": "2006-01-01",
    "monthly_end": "2025-12-31",

    # Annual analysis: crime + weather + FRED + Census ACS
    "annual_start": "2010",  # ACS 5-year estimates available from 2010
    "annual_end": "2023",  # Most recent complete ACS data
}


def get_analysis_range(resolution: str = "monthly") -> tuple:
    """
    Get date range for analysis at specified temporal resolution.

    Args:
        resolution: Temporal resolution ('daily', 'monthly', 'annual').

    Returns:
        Tuple of (start_date, end_date) as strings.

    Raises:
        ValueError: If resolution not recognized.

    Example:
        >>> start, end = get_analysis_range('monthly')
        >>> print(f'{start} to {end}')
    """
    if resolution not in TEMPORAL_CONFIG:
        raise ValueError(f"Unknown resolution: {resolution}. Use 'daily', 'monthly', or 'annual'.")
    return TEMPORAL_CONFIG[f"{resolution}_start"], TEMPORAL_CONFIG[f"{resolution}_end"]
```
  </action>
  <verify>
```bash
python -c "
from analysis.config import TEMPORAL_CONFIG, get_analysis_range

print('TEMPORAL_CONFIG:', TEMPORAL_CONFIG)
start, end = get_analysis_range('monthly')
print(f'Monthly range: {start} to {end}')
assert start == '2006-01-01'
assert end == '2025-12-31'
print('get_analysis_range works correctly')
"
```
  </verify>
  <done>
TEMPORAL_CONFIG exists in config.py with daily, monthly, and annual start/end dates. get_analysis_range helper function exists and returns correct tuples.
  </done>
</task>

<task type="auto">
  <name>Add temporal alignment utilities to external_data.py</name>
  <files>analysis/external_data.py</files>
  <action>
Add temporal alignment functions to `analysis/external_data.py`:

```python
def aggregate_crime_by_period(
    crime_df: pd.DataFrame,
    period: str = "D",  # D=daily, W=weekly, M=monthly, Y=yearly
    date_column: str = "dispatch_date",
) -> pd.DataFrame:
    """
    Aggregate crime incidents to a temporal period.

    Args:
        crime_df: DataFrame with crime incidents. Must have date_column.
        period: Pandas resample period code ('D', 'W', 'M', 'Q', 'Y').
        date_column: Name of date column to aggregate by.

    Returns:
        DataFrame with date index and 'crime_count' column.

    Raises:
        ValueError: If date_column not found in DataFrame.

    Note:
        - Daily (D): Full temporal resolution, matches weather data
        - Monthly (M): Matches FRED unemployment data
        - Yearly (Y): Matches Census ACS 5-year estimates

    Example:
        >>> from analysis.utils import load_data
        >>> df = load_data()
        >>> daily = aggregate_crime_by_period(df, 'D')
        >>> monthly = aggregate_crime_by_period(df, 'M')
    """
    if date_column not in crime_df.columns:
        raise ValueError(f"Date column '{date_column}' not found in DataFrame")

    # Ensure date column is datetime
    df = crime_df.copy()
    df[date_column] = pd.to_datetime(df[date_column])

    # Set date as index and count incidents per period
    df = df.set_index(date_column)

    # Resample and count
    aggregated = df.resample(period).size().reset_index(name='crime_count')
    aggregated = aggregated.set_index(date_column)

    return aggregated


def align_temporal_data(
    crime_df: pd.DataFrame,
    weather_df: pd.DataFrame = None,
    unemployment_df: pd.DataFrame = None,
    census_df: pd.DataFrame = None,
    resolution: str = "monthly",
) -> pd.DataFrame:
    """
    Align crime data with external data sources for correlation analysis.

    Handles temporal misalignment between sources:
        - Crime: Daily (2006-2026)
        - Weather: Daily (2006-2026)
        - FRED: Monthly (1990-present)
        - Census ACS: Annual 5-year estimates (2010-present)

    Args:
        crime_df: Crime incident DataFrame. Must have 'dispatch_date' column.
        weather_df: Weather DataFrame with date index. Optional.
        unemployment_df: FRED unemployment DataFrame with date index. Optional.
        census_df: Census DataFrame with year column. Optional.
        resolution: Temporal resolution ('daily', 'monthly', 'annual').

    Returns:
        DataFrame with aligned data. Columns depend on resolution and
        available external data:
            - daily: date, crime_count, tavg, tmin, tmax, prcp
            - monthly: date, crime_count, tavg, prcp, unemployment_rate
            - annual: year, crime_count, unemployment_rate, poverty_rate

        Resolution trade-offs:
            - Daily: Weather only (no economic data due to monthly/annual frequency)
            - Monthly: Weather + unemployment (no Census due to annual frequency)
            - Annual: Weather + unemployment + Census (full alignment but fewer points)

    Raises:
        ValueError: If resolution not recognized or crime_df is empty.

    Example:
        >>> # Monthly alignment with weather and unemployment
        >>> df = align_temporal_data(crime_df, weather_df, unemployment_df, resolution='monthly')
        >>> print(df.columns)
    """
    if resolution not in ("daily", "monthly", "annual"):
        raise ValueError(f"Unknown resolution: {resolution}. Use 'daily', 'monthly', or 'annual'.")

    # Get analysis range from config
    from analysis.config import get_analysis_range
    start_date, end_date = get_analysis_range(resolution)

    # Aggregate crime to specified period
    if resolution == "daily":
        period = "D"
    elif resolution == "monthly":
        period = "M"
    else:  # annual
        period = "Y"

    crime_agg = aggregate_crime_by_period(crime_df, period=period)

    # Filter to analysis range
    crime_agg = crime_agg.loc[start_date:end_date]

    # Initialize result DataFrame with crime counts
    result = crime_agg.rename(columns={'crime_count': 'crime_count'})

    # Align and merge weather data (if provided)
    if weather_df is not None:
        weather_df = weather_df.copy()
        weather_df.index = pd.to_datetime(weather_df.index)

        # Resample weather to match period
        weather_agg = weather_df[['tavg', 'prcp']].resample(period).mean()
        weather_agg = weather_agg.loc[start_date:end_date]

        # Merge
        result = result.join(weather_agg, how='left')

    # Align and merge unemployment data (if provided and not daily)
    if unemployment_df is not None and resolution != "daily":
        unemployment_df = unemployment_df.copy()
        unemployment_df.index = pd.to_datetime(unemployment_df.index)

        # Unemployment is already monthly, just resample if annual
        if resolution == "annual":
            unemployment_agg = unemployment_df.resample("Y").mean()
        else:
            unemployment_agg = unemployment_df

        unemployment_agg = unemployment_agg.loc[start_date:end_date]
        unemployment_agg.columns = ['unemployment_rate']

        # Merge
        result = result.join(unemployment_agg, how='left')

    # Align and merge Census data (if provided and annual only)
    if census_df is not None and resolution == "annual":
        # Census data is at tract level, need to aggregate to city-wide
        # For now, skip as we need district crosswalk (separate plan)
        pass

    # Remove rows with all-NaN external data
    result = result.dropna(how='all', subset=[c for c in result.columns if c != 'crime_count'])

    return result


def create_lagged_features(
    df: pd.DataFrame,
    columns: list = None,
    lags: list = [1, 7, 30],  # 1 day, 1 week, 1 month
) -> pd.DataFrame:
    """
    Create lagged features for cross-correlation analysis.

    Tests whether weather today predicts crime tomorrow, etc.

    Args:
        df: DataFrame with datetime index.
        columns: Columns to create lags for. If None, uses all numeric columns.
        lags: List of lag periods (same units as DataFrame index frequency).

    Returns:
        DataFrame with added {column}_lag{lag} columns.

    Example:
        >>> df = create_lagged_features(weather_df, columns=['tavg'], lags=[1, 7])
        >>> print(df.columns)  # tavg, tavg_lag1, tavg_lag7
    """
    if columns is None:
        columns = df.select_dtypes(include=[np.number]).columns.tolist()

    result = df.copy()

    for col in columns:
        for lag in lags:
            result[f'{col}_lag{lag}'] = result[col].shift(lag)

    return result
```
  </action>
  <verify>
```bash
python -c "
from analysis.external_data import aggregate_crime_by_period, align_temporal_data, create_lagged_features
import pandas as pd

# Test aggregate_crime_by_period
test_df = pd.DataFrame({
    'dispatch_date': pd.date_range('2020-01-01', '2020-01-31'),
    'text_general_code': ['Theft'] * 31
})
daily = aggregate_crime_by_period(test_df, 'D')
print(f'Daily aggregation: {len(daily)} days')
assert 'crime_count' in daily.columns

# Test create_lagged_features
lagged = create_lagged_features(daily, columns=['crime_count'], lags=[1, 7])
print(f'Lagged columns: {[c for c in lagged.columns if \"lag\" in c]}')
assert 'crime_count_lag1' in lagged.columns

print('Temporal alignment functions work correctly')
"
```
  </verify>
  <done>
aggregate_crime_by_period, align_temporal_data, and create_lagged_features functions exist in external_data.py. Functions correctly aggregate crime counts and create lagged features.
  </done>
</task>

</tasks>

<verification>
After completing all tasks:

1. Run the verify command from task 1 to confirm TEMPORAL_CONFIG works
2. Run the verify command from task 2 to confirm alignment functions work
3. Verify temporal alignment documentation: `python -c "from analysis.external_data import align_temporal_data; help(align_temporal_data)"`
4. Check that resolution trade-offs are documented in function docstring
</verification>

<success_criteria>
1. TEMPORAL_CONFIG exists with daily, monthly, annual ranges
2. get_analysis_range helper function exists and returns correct tuples
3. aggregate_crime_by_period function exists and handles D, W, M, Y periods
4. align_temporal_data function exists with resolution parameter
5. Function docstring documents temporal resolution trade-offs
6. create_lagged_features function exists for cross-correlation analysis
</success_criteria>

<output>
After completion, create `.planning/phases/02-external-data-integration/02-04-SUMMARY.md` with:
- TEMPORAL_CONFIG date ranges for each resolution
- Supported periods for aggregation (D, W, M, Y)
- Trade-offs documented (daily=weather only, monthly=weather+FRED, annual=all)
</output>
