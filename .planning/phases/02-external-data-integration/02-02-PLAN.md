---
phase: 02-external-data-integration
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - .venv/pyvenv.cfg
  - analysis/external_data.py
  - .env.example
autonomous: true

user_setup:
  - service: FRED API
    why: "Federal Reserve Economic Data for unemployment rates"
    env_vars:
      - name: FRED_API_KEY
        source: "FRED Dashboard -> My Account -> API Keys"
  - service: U.S. Census API
    why: "American Community Survey data for economic indicators"
    env_vars:
      - name: CENSUS_API_KEY
        source: "Census API Key Signup - request via email form"

must_haves:
  truths:
    - "User can import fetch_fred_data and fetch_census_data from analysis.external_data"
    - "User can fetch Philadelphia County unemployment rate from FRED API"
    - "User can fetch Census ACS economic indicators (income, poverty)"
    - "Economic data is cached locally to avoid rate limits"
  artifacts:
    - path: "analysis/external_data.py"
      provides: "Economic data fetching functions"
      contains: "fetch_fred_data", "fetch_census_data"
    - path: "data/external/unemployment_philly_monthly.parquet"
      provides: "Cached unemployment rate data"
      optional: true
    - path: "data/external/census_tracts_philly.parquet"
      provides: "Cached Census tract data"
      optional: true
  key_links:
    - from: "analysis/correlation_analysis.py"
      to: "analysis/external_data.py"
      via: "from analysis.external_data import fetch_fred_data, fetch_census_data"
      pattern: "from analysis.external_data import"
---

<objective>
Create the economic data ingestion module using FRED API (for unemployment rates) and U.S. Census API (for income, poverty rates). Implement local caching with staleness management to avoid API rate limits (FRED: 120/day, Census: 500/day).

Purpose: Provide reliable access to Philadelphia economic indicators for correlation with crime patterns. Economic data is needed for CORR-02 (crime-economic correlation analysis).

Output: Extended `analysis/external_data.py` with FRED and Census fetching functions, cached economic datasets, and updated .env.example.
</objective>

<execution_context>
@/Users/dustinober/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dustinober/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-external-data-integration/02-RESEARCH.md
@analysis/config.py
@analysis/external_data.py
</context>

<tasks>

<task type="auto">
  <name>Install fredapi and census libraries</name>
  <files>.venv/pyvenv.cfg</files>
  <action>
Install the fredapi and census packages for fetching economic data:

```bash
source .venv/bin/activate
pip install fredapi census python-dotenv requests-cache
```

- fredapi: Wrapper for Federal Reserve Economic Data API (unemployment rates)
- census: Wrapper for U.S. Census Bureau APIs (ACS income, poverty data)
- python-dotenv: For loading API keys from .env file
- requests-cache: For aggressive caching to avoid rate limits
  </action>
  <verify>
```bash
source .venv/bin/activate
python -c "
import fredapi
import census
import dotenv
import requests_cache
print(f'fredapi version: {fredapi.__version__}')
print('All packages imported successfully')
"
```
  </verify>
  <done>
fredapi, census, python-dotenv, and requests-cache are installed in .venv.
  </done>
</task>

<task type="auto">
  <name>Add FRED data fetching to external_data.py</name>
  <files>analysis/external_data.py</files>
  <action>
Add the following to `analysis/external_data.py`:

First, add imports at the top:
```python
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()
```

Then add after the load_cached_weather function:

```python
def fetch_fred_data(
    series_id: str = "PAPHIL5URN",  # Philadelphia County unemployment rate
    start_date: str = "2006-01-01",
    end_date: str = "2026-01-31",
    cache_path: Path = None,
    force_refresh: bool = False,
) -> pd.DataFrame:
    """
    Fetch economic data from FRED (Federal Reserve Economic Data).

    Requires FRED_API_KEY environment variable. Get free key at:
    https://fred.stlouisfed.org/docs/api/api_key.html

    Args:
        series_id: FRED series ID. Default is PAPHIL5URN (Philadelphia County unemployment).
        start_date: Start date in YYYY-MM-DD format.
        end_date: End date in YYYY-MM-DD format.
        cache_path: Path to cache file. If None, uses default.
        force_refresh: If True, bypass cache and fetch from API.

    Returns:
        DataFrame with date index and value column containing the economic indicator.

    Raises:
        ValueError: If FRED_API_KEY not set or API returns no data.

    Example:
        >>> df = fetch_fred_data("PAPHIL5URN", "2020-01-01", "2020-12-31")
        >>> print(df.describe())
    """
    api_key = os.environ.get("FRED_API_KEY")
    if not api_key:
        raise ValueError(
            "FRED_API_KEY environment variable not set. "
            "Get free API key at: https://fred.stlouisfed.org/docs/api/api_key.html"
        )

    if cache_path is None:
        cache_path = EXTERNAL_DATA_DIR / f"fred_{series_id}_{start_date}_{end_date}.parquet"

    # Check cache first
    if cache_path.exists() and not force_refresh:
        return pd.read_parquet(cache_path)

    # Import here to avoid API key requirement on module load
    from fredapi import Fred

    fred = Fred(api_key=api_key)
    try:
        data = fred.get_series(series_id, start=start_date, end=end_date)
    except Exception as e:
        raise ValueError(f"FRED API error: {e}")

    if data.empty:
        raise ValueError(f"No data returned from FRED for series {series_id}")

    df = pd.DataFrame(data, columns=['value'])
    df.index.name = 'date'

    # Ensure cache directory exists
    cache_path.parent.mkdir(parents=True, exist_ok=True)

    # Save to cache
    df.to_parquet(cache_path)

    return df


def load_cached_fred(
    series_id: str = "PAPHIL5URN",
    start_date: str = None,
    end_date: str = None,
) -> pd.DataFrame:
    """
    Load cached FRED data from local parquet file.

    Args:
        series_id: FRED series ID.
        start_date: Optional start date filter.
        end_date: Optional end date filter.

    Returns:
        DataFrame with FRED data. Returns None if cache doesn't exist.
    """
    cache_path = EXTERNAL_DATA_DIR / f"fred_{series_id}_*.parquet"

    # Find matching cache file (wildcard for date range)
    matching_files = list(cache_path.parent.glob(f"fred_{series_id}_*.parquet"))

    if not matching_files:
        return None

    # Use the most recent matching file
    cache_path = sorted(matching_files)[-1]
    df = pd.read_parquet(cache_path)

    if start_date:
        df = df.loc[start_date:]
    if end_date:
        df = df.loc[:end_date]

    return df
```
  </action>
  <verify>
```bash
# This will fail without API key - that's expected
# We're testing the function exists and error handling works
python -c "
from analysis.external_data import fetch_fred_data, load_cached_fred
print('Functions imported successfully')

# Test error handling
try:
    df = fetch_fred_data()
except ValueError as e:
    if 'FRED_API_KEY' in str(e):
        print('Correctly raises error when API key missing')
    else:
        raise
"
```
  </verify>
  <done>
fetch_fred_data and load_cached_fred functions exist, and function correctly raises ValueError when FRED_API_KEY is not set.
  </done>
</task>

<task type="auto">
  <name>Add Census data fetching to external_data.py</name>
  <files>analysis/external_data.py</files>
  <action>
Add the following to `analysis/external_data.py` (after load_cached_fred):

```python
def fetch_census_data(
    variables: tuple = ("B19013_001E", "B17001_002E", "B17001_001E"),
    year: int = 2019,  # Most recent pre-COVID 5-year estimates
    state_fips: str = "42",  # Pennsylvania
    place: str = None,  # Optional: restrict to Philadelphia city
    cache_path: Path = None,
    force_refresh: bool = False,
) -> pd.DataFrame:
    """
    Fetch American Community Survey (ACS) data from U.S. Census Bureau.

    Requires CENSUS_API_KEY environment variable. Get free key at:
    https://api.census.gov/data/key_signup.html

    Default variables:
        - B19013_001E: Median household income (dollars)
        - B17001_002E: Population below poverty line
        - B17001_001E: Population for whom poverty status determined

    Args:
        variables: Tuple of ACS variable IDs to fetch.
        year: Year of ACS 5-year estimates (available 2010-present).
        state_fips: State FIPS code (42 = Pennsylvania).
        place: Optional place FIPS code for city-level filtering.
        cache_path: Path to cache file. If None, uses default.
        force_refresh: If True, bypass cache and fetch from API.

    Returns:
        DataFrame with tract-level data including state, county, tract,
        and requested variables.

    Raises:
        ValueError: If CENSUS_API_KEY not set or API returns no data.

    Example:
        >>> df = fetch_census_data(year=2019)
        >>> print(df.head())
    """
    api_key = os.environ.get("CENSUS_API_KEY")
    if not api_key:
        raise ValueError(
            "CENSUS_API_KEY environment variable not set. "
            "Get free API key at: https://api.census.gov/data/key_signup.html"
        )

    if cache_path is None:
        var_str = "_".join(variables)
        cache_path = EXTERNAL_DATA_DIR / f"census_acs5_{var_str}_{year}.parquet"

    # Check cache first
    if cache_path.exists() and not force_refresh:
        return pd.read_parquet(cache_path)

    # Import here to avoid API key requirement on module load
    from census import Census

    c = Census(api_key)

    # Build query parameters
    params = {'for': 'tract:*', 'in': f'state:{state_fips}'}

    # Add county filter if place specified (Philadelphia County = 101)
    if place == "Philadelphia":
        params['in'] = f'state:{state_fips} county:101'

    try:
        # Fetch data for each variable and merge
        results = []
        for var in variables:
            data = c.acs5.get((var,), params, year=year)
            df_var = pd.DataFrame(data)
            results.append(df_var)

        # Merge all variables
        df = results[0]
        for df_var in results[1:]:
            df = df.merge(df_var, on=['state', 'county', 'tract'], how='outer')

    except Exception as e:
        raise ValueError(f"Census API error: {e}")

    if df.empty:
        raise ValueError(f"No data returned from Census API for year {year}")

    # Create a geographic identifier
    df['geo_id'] = df['state'] + df['county'] + df['tract']

    # Calculate poverty rate if both numerator and denominator present
    if "B17001_002E" in variables and "B17001_001E" in variables:
        df['poverty_rate'] = (
            pd.to_numeric(df['B17001_002E'], errors='coerce') /
            pd.to_numeric(df['B17001_001E'], errors='coerce') * 100
        )

    # Ensure cache directory exists
    cache_path.parent.mkdir(parents=True, exist_ok=True)

    # Save to cache
    df.to_parquet(cache_path)

    return df


def load_cached_census(
    variables: tuple = ("B19013_001E", "B17001_002E", "B17001_001E"),
    year: int = 2019,
) -> pd.DataFrame:
    """
    Load cached Census ACS data from local parquet file.

    Args:
        variables: Tuple of ACS variable IDs.
        year: Year of ACS data.

    Returns:
        DataFrame with Census data. Returns None if cache doesn't exist.
    """
    var_str = "_".join(variables)
    cache_path = EXTERNAL_DATA_DIR / f"census_acs5_{var_str}_{year}.parquet"

    if not cache_path.exists():
        return None

    return pd.read_parquet(cache_path)
```
  </action>
  <verify>
```bash
# Test function exists and error handling
python -c "
from analysis.external_data import fetch_census_data, load_cached_census
print('Functions imported successfully')

# Test error handling
try:
    df = fetch_census_data()
except ValueError as e:
    if 'CENSUS_API_KEY' in str(e):
        print('Correctly raises error when API key missing')
    else:
        raise
"
```
  </verify>
  <done>
fetch_census_data and load_cached_census functions exist, and function correctly raises ValueError when CENSUS_API_KEY is not set.
  </done>
</task>

<task type="auto">
  <name>Update .env.example with economic API documentation</name>
  <files>.env.example</files>
  <action>
Update `.env.example` to include full documentation:

```bash
# =============================================================================
# External Data API Keys
# =============================================================================
# Copy this file to .env and add your actual API keys
# All API keys are FREE - no payment required

# -----------------------------------------------------------------------------
# FRED API Key (Federal Reserve Economic Data)
# -----------------------------------------------------------------------------
# Purpose: Unemployment rate data (PAPHIL5URN for Philadelphia County)
# Rate Limit: 120 requests per day
# Get free key at: https://fred.stlouisfed.org/docs/api/api_key.html
# 1. Sign in or create account (free)
# 2. Go to "My Account" -> "API Keys"
# 3. Click "Request API Key" (instant approval)
FRED_API_KEY=your_fred_api_key_here

# -----------------------------------------------------------------------------
# U.S. Census API Key
# -----------------------------------------------------------------------------
# Purpose: American Community Survey (ACS) economic indicators
# Variables: Median income (B19013_001E), poverty rate (B17001_002E/B17001_001E)
# Rate Limit: 500 requests per day
# Get free key at: https://api.census.gov/data/key_signup.html
# 1. Complete the request form (email, organization, purpose)
# 2. API key emailed within 24-48 hours (usually faster)
CENSUS_API_KEY=your_census_api_key_here
```
  </action>
  <verify>
```bash
# Check .env.example has proper documentation
grep -q "FRED_API_KEY" .env.example && echo "FRED key documented"
grep -q "CENSUS_API_KEY" .env.example && echo "Census key documented"
grep -q "https://fred.stlouisfed.org" .env.example && echo "FRED URL present"
grep -q "https://api.census.gov" .env.example && echo "Census URL present"
```
  </verify>
  <done>
.env.example contains FRED_API_KEY and CENSUS_API_KEY with complete documentation including purpose, rate limits, and signup URLs.
  </done>
</task>

</tasks>

<verification>
After completing all tasks:

1. Run the verify command from task 2 to confirm FRED functions exist
2. Run the verify command from task 3 to confirm Census functions exist
3. Check that all packages are installed: `python -c "import fredapi, census, dotenv, requests_cache; print('All OK')"`
4. Verify .env.example has complete API documentation
5. Confirm functions correctly raise errors when API keys are missing
</verification>

<success_criteria>
1. fredapi, census, python-dotenv, requests-cache are installed
2. external_data.py has fetch_fred_data, load_cached_fred, fetch_census_data, load_cached_census functions
3. FRED function correctly defaults to PAPHIL5URN (Philadelphia unemployment)
4. Census function correctly defaults to median income and poverty variables
5. Both functions raise ValueError with helpful message when API keys missing
6. .env.example has complete signup instructions for both APIs
</success_criteria>

<output>
After completion, create `.planning/phases/02-external-data-integration/02-02-SUMMARY.md` with:
- Package versions installed (fredapi, census, python-dotenv, requests-cache)
- FRED series ID configured (PAPHIL5URN)
- Census variables configured (B19013_001E, B17001_002E, B17001_001E)
- Note: Actual data fetching requires API keys (user setup needed)
</output>
