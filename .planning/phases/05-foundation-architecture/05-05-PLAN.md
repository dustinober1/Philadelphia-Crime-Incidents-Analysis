---
phase: 05-foundation-architecture
plan: 05
type: execute
wave: 2
depends_on: ["05-04"]
files_modified:
  - (environment - no files modified, packages installed)
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "Developer can run 'black --check analysis/' and code is formatted consistently"
    - "Developer can run 'ruff check analysis/' and see zero linting errors"
    - "Developer can run 'mypy analysis/' and see type checking results (zero errors in new modules)"
    - "Developer can run 'pytest tests/' and tests execute (coverage report will be low until tests are created)"
  artifacts:
    - path: "(environment)"
      provides: "Installed development dependencies"
      packages_installed: ["pytest>=8.0", "pytest-cov>=6.0", "black>=25.0", "ruff>=0.9", "mypy>=1.15", "pre-commit>=4.0"]
  key_links:
    - from: "requirements-dev.txt"
      to: "installed packages"
      via: "pip install -r requirements-dev.txt"
      pattern: "packages available in environment"
    - from: "pyproject.toml"
      to: "quality tools"
      via: "tool configuration read by black, ruff, mypy, pytest"
      pattern: "tools use pyproject.toml config"
---

<objective>
Install development dependencies and verify quality tools work as configured.

Purpose: The verification report identified that quality tools (black, ruff, mypy, pytest) are configured in pyproject.toml and listed in requirements-dev.txt, but not installed in the crime environment. This prevents verification of PEP 8 compliance (QUAL-01) and blocks pre-commit hooks from working.

Output: All development dependencies installed in the crime environment, quality tools verified to work correctly with existing configuration.
</objective>

<execution_context>
@/Users/dustinober/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dustinober/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-foundation-architecture/05-VERIFICATION.md
@.planning/phases/05-foundation-architecture/05-03-SUMMARY.md

@requirements-dev.txt
@pyproject.toml
@environment.yml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install development dependencies from requirements-dev.txt</name>
  <files>requirements-dev.txt</files>
  <action>
    Install all development dependencies using pip in the active conda environment:

    1. Verify the crime conda environment is active:
       ```bash
       conda activate crime
       ```

    2. Install packages from requirements-dev.txt:
       ```bash
       pip install -r requirements-dev.txt
       ```

    3. Verify installation by checking key packages:
       ```bash
       python -c "import pytest, black, ruff, mypy, pre_commit, pydantic, joblib; print('All imports work')"
       ```

    4. Verify tool versions:
       ```bash
       pytest --version
       black --version
       ruff --version
       mypy --version
       pre-commit --version
       ```

    Note: Some packages (pydantic, joblib) may already be installed via conda. pip will skip or upgrade as needed.
  </action>
  <verify>
    Run: `python -c "import pytest, black, ruff, mypy, pre_commit; print('All dev dependencies installed')"`. Expected: "All dev dependencies installed" with no ImportError.
  </verify>
  <done>
    - All packages from requirements-dev.txt installed successfully
    - pytest, black, ruff, mypy, pre-commit commands work
    - All imports succeed without errors
  </done>
</task>

<task type="auto">
  <name>Task 2: Verify black configuration and code formatting</name>
  <files>pyproject.toml</files>
  <action>
    Verify black reads configuration from pyproject.toml and check code formatting:

    1. Verify black config:
       ```bash
       black --config pyproject.toml --help
       ```

    2. Check formatting on new modules (without making changes):
       ```bash
       black --check analysis/utils/ analysis/data/
       ```

    3. If black reports formatting issues, format the code:
       ```bash
       black analysis/utils/ analysis/data/
       ```

    4. Verify formatted code still passes:
       ```bash
       black --check analysis/utils/ analysis/data/
       ```

    Expected: black should report either "no reformatting needed" (code already compliant) or format and pass on second run.
  </action>
  <verify>
    Run: `black --check analysis/utils/ analysis/data/ --config pyproject.toml`. Expected: "no reformatting needed" or similar success message (no errors).
  </verify>
  <done>
    - black reads configuration from pyproject.toml correctly
    - All code in analysis/utils/ and analysis/data/ passes black formatting check
    - Line length 100 enforced
  </done>
</task>

<task type="auto">
  <name>Task 3: Verify ruff configuration and linting</name>
  <files>pyproject.toml</files>
  <action>
    Verify ruff reads configuration from pyproject.toml and check code linting:

    1. Verify ruff config:
       ```bash
       ruff check --config pyproject.toml --help
       ```

    2. Run linting on new modules:
       ```bash
       ruff check analysis/utils/ analysis/data/
       ```

    3. If ruff reports errors, attempt auto-fix:
       ```bash
       ruff check analysis/utils/ analysis/data/ --fix
       ```

    4. Verify fixed code passes:
       ```bash
       ruff check analysis/utils/ analysis/data/
       ```

    Expected: ruff should report either zero violations or fixable issues that are resolved with --fix.
  </action>
  <verify>
    Run: `ruff check analysis/utils/ analysis/data/ --config pyproject.toml`. Expected: Zero violations or only fixable issues resolved by --fix.
  </verify>
  <done>
    - ruff reads configuration from pyproject.toml correctly
    - All code in analysis/utils/ and analysis/data/ passes ruff linting
    - E/W/F/I/B/C4/UP/ARG/SIM rules enforced
  </done>
</task>

<task type="auto">
  <name>Task 4: Verify mypy configuration and type checking</name>
  <files>pyproject.toml</files>
  <action>
    Verify mypy reads configuration from pyproject.toml and check type safety:

    1. Verify mypy config:
       ```bash
       mypy --config-file pyproject.toml --help
       ```

    2. Run mypy on utils modules (should pass after 05-04 fixes):
       ```bash
       mypy analysis/utils/classification.py analysis/utils/temporal.py --config-file pyproject.toml
       ```

    3. Run mypy on data layer (should pass after 05-04 fixes):
       ```bash
       mypy analysis/data/loading.py analysis/data/validation.py analysis/data/preprocessing.py analysis/data/cache.py --config-file pyproject.toml
       ```

    4. Run mypy on entire analysis package:
       ```bash
       mypy analysis/ --config-file pyproject.toml
       ```

    Expected: Zero errors in new modules (classification, temporal, loading, validation, preprocessing, cache). Other modules may have external package issues (ignored in config).
  </action>
  <verify>
    Run: `mypy analysis/utils/ analysis/data/ --config-file pyproject.toml`. Expected: "Success: no issues found" for new modules (external packages ignored via overrides).
  </verify>
  <done>
    - mypy reads configuration from pyproject.toml correctly
    - All new modules pass strict type checking
    - warn_unused_ignores, disallow_untyped_defs enforced
  </done>
</task>

<task type="auto">
  <name>Task 5: Verify pytest configuration and test execution</name>
  <files>pyproject.toml</files>
  <action>
    Verify pytest reads configuration from pyproject.toml and can run tests:

    1. Verify pytest config:
       ```bash
       pytest --version
       pytest --help | grep "pyproject.toml"
       ```

    2. List discoverable tests:
       ```bash
       pytest --collect-only tests/
       ```

    3. Run existing tests (will show low coverage until new tests are created):
       ```bash
       pytest tests/ -v
       ```

    4. Run with coverage (will fail 90% target, this is expected):
       ```bash
       pytest tests/ --cov=analysis --cov-report=term-missing
       ```

    Expected: pytest discovers and runs test_phase2_spatial.py. Coverage will be low (<5%) because tests for new modules don't exist yet (created in 05-06, 05-07).
  </action>
  <verify>
    Run: `pytest tests/ --cov=analysis --cov-report=term-missing -v`. Expected: Tests run successfully (coverage will be low, this is expected).
  </verify>
  <done>
    - pytest reads configuration from pyproject.toml correctly
    - Tests execute and produce coverage report
    - Coverage failure (90% target) is expected - will be fixed in 05-06, 05-07
  </done>
</task>

<task type="auto">
  <name>Task 6: Install and verify pre-commit hooks</name>
  <files>pre-commit-config.yaml</files>
  <action>
    Install pre-commit hooks and verify they work:

    1. Install pre-commit hooks in git repository:
       ```bash
       pre-commit install
       ```

    2. Verify hooks are installed:
       ```bash
       pre-commit run --all-files
       ```

    3. If hooks fail, this is expected for existing code. The hooks are configured correctly for new code going forward.

    4. Test hooks on a new file (optional verification):
       ```bash
       echo "import pandas as pd

def test_example():
    assert True" > tests/test_example.py
       pre-commit run tests/test_example.py --files
       rm tests/test_example.py
       ```

    Expected: pre-commit installs hooks successfully. Running on all files may fail on existing code (this is OK - hooks enforce standards on new commits).
  </action>
  <verify>
    Run: `pre-commit install && pre-commit run --all-files`. Expected: Hooks install successfully and run (may fail on existing code, this is OK).
  </verify>
  <done>
    - pre-commit hooks installed in .git/hooks/
    - black, ruff, mypy, pytest hooks configured
    - Hooks run when files are committed
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. Verify all quality tools installed:
   ```bash
   python -c "import pytest, black, ruff, mypy, pre_commit; print('All tools installed')"
   ```
   Expected: "All tools installed"

2. Verify quality tools work on new modules:
   ```bash
   black --check analysis/utils/ analysis/data/
   ruff check analysis/utils/ analysis/data/
   mypy analysis/utils/ analysis/data/
   ```
   Expected: All pass with zero violations

3. Verify pytest works (low coverage is OK):
   ```bash
   pytest tests/ --cov=analysis --cov-report=term-missing
   ```
   Expected: Tests run, coverage report generated (will be <5%)

4. Verify pre-commit hooks installed:
   ```bash
   ls .git/hooks/pre-commit
   ```
   Expected: pre-commit hook file exists
</verification>

<success_criteria>
1. All packages from requirements-dev.txt installed
2. black, ruff, mypy, pytest run successfully
3. black and ruff pass on new modules (utils, data)
4. mypy passes on new modules (after 05-04 fixes)
5. pytest runs existing tests (coverage will be low until 05-06, 05-07)
6. pre-commit hooks installed
</success_criteria>

<output>
After completion, create `.planning/phases/05-foundation-architecture/05-05-SUMMARY.md`
</output>
