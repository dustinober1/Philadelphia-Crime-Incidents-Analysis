---
phase: 11-core-module-testing
plan: 06
type: execute
wave: 4
depends_on: [11-01, 11-02, 11-03, 11-04, 11-05]
files_modified:
  - .planning/phases/11-core-module-testing/11-06-COVERAGE.txt
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Coverage report shows 60-70% overall coverage for core modules"
    - "All 10 core modules (models/, data/, utils/) have tests"
    - "Tests pass with pytest -nauto"
    - "Coverage report saved to phase directory"
  artifacts:
    - path: ".planning/phases/11-core-module-testing/11-06-COVERAGE.txt"
      provides: "Coverage report for Phase 11 verification"
      min_lines: 50
  key_links:
    - from: "11-06-COVERAGE.txt"
      to: "tests/"
      via: "pytest --cov execution"
      pattern: "pytest.*--cov"
---

<objective>
Run comprehensive coverage report for all core modules (models/, data/, utils/) to verify 60-70% overall coverage milestone achieved. Identify any remaining gaps and document coverage status.

**Purpose:** Verify CORE-04 requirement (60-70% overall coverage for core modules) is met. Provide baseline for Phases 12-13.

**Output:** Coverage report saved to phase directory with per-module breakdown and overall summary.
</objective>

<execution_context>
@/Users/dustinober/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dustinober/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/11-core-module-testing/11-RESEARCH.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Lock honored decisions from Phase 10
- pytest-xdist: Use -nauto for local development
- Branch coverage: Set branch=true
- Multi-format reports: XML, terminal-missing, HTML
- Coverage threshold: Place fail_under in [tool.coverage.report] section
</context>

<tasks>

<task type="auto">
  <name>Run coverage report for all core modules</name>
  <files>.planning/phases/11-core-module-testing/11-06-COVERAGE.txt</files>
  <action>
    Run pytest with coverage for all core modules (analysis/models, analysis/data, analysis/utils):

    ```bash
    pytest tests/test_models_*.py tests/test_data_*.py tests/test_utils_*.py \
      --cov=analysis.models \
      --cov=analysis.data \
      --cov=analysis.utils \
      --cov-report=term-missing \
      --cov-report=html \
      --cov-report=xml \
      -nauto \
      -v
    ```

    Save the terminal output to the phase directory:

    ```bash
    pytest tests/test_models_*.py tests/test_data_*.py tests/test_utils_*.py \
      --cov=analysis.models \
      --cov=analysis.data \
      --cov=analysis.utils \
      --cov-report=term-missing \
      -nauto \
      > .planning/phases/11-core-module-testing/11-06-COVERAGE.txt 2>&1
    ```

    Run from project root directory.
  </action>
  <verify>cat .planning/phases/11-core-module-testing/11-06-COVERAGE.txt</verify>
  <done>Coverage report generated and saved to phase directory</done>
</task>

<task type="auto">
  <name>Verify overall coverage meets 60-70% milestone</name>
  <files>.planning/phases/11-core-module-testing/11-06-COVERAGE.txt</files>
  <action>
    Parse the coverage report to verify:

    1. **Overall coverage** for analysis.models, analysis.data, analysis.utils combined is 60-70%
    2. **Per-module coverage** for each of the 10 core modules:
       - analysis.models/classification.py: 80%+
       - analysis.models/time_series.py: 80%+
       - analysis.models/validation.py: 80%+
       - analysis.utils/spatial.py: 80%+
       - analysis.data/loading.py: 80%+
       - analysis.data/cache.py: 80%+
       - analysis.data/validation.py: 80%+ (existing tests)
       - analysis.data/preprocessing.py: 90%+ (existing tests)
       - analysis.utils/classification.py: 95%+ (existing tests)
       - analysis.utils/temporal.py: 95%+ (existing tests)

    3. **All tests pass** (no FAIL or ERROR in output)

    If overall coverage is below 60%, identify which modules need additional tests. If overall coverage is above 70%, document that milestone exceeded.

    Extract key lines from coverage report:
    - TOTAL line with overall percentage
    - Per-module lines (Name, Stmts, Miss, Cover, Missing)
  </action>
  <verify>grep -E "(TOTAL|analysis\.(models|data|utils))" .planning/phases/11-core-module-testing/11-06-COVERAGE.txt</verify>
  <done>Overall coverage 60-70% confirmed; per-module breakdown documented</done>
</task>

<task type="auto">
  <name>Generate HTML coverage report for visual review</name>
  <files>htmlcov/index.html</files>
  <action>
    Generate HTML coverage report for detailed per-line coverage visualization:

    ```bash
    pytest tests/test_models_*.py tests/test_data_*.py tests/test_utils_*.py \
      --cov=analysis.models \
      --cov=analysis.data \
      --cov=analysis.utils \
      --cov-report=html:htmlcov \
      --cov-report=term-missing \
      -nauto
    ```

    Verify htmlcov/index.html was created. List key files for visual inspection:
    - htmlcov/analysis_models_classification.html
    - htmlcov/analysis_models_time_series.html
    - htmlcov/analysis_models_validation.html
    - htmlcov/analysis_utils_spatial.html
    - htmlcov/analysis_data_loading.html
    - htmlcov/analysis_data_cache.html

    Document any files with <80% coverage for follow-up in Phases 12-13.
  </action>
  <verify>ls -la htmlcov/ | grep "analysis_"</verify>
  <done>HTML coverage report generated; files with <80% coverage documented</done>
</task>

<task type="auto">
  <name>Document coverage status and create summary</name>
  <files>.planning/phases/11-core-module-testing/11-06-SUMMARY.md</files>
  <action>
    Create 11-06-SUMMARY.md documenting:

    **Coverage Summary:**
    - Overall coverage percentage
    - Per-module coverage table
    - Tests added in Phase 11 (counts per module)
    - Total test count for core modules

    **Modules Meeting 80%+ Target:**
    - List modules achieving 80%+ coverage

    **Modules Below 80% (if any):**
    - List modules with <80% coverage
    - Identify specific functions/lines needing tests
    - Recommend follow-up actions for Phases 12-13

    **Verification of CORE Requirements:**
    - CORE-01: models/ modules tested (yes/no)
    - CORE-02: data/ modules tested (yes/no)
    - CORE-03: utils/ modules tested (yes/no)
    - CORE-04: 60-70% overall coverage achieved (percentage)

    **Next Steps:**
    - Phases 12-13 will test api/, pipeline/, CLI modules
    - Target 95% overall coverage by Phase 15

    Include grep command output showing coverage totals.
  </action>
  <verify>cat .planning/phases/11-core-module-testing/11-06-SUMMARY.md</verify>
  <done>Summary document created with coverage status and next steps</done>
</task>

</tasks>

<verification>
- Coverage report saved to .planning/phases/11-core-module-testing/11-06-COVERAGE.txt
- Overall coverage is 60-70% for core modules (models/, data/, utils/)
- All 10 core modules have tests
- All tests pass with pytest -nauto
- HTML coverage report generated in htmlcov/
- Summary document created with verification of CORE-01 through CORE-04
</verification>

<success_criteria>
- Coverage report shows 60-70% overall coverage
- All 10 core modules have tests (either new or verified existing)
- CORE-01 through CORE-04 requirements verified
- HTML coverage report available for visual review
- Summary documents any gaps for follow-up in Phases 12-13
</success_criteria>

<output>
After completion, create `.planning/phases/11-core-module-testing/11-06-SUMMARY.md`
</output>
