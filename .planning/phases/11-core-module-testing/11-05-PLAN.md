---
phase: 11-core-module-testing
plan: 05
type: execute
wave: 3
depends_on: []
files_modified:
  - tests/test_data_loading.py
  - tests/test_data_cache.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - "tests/test_data_loading.py exists with additional tests for uncovered branches"
    - "tests/test_data_cache.py exists with cache configuration tests"
    - "All functions in data/loading.py and data/cache.py have test coverage"
    - "Tests mock file I/O operations"
  artifacts:
    - path: "tests/test_data_loading.py"
      provides: "Unit tests for data loading functions"
      min_lines: 300
      exports: ["TestLoadCrimeData", "TestLoadBoundaries", "TestLoadExternalData", "TestInternalLoadFunctions", "TestMemoryInstance", "TestGeopandasImport", "TestFileNotFoundError"]
    - path: "tests/test_data_cache.py"
      provides: "Unit tests for cache configuration"
      min_lines: 100
      exports: ["TestMemoryInstance", "TestClearCache", "TestCacheDirectory"]
  key_links:
    - from: "tests/test_data_loading.py"
      to: "analysis/data/loading.py"
      via: "import and function call testing"
      pattern: "from analysis.data.loading import"
    - from: "tests/test_data_cache.py"
      to: "analysis/data/cache.py"
      via: "import and function call testing"
      pattern: "from analysis.data.cache import"
---

<objective>
Add targeted tests for data/loading.py and create new tests for data/cache.py. Mock file I/O operations to test error handling and caching behavior without real data files.

**Purpose:** Ensure data loading and caching functions are tested. Test FileNotFoundError handling, datetime parsing, cache configuration, and cache invalidation.

**Output:** Enhanced test_data_loading.py and new test_data_cache.py with 25-35 total tests.
</objective>

<execution_context>
@/Users/dustinober/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dustinober/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/11-core-module-testing/11-RESEARCH.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Lock honored decisions from Phase 10
- pytest-xdist: Use -nauto for local development
- Branch coverage: Set branch=true
- Testing priority: High-priority modules (data processing, validation, utilities) first

# Reference existing patterns
@tests/conftest.py
@tests/test_data_loading.py (existing)
@tests/test_data_validation.py
</context>

<tasks>

<task type="auto">
  <name>Create test_data_cache.py with cache configuration tests</name>
  <files>tests/test_data_cache.py</files>
  <action>
    Create tests/test_data_cache.py with the following test structure:

    **Class TestMemoryInstance:**
    - test_memory_instance_exists: Verify memory is not None
    - test_memory_has_location_attribute: Verify memory has 'location' attribute
    - test_memory_location_points_to_cache_dir: Verify memory.location is project root/.cache/joblib
    - test_memory_verbose_is_zero: Verify memory.verbose == 0 (silent operation)

    **Class TestClearCache:**
    - test_clear_cache_removes_cached_files: Verify cache directory empty after clear_cache()
    - test_clear_cache_prints_confirmation: Verify function prints "Cache cleared:" message
    - test_clear_cache_handles_nonexistent_cache: Verify no error when cache doesn't exist
    - test_clear_cache_preserves_cache_directory: Verify _CACHE_DIR still exists after clearing

    **Class TestCacheDirectory:**
    - test_cache_dir_exists_after_import: Verify _CACHE_DIR created on module import
    - test_cache_dir_is_absolute_path: Verify _CACHE_DIR is absolute Path
    - test_cache_dir_name_is_joblib: Verify cache directory name is 'joblib'
    - test_cache_dir_under_project_cache: Verify _CACHE_DIR is project_root/.cache/joblib

    Use unittest.mock.patch for file system operations. Mock Path.iterdir() to return mock file list. Verify print statements with io.StringIO capture.
  </action>
  <verify>pytest tests/test_data_cache.py -v</verify>
  <done>15 tests pass for cache configuration</done>
</task>

<task type="auto">
  <name>Add targeted tests to test_data_loading.py for uncovered branches</name>
  <files>tests/test_data_loading.py</files>
  <action>
    First, run coverage on existing test_data_loading.py to identify gaps:

    ```bash
    pytest tests/test_data_loading.py --cov=analysis.data.loading --cov-report=term-missing
    ```

    Based on coverage gaps, add the following test classes if missing:

    **TestFileNotFoundErrorHandling:**
    - test_load_crime_data_raises_file_not_found: Mock CRIME_DATA_PATH to nonexistent path, verify FileNotFoundError raised with "Crime data not found" message
    - test_load_boundaries_raises_file_not_found: Mock boundary file to nonexistent, verify FileNotFoundError raised
    - test_internal_function_raises_on_missing_parquet: Verify _load_crime_data_parquet raises FileNotFoundError for missing file

    **TestDatetimeParsing:**
    - test_dispatch_date_parsed_from_category_dtype: Mock parquet file with dispatch_date as category dtype, verify parsed to datetime64
    - test_dispatch_date_timezone_handling: Verify datetime parsing handles timezone-aware datetimes (if applicable)

    **TestCleanParameter:**
    - test_clean_false_preserves_null_dates: Verify rows with null dispatch_date preserved when clean=False
    - test_clean_true_drops_null_dates: Verify rows with null dispatch_date dropped when clean=True
    - test_clean_parameter_in_cache_key: Verify clean=True and clean=False use separate cache entries

    **TestBoundaryNameValidation:**
    - test_invalid_boundary_name_raises_value_error: Test boundary names other than 'police_districts', 'census_tracts', 'census_tracts_pop'
    - test_boundary_name_case_sensitivity: Verify boundary name matching is case-sensitive
    - test_census_tracts_pop_alias_works: Verify 'census_tracts_pop' loads same file as 'census_tracts'

    Use unittest.mock.patch to mock CRIME_DATA_PATH, BOUNDARY_DATA_PATH, and pandas.read_parquet.
  </action>
  <verify>pytest tests/test_data_loading.py --cov=analysis.data.loading --cov-report=term-missing</verify>
  <done>Coverage report shows 80%+ for data/loading.py with all branches covered</done>
</task>

<task type="auto">
  <name>Run combined coverage report for data/loading.py and data/cache.py</name>
  <files>tests/test_data_loading.py, tests/test_data_cache.py</files>
  <action>
    Run pytest with coverage for both modules:

    ```bash
    pytest tests/test_data_loading.py tests/test_data_cache.py --cov=analysis.data.loading --cov=analysis.data.cache --cov-report=term-missing --cov-report=html
    ```

    Target: 80%+ coverage for both data/loading.py and data/cache.py.

    If coverage is below 80% for either module, identify missing branches:
    - Check for untested error paths (FileNotFoundError, ValueError)
    - Check for edge cases (empty files, malformed data)
    - Check for caching behavior variations

    Document final coverage percentages in plan summary.

    Note: test_data_loading.py already exists with 31 tests. Focus on adding tests only for uncovered branches, not rewriting existing tests.
  </action>
  <verify>pytest tests/test_data_loading.py tests/test_data_cache.py --cov=analysis.data.loading --cov=analysis.data.cache --cov-report=term-missing</verify>
  <done>Coverage report shows 80%+ for both data/loading.py and data/cache.py</done>
</task>

</tasks>

<verification>
- All tests in test_data_cache.py pass with pytest -nauto
- Updated tests in test_data_loading.py pass with pytest -nauto
- Coverage report shows 80%+ for data/loading.py
- Coverage report shows 80%+ for data/cache.py
- No tests load real data files (all file I/O mocked)
- All tests follow behavior-focused pattern from TESTING_QUALITY_CRITERIA.md
</verification>

<success_criteria>
- test_data_cache.py created with 10-15 tests
- test_data_loading.py enhanced with 5-10 additional tests for uncovered branches
- 80%+ coverage achieved for both data/loading.py and data/cache.py
- All tests pass with pytest -nauto in under 30 seconds
- File I/O operations mocked to avoid slow disk access
</success_criteria>

<output>
After completion, create `.planning/phases/11-core-module-testing/11-05-SUMMARY.md`
</output>
