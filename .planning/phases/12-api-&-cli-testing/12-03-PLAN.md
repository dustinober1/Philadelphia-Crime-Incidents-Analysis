---
phase: 12-api-&-cli-testing
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/test_api_endpoints.py
autonomous: true

must_haves:
  truths:
    - "All 4 policy API endpoints return 200 status code"
    - "Policy endpoints return correctly structured JSON data"
    - "Policy analysis endpoints have expected data fields"
    - "Error handling for missing policy data is tested"
  artifacts:
    - path: "tests/test_api_endpoints.py"
      provides: "Test suite for policy API endpoints"
      min_lines: 150
  key_links:
    - from: "tests/test_api_endpoints.py"
      to: "api/routers/policy.py"
      via: "TestClient"
      pattern: "client\.get\('/api/v1/policy"
---

<objective>
Write integration tests for all 4 policy analysis endpoints using FastAPI TestClient.

Purpose: Ensure all policy endpoints (/retail-theft, /vehicle-crimes, /composition, /events) are properly tested with request/response contract validation.

Output: Extended test_api_endpoints.py with comprehensive tests for all policy endpoints.
</objective>

<execution_context>
@/Users/dustinober/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dustinober/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/12-api-&-cli-testing/12-RESEARCH.md
@tests/test_api_endpoints.py
@api/routers/policy.py
@api/services/data_loader.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add tests for all 4 policy analysis endpoints</name>
  <files>tests/test_api_endpoints.py</files>
  <action>
Add integration tests for the 4 policy endpoints in test_api_endpoints.py:

1. **test_policy_retail_theft()** - Test GET /api/v1/policy/retail-theft
   - Verify response status is 200
   - Verify response is a list
   - Verify each row has expected keys (year, month, retail_theft_count, trend)

2. **test_policy_vehicle_crimes()** - Test GET /api/v1/policy/vehicle-crimes
   - Verify response status is 200
   - Verify response is a list
   - Verify each row has vehicle crime data fields

3. **test_policy_composition()** - Test GET /api/v1/policy/composition
   - Verify response status is 200
   - Verify response is a list
   - Verify composition breakdown by crime category

4. **test_policy_events()** - Test GET /api/v1/policy/events
   - Verify response status is 200
   - Verify response is a list
   - Verify event impact analysis data is present

Use the existing TestClient pattern. Load real data using setup_module().
Focus on data structure validation rather than specific values (data changes).
  </action>
  <verify>Run pytest tests/test_api_endpoints.py -v -k "policy" and verify all new tests pass</verify>
  <done>All 4 policy endpoints have passing tests with data structure validation</done>
</task>

<task type="auto">
  <name>Task 2: Add policy endpoint data validation tests</name>
  <files>tests/test_api_endpoints.py</files>
  <action>
Add detailed data validation tests for policy endpoints:

1. **test_policy_retail_theft_trend_data()**
   - Verify retail theft data has temporal coverage (multiple years)
   - Verify trend direction is present (increasing/decreasing)
   - Verify data is sorted chronologically

2. **test_policy_vehicle_crimes_categories()**
   - Verify vehicle crime categories are present (motor theft, theft from vehicle)
   - Verify data has time series coverage
   - Verify count fields are non-negative integers

3. **test_policy_composition_breakdown()**
   - Verify composition data includes major crime categories
   - Verify percentage totals are reasonable (approximately 100%)
   - Verify year-over-year comparison fields exist

4. **test_policy_events_impact_metrics()**
   - Verify event data includes impact metrics
   - Verify pre/post event comparison exists
   - Verify event types are represented (sports, concerts, etc.)

Add these tests to test_api_endpoints.py.
Use pytest.approx for float comparisons where needed.
  </action>
  <verify>Run pytest tests/test_api_endpoints.py -v -k "policy" and verify data validation tests pass</verify>
  <done>Policy endpoint data is validated for completeness, structure, and logical consistency</done>
</task>

<task type="auto">
  <name>Task 3: Add policy endpoint error handling tests</name>
  <files>tests/test_api_endpoints.py</files>
  <action>
Add error handling tests for policy endpoints:

1. **test_policy_endpoint_missing_data()**
   - Use monkeypatch to remove policy data keys from _DATA_CACHE
   - Call each policy endpoint
   - Verify 500 status is returned
   - Verify error response structure

2. **test_policy_empty_dataset()**
   - Use monkeypatch to set policy data to empty list
   - Verify endpoint returns 200 with empty list
   - Tests graceful handling of empty results

Pattern: Use monkeypatch.setattr("api.services.data_loader._DATA_CACHE", {}).
  </action>
  <verify>Run pytest tests/test_api_endpoints.py -v -k "policy" and verify error handling tests pass</verify>
  <done>Error paths for policy endpoints are tested, including missing data and empty datasets</done>
</task>

</tasks>

<verification>
After completion, verify:
1. Run pytest tests/test_api_endpoints.py -v -k "policy" and count passing tests
2. All 4 policy endpoints (/retail-theft, /vehicle-crimes, /composition, /events) have tests
3. Data validation includes field presence, data types, and logical consistency
4. At least 7 new policy-focused tests pass
5. Coverage includes happy path, data validation, and error handling
</verification>

<success_criteria>
1. All 4 policy API endpoints have integration tests
2. Tests validate response structure and expected data fields
3. Data consistency is validated (chronological order, non-negative counts, etc.)
4. Error handling is tested for missing policy data
5. All tests follow existing TestClient patterns
</success_criteria>

<output>
After completion, create .planning/phases/12-api-&-cli-testing/12-03-SUMMARY.md with:
- Number of tests added for policy endpoints
- Coverage percentage for api/routers/policy.py
- Any data quality issues discovered
</output>
