---
phase: 12-api-&-cli-testing
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/test_api_endpoints.py
autonomous: true

must_haves:
  truths:
    - "All 5 trends API endpoints return 200 status code"
    - "Trends endpoints return correctly structured JSON data"
    - "Query parameter filtering works (category, start_year, end_year)"
    - "Error handling paths are tested (missing data keys)"
  artifacts:
    - path: "tests/test_api_endpoints.py"
      provides: "Test suite for trends API endpoints"
      min_lines: 150
  key_links:
    - from: "tests/test_api_endpoints.py"
      to: "api/routers/trends.py"
      via: "TestClient"
      pattern: "client\.get\('/api/v1/trends"
---

<objective>
Write integration tests for all 5 trends API endpoints using FastAPI TestClient.

Purpose: Ensure all trends endpoints (/annual, /monthly, /covid, /seasonality, /robbery-heatmap) are properly tested with request/response contract validation and error handling.

Output: Extended test_api_endpoints.py with comprehensive tests for all trends endpoints.
</objective>

<execution_context>
@/Users/dustinober/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dustinober/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/12-api-&-cli-testing/12-RESEARCH.md
@.planning/phases/11-core-module-testing/11-06-SUMMARY.md
@tests/test_api_endpoints.py
@api/routers/trends.py
@api/services/data_loader.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add tests for /monthly, /covid, /seasonality, /robbery-heatmap endpoints</name>
  <files>tests/test_api_endpoints.py</files>
  <action>
Add integration tests for the 4 untested trends endpoints in test_api_endpoints.py:

1. **test_trends_monthly()** - Test GET /api/v1/trends/monthly
   - Test without filters returns all data
   - Test with start_year parameter filters correctly
   - Test with end_year parameter filters correctly
   - Test with both start_year and end_year filters correctly
   - Verify response is a list with expected keys (month, total_incidents, etc.)

2. **test_trends_covid()** - Test GET /api/v1/trends/covid
   - Verify response status is 200
   - Verify response is a list
   - Verify each row has expected structure (period, comparison metrics)

3. **test_trends_seasonality()** - Test GET /api/v1/trends/seasonality
   - Verify response status is 200
   - Verify response is a dict (not list)
   - Verify expected keys exist (e.g., monthly_patterns, seasonal_indices)

4. **test_trends_robbery_heatmap()** - Test GET /api/v1/trends/robbery-heatmap
   - Verify response status is 200
   - Verify response is a list
   - Verify each row has coordinate data (lat, lon, intensity)

Use the existing TestClient pattern from test_trends_annual() and test_metadata().
Load real data using setup_module() which calls load_all_data().
Focus on request/response contract validation, not implementation details.
  </action>
  <verify>Run pytest tests/test_api_endpoints.py -v -k "trends" and verify all new tests pass</verify>
  <done>All 5 trends endpoints have passing tests with 200 status validation and response structure checks</done>
</task>

<task type="auto">
  <name>Task 2: Add trends endpoint query parameter validation tests</name>
  <files>tests/test_api_endpoints.py</files>
  <action>
Add parameter validation tests for trends endpoints that accept query parameters:

1. **test_trends_annual_with_category_filter()**
   - Test ?category=Violence filters correctly
   - Verify all returned rows have crime_category == "Violence"
   - Test with category that has no data returns empty list

2. **test_trends_monthly_with_year_filters()**
   - Test start_year=2019 returns data from 2019 onwards
   - Test end_year=2021 returns data through 2021
   - Test start_year > end_year returns empty list
   - Test invalid year format returns 422 (FastAPI auto-validation)

Add these tests to test_api_endpoints.py using parametrize where appropriate.
  </action>
  <verify>Run pytest tests/test_api_endpoints.py::test_trends_annual_with_category_filter -v and verify filtering works correctly</verify>
  <done>Query parameter filtering is tested and validated for both annual and monthly endpoints</done>
</task>

<task type="auto">
  <name>Task 3: Add trends endpoint error handling tests</name>
  <files>tests/test_api_endpoints.py</files>
  <action>
Add error handling tests for trends endpoints using monkeypatch to simulate failures:

1. **test_trends_endpoint_missing_data_key()**
   - Use monkeypatch to clear _DATA_CACHE
   - Call /api/v1/trends/annual
   - Verify 500 status is returned (KeyError becomes 500 via exception handler)
   - Verify error response has correct structure

2. **test_trends_monthly_invalid_year_format()**
   - Pass non-integer year parameter
   - Verify FastAPI returns 422 validation error
   - Verify error response contains "detail" key

Pattern: Use monkeypatch to set "api.services.data_loader._DATA_CACHE" to empty dict.
  </action>
  <verify>Run pytest tests/test_api_endpoints.py -v -k "error" and verify error handling works as expected</verify>
  <done>Error paths for trends endpoints are tested, including missing data and invalid inputs</done>
</task>

</tasks>

<verification>
After completion, verify:
1. Run pytest tests/test_api_endpoints.py -v -k "trends" and count passing tests
2. All 5 trends endpoints (/annual, /monthly, /covid, /seasonality, /robbery-heatmap) have at least one test
3. Query parameter filtering is tested for annual and monthly endpoints
4. Error handling is tested for missing data keys and invalid inputs
5. Total of at least 8 new trend-focused tests pass
</verification>

<success_criteria>
1. All 5 trends API endpoints have integration tests
2. Tests validate request/response contracts (status codes, data types, expected keys)
3. Query parameter filtering is tested and working
4. Error handling paths are covered (422 for invalid input, 500 for missing data)
5. All tests use TestClient and follow existing patterns from Phase 11
</success_criteria>

<output>
After completion, create .planning/phases/12-api-&-cli-testing/12-01-SUMMARY.md with:
- Number of tests added for trends endpoints
- Coverage percentage for api/routers/trends.py
- Any issues discovered during testing
</output>
