---
phase: 12-api-&-cli-testing
plan: 08
type: execute
wave: 3
depends_on: ["12-01", "12-02", "12-03", "12-04", "12-05", "12-06", "12-07"]
files_modified:
  - .planning/phases/12-api-&-cli-testing/12-08-SUMMARY.md
autonomous: true

must_haves:
  truths:
    - "Overall coverage for API and CLI modules reaches 80-85%"
    - "Coverage report is generated in terminal, JSON, and HTML formats"
    - "Each router (trends, spatial, policy, forecasting, metadata, questions) has 80%+ coverage"
    - "API service layer (data_loader.py) has 85%+ coverage"
    - "CLI main commands (version, info) have 80%+ coverage"
  artifacts:
    - path: ".planning/phases/12-api-&-cli-testing/12-08-SUMMARY.md"
      provides: "Phase 12 coverage report and summary"
      min_lines: 150
  key_links:
    - from: ".planning/phases/12-api-&-cli-testing/12-08-SUMMARY.md"
      to: "htmlcov/index.html"
      via: "coverage report generation"
      pattern: "Coverage report:"
---

<objective>
Generate comprehensive coverage report for API and CLI modules and verify Phase 12 success criteria.

Purpose: Measure and document test coverage for all API routers, service layer, and CLI main commands. Generate HTML, JSON, and terminal reports for visibility.

Output: Coverage report showing 80-85% overall coverage for Phase 12 modules, with per-module breakdown in SUMMARY.md.
</objective>

<execution_context>
@/Users/dustinober/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dustinober/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/12-api-&-cli-testing/12-RESEARCH.md
@.planning/phases/11-core-module-testing/11-06-SUMMARY.md
@pyproject.toml
@api/routers/*.py
@api/services/*.py
@analysis/cli/main.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Run coverage for API and CLI modules</name>
  <files>.planning/phases/12-api-&-cli-testing/12-08-SUMMARY.md</files>
  <action>
Generate coverage report for API and CLI modules:

1. Run pytest with coverage for specific modules:
   ```bash
   pytest -o addopts='' --cov=api/routers --cov=api/services --cov=api/main --cov=analysis/cli/main --cov-report=term-missing --cov-report=json --cov-report=html
   ```

2. Capture terminal output showing per-module coverage:
   - api/routers/trends.py
   - api/routers/spatial.py
   - api/routers/policy.py
   - api/routers/forecasting.py
   - api/routers/metadata.py
   - api/routers/questions.py
   - api/services/data_loader.py
   - api/main.py
   - analysis/cli/main.py

3. Save terminal output to a temp file for reference:
   ```bash
   pytest -o addopts='' --cov=api/routers --cov=api/services --cov=api/main --cov=analysis/cli/main --cov-report=term-missing > /tmp/phase12_coverage.txt 2>&1
   ```

Use -o addopts='' to disable xdist for accurate coverage measurement.
  </action>
  <verify>Run the coverage command and verify it completes successfully</verify>
  <done>Coverage data is collected for all API and CLI modules</done>
</task>

<task type="auto">
  <name>Task 2: Generate HTML and JSON coverage reports</name>
  <files>.planning/phases/12-api-&-cli-testing/12-08-SUMMARY.md</files>
  <action>
Generate detailed coverage reports in multiple formats:

1. Generate HTML report:
   ```bash
   pytest -o addopts='' --cov=api/routers --cov=api/services --cov=api/main --cov=analysis/cli/main --cov-report=html
   ```
   Verify htmlcov/ directory is created with per-module HTML files.

2. Generate JSON report:
   ```bash
   pytest -o addopts='' --cov=api/routers --cov=api/services --cov=api/main --cov=analysis/cli/main --cov-report=json
   ```
   Verify coverage.json is created.

3. Check coverage.json for per-module percentages:
   ```bash
   python -c "import json; data = json.load(open('coverage.json')); [print(f'{k}: {v[\"summary\"][\"percent_covered\"]:.2f}%') for k in data['files'].keys() if 'api' in k or 'cli' in k]"
   ```

4. Copy HTML report location for SUMMARY.md.

Save the JSON output for inclusion in the summary.
  </action>
  <verify>Check that htmlcov/ directory and coverage.json file exist</verify>
  <done>HTML and JSON coverage reports are generated</done>
</task>

<task type="auto">
  <name>Task 3: Analyze coverage gaps and document findings</name>
  <files>.planning/phases/12-api-&-cli-testing/12-08-SUMMARY.md</files>
  <action>
Analyze coverage results and document gaps:

1. Identify modules below 80% coverage:
   - Read coverage.json and check each module's percent_covered
   - List modules that need additional tests

2. For modules below threshold, identify uncovered lines:
   - Check terminal-missing report or HTML files
   - Identify specific lines or functions not covered
   - Categorize gaps (error handling, edge cases, unused code)

3. Document acceptable exclusions:
   - Lines that are defensive conditionals (unlikely to trigger)
   - Lines that require external services (Firestore)
   - Lines that are type annotations or imports

4. Calculate overall Phase 12 coverage:
   - Average coverage across all api/* modules
   - Average coverage across analysis/cli/main.py
   - Compare to 80-85% target

Save analysis for inclusion in SUMMARY.md.
  </action>
  <verify>Review the coverage analysis and categorize any gaps</verify>
  <done>Coverage gaps are identified and documented</done>
</task>

<task type="auto">
  <name>Task 4: Create Phase 12 SUMMARY.md with coverage report</name>
  <files>.planning/phases/12-api-&-cli-testing/12-08-SUMMARY.md</files>
  <action>
Create comprehensive SUMMARY.md for Phase 12:

1. Include frontmatter with coverage metrics:
   ```yaml
   ---
   phase: 12-api-&-cli-testing
   plan: 08
   type: summary
   coverage:
     overall: XX%
     api_routers: XX%
     api_services: XX%
     cli_main: XX%
   ---
   ```

2. Document per-module coverage:
   - api/routers/trends.py: XX%
   - api/routers/spatial.py: XX%
   - api/routers/policy.py: XX%
   - api/routers/forecasting.py: XX%
   - api/routers/metadata.py: XX%
   - api/routers/questions.py: XX%
   - api/services/data_loader.py: XX%
   - api/main.py: XX%
   - analysis/cli/main.py: XX%

3. Document tests created:
   - Total number of API endpoint tests
   - Total number of CLI tests
   - Total number of service layer tests
   - Total number of error handling tests

4. List coverage gaps:
   - Modules below 80% with specific line numbers
   - Explanation for each gap (defensive code, external deps, etc.)

5. Compare to Phase 11 baseline:
   - Phase 11 achieved 81.75% for core modules
   - Phase 12 extends coverage to API and CLI layers

6. Link to HTML report:
   - htmlcov/index.html for detailed view

Save to .planning/phases/12-api-&-cli-testing/12-08-SUMMARY.md.
  </action>
  <verify>Read the created SUMMARY.md and verify it has all required sections</verify>
  <done>Phase 12 summary document is created with full coverage report</done>
</task>

</tasks>

<verification>
After completion, verify:
1. Coverage report shows 80-85% for Phase 12 modules (api/, analysis/cli/main.py)
2. HTML report is accessible at htmlcov/index.html
3. JSON report (coverage.json) contains per-module breakdown
4. SUMMARY.md documents all coverage metrics and gaps
5. Success criteria from roadmap are met:
   - All 11 FastAPI endpoints have tests
   - API tests validate request/response contracts
   - CLI commands (version, info) have tests
   - Service layer has 85%+ coverage
</verification>

<success_criteria>
1. Overall coverage for API and CLI modules is 80-85%
2. Coverage report is generated in terminal, JSON, and HTML formats
3. Each router module has 80%+ coverage (trends, spatial, policy, forecasting, metadata, questions)
4. API service layer (data_loader.py) has 85%+ coverage
5. CLI main commands have 80%+ coverage
6. SUMMARY.md documents all tests created and any coverage gaps
7. Success criteria from Phase 12 roadmap are verified
</success_criteria>

<output>
After completion, create .planning/phases/12-api-&-cli-testing/12-08-SUMMARY.md with:
- Frontmatter with coverage metrics
- Per-module coverage breakdown
- Total tests created in Phase 12
- Coverage gaps and explanations
- Comparison to Phase 11 baseline
- Link to HTML coverage report
</output>
