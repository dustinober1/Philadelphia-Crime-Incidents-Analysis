---
phase: 01-statistical-rigor
plan: 03
type: execute
wave: 2
depends_on: [01-01, 01-05]
files_modified:
  - analysis/spatial_analysis.py
  - analysis/red_zones.py
  - analysis/categorical_analysis.py
  - analysis/cross_analysis.py
  - analysis/weighted_severity_analysis.py
autonomous: true

must_haves:
  truths:
    - "User can view p-values for spatial correlation analyses"
    - "User can view 99% confidence intervals on spatial cluster analyses"
    - "User can view statistical significance for district-level comparisons"
    - "User can view chi-square tests for crime type associations"
    - "User can view analysis metadata in all spatial reports"
  artifacts:
    - path: "analysis/spatial_analysis.py"
      contains: "from analysis.stats_utils import", "from analysis.reproducibility import"
      min_lines: 200
    - path: "analysis/red_zones.py"
      contains: "from analysis.stats_utils import", "bootstrap_ci"
      min_lines: 350
    - path: "analysis/categorical_analysis.py"
      contains: "from analysis.stats_utils import", "chi_square_test", "apply_fdr_correction"
      min_lines: 200
    - path: "analysis/cross_analysis.py"
      contains: "from analysis.stats_utils import", "correlation_test"
      min_lines: 200
    - path: "analysis/weighted_severity_analysis.py"
      contains: "from analysis.stats_utils import", "bootstrap_ci"
      min_lines: 300
  key_links:
    - from: "analysis/spatial_analysis.py"
      to: "analysis/stats_utils.py"
      via: "from analysis.stats_utils import apply_fdr_correction, bootstrap_ci"
    - from: "analysis/categorical_analysis.py"
      to: "analysis/stats_utils.py"
      via: "from analysis.stats_utils import chi_square_test, compare_multiple_samples, apply_fdr_correction"
    - from: "analysis/red_zones.py"
      to: "analysis/stats_utils.py"
      via: "from analysis.stats_utils import bootstrap_ci"
    - from: "analysis/cross_analysis.py"
      to: "analysis/stats_utils.py"
      via: "from analysis.stats_utils import correlation_test, chi_square_test"
---

<objective>
Add statistical significance testing and 99% confidence intervals to all spatial and categorical analysis modules (spatial_analysis, red_zones, categorical_analysis, cross_analysis, weighted_severity_analysis). This enables users to view p-values for spatial correlations, district comparisons, crime type associations, and confidence intervals on spatial visualizations.

Purpose: Meet STAT-01 (p-values for spatial correlations) and STAT-02 (99% CI on visualizations) requirements for spatial and categorical analyses.

Output: Updated spatial/categorical analysis modules with statistical test results in outputs, confidence intervals on plots, and analysis metadata in reports.
</objective>

<execution_context>
@/Users/dustinober/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dustinober/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/01-statistical-rigor/01-01-SUMMARY.md
@.planning/phases/01-statistical-rigor/01-05-SUMMARY.md
@analysis/config.py
@analysis/utils.py
@analysis/spatial_analysis.py
@analysis/red_zones.py
@analysis/categorical_analysis.py
@analysis/cross_analysis.py
@analysis/weighted_severity_analysis.py
</context>

<tasks>

<task type="auto">
  <name>Add statistical tests to spatial_analysis.py</name>
  <files>analysis/spatial_analysis.py</files>
  <action>
Update `analysis/spatial_analysis.py` to add statistical testing:

1. **Add imports**:
   ```python
   from analysis.stats_utils import apply_fdr_correction, bootstrap_ci, correlation_test
   from analysis.reproducibility import set_global_seed, get_analysis_metadata, format_metadata_markdown
   from analysis.config import STAT_CONFIG
   ```

2. **Add set_global_seed call** at start

3. **Add district comparison tests**:
   - Compare crime rates across all 23+ districts using compare_multiple_samples
   - If significant (p < 0.01), run post-hoc pairwise comparisons
   - Apply FDR correction to all pairwise tests
   - Store results: omnibus test, post-hoc with FDR-adjusted p-values

4. **Add spatial autocorrelation note**:
   - Document that standard tests assume independence
   - Note spatial correlation as limitation
   - Recommend pysal for future spatial statistics

5. **Add bootstrap CI** for district-level statistics:
   - 99% CI for mean crimes per district
   - 99% CI for hotspot threshold

6. **Update markdown report** to include:
   - Analysis Configuration section
   - District comparison omnibus test result
   - Top significant district pairs (after FDR correction)
   - Bootstrap CIs for district statistics

Note: For true spatial autocorrelation testing (Moran's I), note that pysal/libpysal would be needed - document as limitation for this phase.
  </action>
  <verify>
```bash
python -c "
from analysis.spatial_analysis import analyze_spatial_patterns
results = analyze_spatial_patterns()
print('Results keys:', list(results.keys()))
print('District comparison:', results.get('district_comparison', 'NOT FOUND'))
print('Bootstrap CI:', results.get('district_mean_ci', 'NOT FOUND'))
"
```
  </verify>
  <done>
spatial_analysis.py includes district comparison with omnibus test, FDR-adjusted post-hoc pairwise tests, bootstrap CIs for district statistics, and documents spatial autocorrelation as limitation.
  </done>
</task>

<task type="auto">
  <name>Add statistical tests to red_zones.py</name>
  <files>analysis/red_zones.py</files>
  <action>
Update `analysis/red_zones.py` to add statistical testing:

1. **Add imports**:
   ```python
   from analysis.stats_utils import bootstrap_ci
   from analysis.reproducibility import set_global_seed, get_analysis_metadata, format_metadata_markdown
   from analysis.config import STAT_CONFIG
   ```

2. **Add set_global_seed call** at start

3. **Add bootstrap CI** for cluster statistics:
   - 99% CI for cluster centroid locations
   - 99% CI for cluster crime counts
   - Use bootstrap resampling of coordinates within each cluster

4. **Add cluster significance test**:
   - Compare cluster density vs random spatial distribution
   - Generate random points with same spatial extent
   - Bootstrap test for density difference
   - Store: observed_density, null_mean, p_value, is_significant

5. **Update markdown report** to include:
   - Analysis Configuration section
   - Cluster significance test results
   - Confidence intervals for top hotspots
   - Interpretation: "X hotspots are significantly denser than random (p < 0.01)"
  </action>
  <verify>
```bash
python -c "
from analysis.red_zones import analyze_red_zones
results = analyze_red_zones()
print('Results keys:', list(results.keys()))
print('Cluster significance:', results.get('cluster_significance', 'NOT FOUND'))
print('Cluster CIs:', results.get('cluster_cis', 'NOT FOUND'))
"
```
  </verify>
  <done>
red_zones.py includes bootstrap CIs for cluster statistics (centroids, counts), significance test comparing cluster density to random distribution, and reports which hotspots are statistically significant.
  </done>
</task>

<task type="auto">
  <name>Add statistical tests to categorical_analysis.py</name>
  <files>analysis/categorical_analysis.py</files>
  <action>
Update `analysis/categorical_analysis.py` to add statistical testing:

1. **Add imports**:
   ```python
   from analysis.stats_utils import chi_square_test, compare_multiple_samples, apply_fdr_correction
   from analysis.reproducibility import set_global_seed, get_analysis_metadata, format_metadata_markdown
   from analysis.config import STAT_CONFIG
   ```

2. **Add set_global_seed call** at start

3. **Add chi-square test** for crime type distribution:
   - Test if crime types are uniformly distributed
   - Chi-square test for UCR category distribution
   - Store: chi2_statistic, p_value, is_significant

4. **Add district comparison** across crime types:
   - Compare crime counts across districts for each major crime type
   - Use chi-square test of independence (crime type vs district)
   - Apply FDR correction across all crime types tested

5. **Add UCR category comparison**:
   - Compare violent vs property vs other crime counts
   - Use compare_multiple_samples
   - Include effect sizes for pairwise comparisons

6. **Update markdown report** to include:
   - Analysis Configuration section
   - Crime type uniformity test
   - Crime-district association test (with Cramer's V if possible)
   - UCR category comparison with effect sizes
  </action>
  <verify>
```bash
python -c "
from analysis.categorical_analysis import analyze_categorical_patterns
results = analyze_categorical_patterns()
print('Results keys:', list(results.keys()))
print('UCR comparison:', results.get('ucr_comparison', 'NOT FOUND'))
print('Chi-square test:', results.get('crime_uniformity_test', 'NOT FOUND'))
"
```
  </verify>
  <done>
categorical_analysis.py includes chi-square test for crime type distribution, crime-district association test with FDR correction, and UCR category comparison with effect sizes.
  </done>
</task>

<task type="auto">
  <name>Add statistical tests to cross_analysis.py</name>
  <files>analysis/cross_analysis.py</files>
  <action>
Update `analysis/cross_analysis.py` to add statistical testing:

1. **Add imports**:
   ```python
   from analysis.stats_utils import correlation_test, chi_square_test, apply_fdr_correction
   from analysis.reproducibility import set_global_seed, get_analysis_metadata, format_metadata_markdown
   from analysis.config import STAT_CONFIG
   ```

2. **Add set_global_seed call** at start

3. **Add correlation tests** for cross-dimensional patterns:
   - Crime type vs hour: chi-square test of independence
   - Crime type vs day of week: chi-square test
   - District vs hour: chi-square test
   - District vs crime type: chi-square test

4. **Add pairwise correlation tests**:
   - For each pair of variables, test if correlation is significant
   - Use appropriate test (Pearson if normal, Spearman if not)
   - Apply FDR correction across all correlation tests

5. **Update markdown report** to include:
   - Analysis Configuration section
   - Cross-tabulation significance tests (chi-square)
   - Correlation test results with FDR adjustment
   - Notable associations (p < 0.01) with effect sizes
  </action>
  <verify>
```bash
python -c "
from analysis.cross_analysis import analyze_cross_patterns
results = analyze_cross_patterns()
print('Results keys:', list(results.keys()))
print('Cross-tab tests:', results.get('crosstab_tests', 'NOT FOUND'))
print('Correlation tests:', results.get('correlation_tests', 'NOT FOUND'))
"
```
  </verify>
  <done>
cross_analysis.py includes chi-square tests for cross-tabulations (crime x hour, crime x day, district x hour), correlation tests with automatic selection, and FDR correction across all tests.
  </done>
</task>

<task type="auto">
  <name>Add statistical tests to weighted_severity_analysis.py</name>
  <files>analysis/weighted_severity_analysis.py</files>
  <action>
Update `analysis/weighted_severity_analysis.py` to add statistical testing:

1. **Add imports**:
   ```python
   from analysis.stats_utils import bootstrap_ci, compare_multiple_samples, apply_fdr_correction
   from analysis.reproducibility import set_global_seed, get_analysis_metadata, format_metadata_markdown
   from analysis.config import STAT_CONFIG
   ```

2. **Add set_global_seed call** at start

3. **Add bootstrap CI** for severity scores:
   - 99% CI for each district's severity score
   - 99% CI for city-wide mean severity
   - Use bootstrap resampling with replacement

4. **Add district comparison** based on severity scores:
   - Compare severity scores across all districts
   - Use compare_multiple_samples (ANOVA or Kruskal-Wallis)
   - Post-hoc pairwise comparisons with FDR correction
   - Identify districts with significantly higher/lower severity

5. **Update markdown report** to include:
   - Analysis Configuration section
   - District severity comparison (omnibus + post-hoc)
   - Bootstrap CIs for severity rankings
   - Identification of statistically significant "high severity" districts

Note: Emphasize that severity scores are weighted by crime type - statistical tests apply to the computed scores, not raw crime counts.
  </action>
  <verify>
```bash
python -c "
from analysis.weighted_severity_analysis import analyze_weighted_severity
results = analyze_weighted_severity()
print('Results keys:', list(results.keys()))
print('District comparison:', results.get('district_comparison', 'NOT FOUND'))
print('Severity CIs:', results.get('severity_cis', 'NOT FOUND'))
"
```
  </verify>
  <done>
weighted_severity_analysis.py includes bootstrap CIs for district severity scores, district comparison with post-hoc tests, and identifies statistically significant high-severity districts.
  </done>
</task>

</tasks>

<verification>
After completing all tasks:

1. Run each module's verify command
2. Check that all reports include "Analysis Configuration" section
3. Verify FDR correction is applied to omnibus comparisons
4. Verify 99% CIs are calculated for relevant statistics
5. Verify spatial autocorrelation is documented as limitation where applicable
</verification>

<success_criteria>
1. spatial_analysis.py: District comparison with FDR-adjusted post-hoc, bootstrap CIs
2. red_zones.py: Cluster significance test vs random distribution, bootstrap CIs
3. categorical_analysis.py: Chi-square tests for crime type distributions, UCR comparison
4. cross_analysis.py: Chi-square tests for cross-tabulations, correlation tests with FDR
5. weighted_severity_analysis.py: Bootstrap CIs for severity scores, district comparison
6. All modules: Analysis Configuration section in reports
7. All verify commands pass
</success_criteria>

<output>
After completion, create `.planning/phases/01-statistical-rigor/01-03-SUMMARY.md` with:
- List of statistical tests added to each module
- Example significant findings (e.g., "District X has significantly higher severity")
- FDR correction summary (how many tests, how many significant after correction)
- Any deviations from plan
</output>
