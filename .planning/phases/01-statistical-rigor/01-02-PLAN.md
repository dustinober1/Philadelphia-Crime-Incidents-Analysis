---
phase: 01-statistical-rigor
plan: 02
type: execute
wave: 2
depends_on: [01-01, 01-05]
files_modified:
  - analysis/temporal_analysis.py
  - analysis/summer_spike.py
  - analysis/covid_lockdown.py
  - analysis/safety_trend.py
  - analysis/robbery_timing.py
autonomous: true

must_haves:
  truths:
    - "User can view Mann-Kendall trend test p-values for long-term crime trends"
    - "User can view 99% confidence intervals on temporal trend visualizations"
    - "User can view statistical significance for seasonal/monthly/day-of-week patterns"
    - "User can view effect sizes for time period comparisons"
    - "User can view analysis metadata (seed, data version, parameters) in reports"
  artifacts:
    - path: "analysis/temporal_analysis.py"
      contains: "from analysis.stats_utils import", "mann_kendall_test", "bootstrap_ci"
      min_lines: 400
    - path: "analysis/summer_spike.py"
      contains: "from analysis.stats_utils import", "compare_two_samples"
      min_lines: 200
    - path: "analysis/covid_lockdown.py"
      contains: "from analysis.stats_utils import", "compare_multiple_samples"
      min_lines: 300
    - path: "analysis/safety_trend.py"
      contains: "from analysis.reproducibility import", "set_global_seed"
      min_lines: 200
    - path: "analysis/robbery_timing.py"
      contains: "from analysis.stats_utils import", "chi_square_test"
      min_lines: 200
  key_links:
    - from: "analysis/temporal_analysis.py"
      to: "analysis/stats_utils.py"
      via: "from analysis.stats_utils import mann_kendall_test, bootstrap_ci, compare_two_samples"
    - from: "analysis/temporal_analysis.py"
      to: "analysis/reproducibility.py"
      via: "from analysis.reproducibility import set_global_seed, get_analysis_metadata"
    - from: "analysis/summer_spike.py"
      to: "analysis/stats_utils.py"
      via: "from analysis.stats_utils import compare_two_samples, cohens_d"
    - from: "analysis/covid_lockdown.py"
      to: "analysis/stats_utils.py"
      via: "from analysis.stats_utils import compare_multiple_samples, apply_fdr_correction"
---

<objective>
Add statistical significance testing and 99% confidence intervals to all temporal analysis modules (temporal_analysis, summer_spike, covid_lockdown, safety_trend, robbery_timing). This enables users to view p-values for trend analyses, temporal comparisons, and confidence intervals on all temporal visualizations.

Purpose: Meet STAT-01 (p-values for temporal comparisons) and STAT-02 (99% CI on visualizations) requirements for temporal analyses.

Output: Updated temporal analysis modules with statistical test results in outputs, confidence intervals on plots, and analysis metadata in reports.
</objective>

<execution_context>
@/Users/dustinober/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dustinober/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/01-statistical-rigor/01-01-SUMMARY.md
@.planning/phases/01-statistical-rigor/01-05-SUMMARY.md
@analysis/config.py
@analysis/utils.py
@analysis/temporal_analysis.py
@analysis/summer_spike.py
@analysis/covid_lockdown.py
@analysis/safety_trend.py
@analysis/robbery_timing.py
</context>

<tasks>

<task type="auto">
  <name>Add statistical tests to temporal_analysis.py</name>
  <files>analysis/temporal_analysis.py</files>
  <action>
Update `analysis/temporal_analysis.py` to add statistical testing:

1. **Add imports** at top:
   ```python
   from analysis.stats_utils import mann_kendall_test, bootstrap_ci, compare_two_samples, apply_fdr_correction
   from analysis.reproducibility import set_global_seed, get_analysis_metadata, format_metadata_markdown
   from analysis.config import STAT_CONFIG
   ```

2. **Add set_global_seed call** at start of `analyze_temporal_patterns()`:
   ```python
   # Set seed for reproducibility
   set_global_seed(STAT_CONFIG["random_seed"])
   ```

3. **Add Mann-Kendall trend test** for yearly crime counts:
   - After computing yearly_counts
   - Run mann_kendall_test on complete years (2006-2025, exclude 2026)
   - Store results: trend_direction, tau, p_value, is_significant
   - Include in results dict as "trend_test"

4. **Add bootstrap CI** for yearly mean:
   - Use bootstrap_ci on yearly counts
   - 99% confidence level from STAT_CONFIG
   - Store: ci_lower, ci_upper, point_estimate, se
   - Include in results dict as "yearly_mean_ci"

5. **Add chi-square test** for day-of-week distribution:
   - Test if crimes are evenly distributed across days
   - Use stats.chi2_contingency on observed vs expected
   - Store: statistic, p_value, is_significant
   - Include in results dict as "dow_uniformity_test"

6. **Add seasonal comparison test**:
   - Compare summer vs winter counts using compare_two_samples
   - Include Cohen's d effect size
   - Store test results in results dict as "seasonal_comparison"

7. **Update plots** to show confidence intervals:
   - For yearly trend: Add 99% CI shaded band using fill_between
   - For monthly bar: Add error bars with bootstrap CIs
   - Use STAT_CONFIG["confidence_level"] for all CIs

8. **Update generate_markdown_report** to include:
   - "Analysis Configuration" section using format_metadata_markdown
   - Statistical test results in formatted tables
   - P-values reported exactly (e.g., "p = 0.0032" not "p < 0.05")
   - Effect sizes with interpretation (small/medium/large)

Report format:
```markdown
#### Analysis Configuration
[metadata from format_metadata_markdown]

#### Long-term Trend (2006-2025)
- **Mann-Kendall Test**: {trend} (tau = {tau:.3f}, p = {p_value:.4f})
- **99% CI for annual mean**: [{ci_lower:.0f}, {ci_upper:.0f}]
```
  </action>
  <verify>
```bash
python -c "
from analysis.temporal_analysis import analyze_temporal_patterns, generate_markdown_report
results = analyze_temporal_patterns()
print('Results keys:', list(results.keys()))
print('Trend test:', results.get('trend_test', 'NOT FOUND'))
print('Yearly CI:', results.get('yearly_mean_ci', 'NOT FOUND'))
report = generate_markdown_report(results)
assert 'Analysis Configuration' in report
assert 'Mann-Kendall' in report
assert 'p =' in report
print('Verification passed')
"
```
  </verify>
  <done>
temporal_analysis.py includes statistical test results (Mann-Kendall, bootstrap CI, chi-square, seasonal comparison), plots show 99% CIs, and markdown report includes Analysis Configuration section with p-values and effect sizes.
  </done>
</task>

<task type="auto">
  <name>Add statistical tests to summer_spike.py</name>
  <files>analysis/summer_spike.py</files>
  <action>
Update `analysis/summer_spike.py` to add statistical testing:

1. **Add imports**:
   ```python
   from analysis.stats_utils import compare_two_samples, cohens_d, bootstrap_ci
   from analysis.reproducibility import set_global_seed, get_analysis_metadata, format_metadata_markdown
   from analysis.config import STAT_CONFIG
   ```

2. **Add set_global_seed call** at start of main analysis function

3. **Add statistical tests** for July-August spike:
   - Compare July-August vs other months using compare_two_samples
   - Calculate Cohen's d for effect size
   - Bootstrap 99% CI for the difference
   - Store results with test name, p-value, effect size, CI

4. **Test year-over-year** consistency of summer spike:
   - Compare summer vs non-summer for each year (2006-2025)
   - Count how many years show significant spike
   - Apply FDR correction across all years

5. **Update markdown report** to include:
   - Analysis Configuration section
   - Test results with p-values and effect sizes
   - Statement: "Summer spike is statistically significant in X out of 20 years (after FDR correction)"
  </action>
  <verify>
```bash
python -c "
from analysis.summer_spike import analyze_summer_spike
results = analyze_summer_spike()
print('Results keys:', list(results.keys()))
print('Summer vs other test:', results.get('summer_comparison_test', 'NOT FOUND'))
print('Cohens d:', results.get('cohens_d', 'NOT FOUND'))
"
```
  </verify>
  <done>
summer_spike.py includes statistical comparison of summer vs other months with p-value, Cohen's d effect size, 99% CI for difference, and FDR-adjusted year-over-year analysis.
  </done>
</task>

<task type="auto">
  <name>Add statistical tests to covid_lockdown.py</name>
  <files>analysis/covid_lockdown.py</files>
  <action>
Update `analysis/covid_lockdown.py` to add statistical testing:

1. **Add imports**:
   ```python
   from analysis.stats_utils import compare_multiple_samples, apply_fdr_correction, bootstrap_ci
   from analysis.reproducibility import set_global_seed, get_analysis_metadata, format_metadata_markdown
   from analysis.config import STAT_CONFIG
   ```

2. **Add set_global_seed call** at start

3. **Define periods** for comparison:
   - Pre-COVID: 2018-2019
   - Lockdown: March-May 2020
   - Post-lockdown: June-December 2020
   - Recovery: 2021-2022

4. **Add multi-group comparison**:
   - Use compare_multiple_samples for the 4 periods
   - Tukey HSD post-hoc for pairwise comparisons
   - Report which periods differ significantly

5. **Add monthly trend analysis** with bootstrap CIs:
   - Compare 2020 monthly counts to 2018-2019 baseline
   - 99% CI for each month's deviation

6. **Update markdown report** to include:
   - Analysis Configuration section
   - Omnibus test result (ANOVA or Kruskal-Wallis)
   - Post-hoc pairwise comparisons with FDR adjustment
   - Effect sizes for significant differences
  </action>
  <verify>
```bash
python -c "
from analysis.covid_lockdown import analyze_covid_impact
results = analyze_covid_impact()
print('Results keys:', list(results.keys()))
print('Period comparison:', results.get('period_comparison', 'NOT FOUND'))
print('Post-hoc results:', results.get('post_hoc_results', 'NOT FOUND'))
"
```
  </verify>
  <done>
covid_lockdown.py includes multi-group comparison across 4 periods with omnibus test, Tukey HSD post-hoc, FDR-adjusted p-values, and effect sizes for pairwise differences.
  </done>
</task>

<task type="auto">
  <name>Add statistical tests to safety_trend.py</name>
  <files>analysis/safety_trend.py</files>
  <action>
Update `analysis/safety_trend.py` to add statistical testing:

1. **Add imports**:
   ```python
   from analysis.stats_utils import mann_kendall_test, cohens_d, bootstrap_ci
   from analysis.reproducibility import set_global_seed, get_analysis_metadata, format_metadata_markdown
   from analysis.config import STAT_CONFIG
   ```

2. **Add set_global_seed call** at start

3. **Add trend tests** for violent and property crime (2016-2025):
   - Mann-Kendall test for each category
   - Bootstrap 99% CI for trend slope
   - Report: trend direction, tau, p-value, is_significant

4. **Add violent vs property comparison**:
   - Compare annual rates using compare_two_samples
   - Cohen's d for effect size
   - Test if divergence is statistically significant

5. **Update markdown report** to include:
   - Analysis Configuration section
   - Violent crime trend: {direction} (tau={tau:.3f}, p={p:.4f})
   - Property crime trend: {direction} (tau={tau:.3f}, p={p:.4f})
   - Comparison effect size with interpretation
  </action>
  <verify>
```bash
python -c "
from analysis.safety_trend import analyze_safety_trend
results = analyze_safety_trend()
print('Results keys:', list(results.keys()))
print('Violent trend:', results.get('violent_trend', 'NOT FOUND'))
print('Property trend:', results.get('property_trend', 'NOT FOUND'))
"
```
  </verify>
  <done>
safety_trend.py includes Mann-Kendall trend tests for violent and property crime, bootstrap CIs for trends, and comparison between categories with effect size.
  </done>
</task>

<task type="auto">
  <name>Add statistical tests to robbery_timing.py</name>
  <files>analysis/robbery_timing.py</files>
  <action>
Update `analysis/robbery_timing.py` to add statistical testing:

1. **Add imports**:
   ```python
   from analysis.stats_utils import chi_square_test, compare_multiple_samples, bootstrap_ci
   from analysis.reproducibility import set_global_seed, get_analysis_metadata, format_metadata_markdown
   from analysis.config import STAT_CONFIG
   ```

2. **Add set_global_seed call** at start

3. **Add chi-square test** for time-of-day distribution:
   - Test if robberies are uniformly distributed across hours
   - Report chi-square statistic, p-value, is_significant

4. **Add time period comparison**:
   - Compare 4 time periods (overnight, morning, afternoon, evening)
   - Use compare_multiple_samples (ANOVA or Kruskal-Wallis)
   - Tukey HSD post-hoc for pairwise differences

5. **Add day-of-week test**:
   - Chi-square test for uniform distribution across days
   - Compare weekday vs weekend using compare_two_samples

6. **Update markdown report** to include:
   - Analysis Configuration section
   - Time-of-day uniformity test result
   - Time period comparison with post-hoc
   - Day-of-week pattern test result
  </action>
  <verify>
```bash
python -c "
from analysis.robbery_timing import analyze_robbery_timing
results = analyze_robbery_timing()
print('Results keys:', list(results.keys()))
print('Time period test:', results.get('time_period_test', 'NOT FOUND'))
print('Day of week test:', results.get('dow_test', 'NOT FOUND'))
"
```
  </verify>
  <done>
robbery_timing.py includes chi-square tests for time-of-day and day-of-week distributions, multi-group comparison for time periods, and all p-values reported in markdown output.
  </done>
</task>

</tasks>

<verification>
After completing all tasks:

1. Run each module's verify command
2. Check that all reports include "Analysis Configuration" section
3. Verify p-values are reported exactly (e.g., "p = 0.0032")
4. Verify 99% CIs are shown on relevant plots
5. Verify effect sizes are included with interpretation
</verification>

<success_criteria>
1. temporal_analysis.py: Mann-Kendall trend test, bootstrap CIs, seasonal comparison
2. summer_spike.py: Summer vs other comparison with effect size and CI
3. covid_lockdown.py: 4-period comparison with Tukey HSD post-hoc
4. safety_trend.py: Mann-Kendall trends for violent and property crime
5. robbery_timing.py: Chi-square tests for temporal distributions
6. All modules: Analysis Configuration section in reports
7. All verify commands pass without errors
</success_criteria>

<output>
After completion, create `.planning/phases/01-statistical-rigor/01-02-SUMMARY.md` with:
- List of statistical tests added to each module
- Example p-values from test runs
- Any notable findings (e.g., trends significant at p < 0.01)
- Any deviations from plan
</output>
