---
wave: 2
depends_on: ["01-01"]
files_modified:
  - notebooks/covid_lockdown_crime_landscape.ipynb
autonomous: true
---

# Plan 01-04: COVID Analysis Notebook (CHIEF-03)

<objective>
Refactor the COVID Lockdown Crime Landscape notebook (CHIEF-03) to use external configuration, produce comparative pre/during/post COVID analysis with displacement effects, and generate academic-style reports.

This notebook answers: "How did COVID-19 lockdowns impact the crime landscape?" with annotated time series showing lockdown impact and analysis of burglary displacement patterns.

Requirement Coverage: CHIEF-03 - Comparative pre/during/post COVID time series with lockdown annotation and analysis of displacement effects
</objective>

<tasks>

<task id="1" type="code">
<name>Refactor Data Loading and Configuration</name>
<what>Integrate external configuration for COVID period definitions and standardize data loading.</what>
<how>
1. Add config loading cell at notebook top:
   ```python
   from analysis.config_loader import Phase1Config
   from analysis.utils import load_data, classify_crime_category, extract_temporal_features

   config = Phase1Config()
   params = config.get_notebook_params('covid')
   LOCKDOWN_DATE = pd.Timestamp(params['lockdown_date'])  # 2020-03-01
   BEFORE_YEARS = params['before_years']    # [2018, 2019]
   DURING_YEARS = params['during_years']    # [2020, 2021]
   AFTER_START_YEAR = params['after_start_year']  # 2023
   VERSION = config.version
   ```
2. Add papermill parameter cell with tag "parameters":
   ```python
   # Parameters (injected by papermill)
   VERSION = "v1.0"
   LOCKDOWN_DATE = "2020-03-01"
   BEFORE_YEARS = [2018, 2019]
   DURING_YEARS = [2020, 2021]
   AFTER_START_YEAR = 2023
   FAST_MODE = False
   ```
3. Replace hardcoded data loading with shared utilities
4. Filter to exclude 2026 data and include only 2018-2025
5. Add reproducibility cell documenting environment
6. Define period assignment:
   ```python
   def assign_period(year):
       if year in BEFORE_YEARS: return 'Before'
       if year in DURING_YEARS: return 'During'
       if year >= AFTER_START_YEAR: return 'After'
       return 'Transition'  # 2022
   ```
</how>
<files>
- notebooks/covid_lockdown_crime_landscape.ipynb
</files>
<verify>
```bash
cd notebooks && python -c "
import nbformat
nb = nbformat.read('covid_lockdown_crime_landscape.ipynb', as_version=4)
code = ' '.join([c.source for c in nb.cells if c.cell_type == 'code'])
assert 'LOCKDOWN_DATE' in code, 'Missing LOCKDOWN_DATE parameter'
assert 'Phase1Config' in code or 'config_loader' in code, 'Missing config import'
print('Config integration verified')
"
```
</verify>
</task>

<task id="2" type="code">
<name>Restructure to Academic Report Format</name>
<what>Organize into Summary, Methods, Findings, Limitations format with explicit period definitions.</what>
<how>
1. Add "Summary" section with high-level answer:
   - "COVID lockdowns significantly altered Philadelphia's crime landscape"
   - Key findings: overall change, displacement effect observed
   - Statistical significance statement
2. Create "Methods" section documenting:
   - Period definitions with date ranges:
     - Before: 2018-2019 (pre-pandemic baseline)
     - During: 2020-2021 (pandemic restrictions)
     - After: 2023-2025 (post-pandemic recovery)
     - Transition: 2022 (excluded from comparison)
   - Lockdown date: March 1, 2020 (Philadelphia stay-at-home order)
   - Displacement analysis approach: Residential vs Commercial burglary comparison
3. Add "Assumptions" subsection:
   - March 1, 2020 chosen as lockdown start (aligns with state guidelines)
   - 2022 excluded as transition year
   - Burglary classification based on UCR sub-codes
   - Displacement hypothesis: empty commercial areas, occupied homes
4. Organize analysis under "Findings" section
5. Add "Limitations" section:
   - Confounding factors: economic recession, civil unrest
   - Policy changes during period not controlled
   - Short post-COVID period (only 2+ years)
   - Reporting delays during pandemic
6. Add "Data Quality Summary" with records per period
7. Include timestamp in title
</how>
<files>
- notebooks/covid_lockdown_crime_landscape.ipynb
</files>
<verify>
```bash
cd notebooks && python -c "
import nbformat
nb = nbformat.read('covid_lockdown_crime_landscape.ipynb', as_version=4)
md = ' '.join([c.source for c in nb.cells if c.cell_type == 'markdown'])
assert 'Methods' in md, 'Missing Methods section'
assert 'Limitations' in md, 'Missing Limitations section'
print('Academic format verified')
"
```
</verify>
</task>

<task id="3" type="code">
<name>Enhance Time Series Visualization with Annotations</name>
<what>Create publication-quality annotated time series showing lockdown impact clearly.</what>
<how>
1. Import colors: `from analysis.config import COLORS`
2. Create main time series chart with:
   - Monthly crime counts over time (2018-2025)
   - Colorblind-safe line colors
3. Add lockdown annotation:
   ```python
   ax.axvline(LOCKDOWN_DATE, color='red', linestyle='--', linewidth=2)
   ax.annotate('COVID-19 Lockdown', xy=(LOCKDOWN_DATE, y_max * 0.9),
               fontsize=12, color='red', fontweight='bold')
   ```
4. Add period shading:
   ```python
   ax.axvspan(before_start, before_end, alpha=0.1, color='blue', label='Before')
   ax.axvspan(during_start, during_end, alpha=0.1, color='red', label='During')
   ax.axvspan(after_start, after_end, alpha=0.1, color='green', label='After')
   ```
5. Add annotations for key points:
   - Peak before lockdown
   - Minimum during lockdown
   - Recovery point in After period
   - Percent change labels
6. Save at 300 DPI with timestamp in subtitle
</how>
<files>
- notebooks/covid_lockdown_crime_landscape.ipynb
</files>
<verify>
```bash
cd notebooks && python -c "
import nbformat
nb = nbformat.read('covid_lockdown_crime_landscape.ipynb', as_version=4)
code = ' '.join([c.source for c in nb.cells if c.cell_type == 'code'])
assert 'axvline' in code or 'vline' in code, 'Missing lockdown vertical line'
assert 'dpi=300' in code or 'dpi = 300' in code, 'Missing 300 DPI'
print('Time series annotations verified')
"
```
</verify>
</task>

<task id="4" type="code">
<name>Implement Displacement Analysis</name>
<what>Analyze burglary displacement (Residential vs Commercial) as required by CHIEF-03.</what>
<how>
1. Filter for burglary crimes:
   ```python
   # UCR code 500 = Burglary
   burglary_df = df[df['ucr_general'] == 500].copy()
   ```
2. Classify by type using text_general_code:
   ```python
   def classify_burglary(text):
       if 'Residential' in str(text): return 'Residential'
       if 'Non-Residential' in str(text) or 'Commercial' in str(text): return 'Commercial'
       return 'Other'

   burglary_df['burglary_type'] = burglary_df['text_general_code'].apply(classify_burglary)
   ```
3. Calculate period-over-period change:
   ```python
   pivot = burglary_df.groupby(['period', 'burglary_type']).size().unstack()
   pct_change_during = (pivot.loc['During'] - pivot.loc['Before']) / pivot.loc['Before'] * 100
   ```
4. Create displacement visualization:
   - Grouped bar chart: Residential vs Commercial by period
   - Or line chart showing divergent trends
   - Clear legend and labels
5. Run statistical test:
   ```python
   from scipy.stats import chi2_contingency
   # Test if distribution differs significantly
   ```
6. Display summary:
   "During lockdown: Residential burglaries -25.5%, Commercial burglaries +75%"
</how>
<files>
- notebooks/covid_lockdown_crime_landscape.ipynb
</files>
<verify>
```bash
cd notebooks && python -c "
import nbformat
nb = nbformat.read('covid_lockdown_crime_landscape.ipynb', as_version=4)
code = ' '.join([c.source for c in nb.cells if c.cell_type == 'code'])
assert 'Residential' in code or 'burglary' in code.lower(), 'Missing burglary analysis'
print('Displacement analysis verified')
"
```
</verify>
</task>

<task id="5" type="code">
<name>Comparative Pre/During/Post Analysis</name>
<what>Produce clear comparison of crime patterns across three COVID periods.</what>
<how>
1. Calculate aggregate statistics per period:
   ```python
   period_stats = df.groupby('period').agg({
       'objectid': 'count',
       'crime_category': lambda x: (x == 'Violent').mean()  # % violent
   })
   ```
2. Compute percent changes:
   - During vs Before: (During - Before) / Before * 100
   - After vs During: (After - During) / During * 100
3. Break down by crime category:
   - Violent, Property, Other for each period
   - Identify biggest changes
4. Create grouped bar chart:
   - X-axis: Crime categories
   - Groups: Before, During, After
   - Clear labels with counts
5. Statistical test:
   - ANOVA or chi-square for distribution differences
   - Display F-statistic and p-value
6. Generate interpretation:
   - "Property crimes decreased 15% during lockdown"
   - "Violent crimes showed minimal change"
   - "After period shows partial recovery to baseline"
</how>
<files>
- notebooks/covid_lockdown_crime_landscape.ipynb
</files>
<verify>
```bash
cd notebooks && python -c "
import nbformat
nb = nbformat.read('covid_lockdown_crime_landscape.ipynb', as_version=4)
code = ' '.join([c.source for c in nb.cells if c.cell_type == 'code'])
assert 'Before' in code and 'During' in code and 'After' in code, 'Missing period analysis'
print('Period comparison verified')
"
```
</verify>
</task>

<task id="6" type="code">
<name>Implement Versioned Artifact Generation</name>
<what>Save all outputs with versioned filenames and generate manifest.</what>
<how>
1. Import artifact functions from analysis module
2. Save figures with versioned paths:
   ```python
   artifacts = []

   timeline_path = REPORTS_DIR / f'covid_timeline_{VERSION}.png'
   fig1.savefig(timeline_path, dpi=300, bbox_inches='tight')
   artifacts.append(timeline_path)

   displacement_path = REPORTS_DIR / f'burglary_displacement_{VERSION}.png'
   fig2.savefig(displacement_path, dpi=300, bbox_inches='tight')
   artifacts.append(displacement_path)

   comparison_path = REPORTS_DIR / f'period_comparison_{VERSION}.png'
   fig3.savefig(comparison_path, dpi=300, bbox_inches='tight')
   artifacts.append(comparison_path)
   ```
3. Generate markdown report with:
   - Executive summary
   - Period comparison table
   - Displacement analysis findings
   - Statistical test results
4. Save manifest with all artifacts
</how>
<files>
- notebooks/covid_lockdown_crime_landscape.ipynb
</files>
<verify>
```bash
ls reports/covid_*.png 2>/dev/null && echo "PNG artifacts exist"
ls reports/covid_*.md 2>/dev/null && echo "Report exists"
```
</verify>
</task>

<task id="7" type="code">
<name>Test Headless Execution</name>
<what>Verify notebook runs via papermill with COVID period parameters.</what>
<how>
1. Add error handling:
   - Missing burglary data
   - Empty period groups
   - Invalid date parsing
2. Test papermill execution:
   ```bash
   cd notebooks
   papermill covid_lockdown_crime_landscape.ipynb /tmp/output.ipynb \
     -p VERSION "v1.0" \
     -p LOCKDOWN_DATE "2020-03-01" \
     -p BEFORE_YEARS "[2018, 2019]" \
     -p DURING_YEARS "[2020, 2021]" \
     --timeout 600
   ```
3. Verify period parameters correctly applied
4. Check all artifacts generated
5. Test fast mode completes in < 30 seconds
</how>
<files>
- notebooks/covid_lockdown_crime_landscape.ipynb
</files>
<verify>
```bash
cd notebooks && papermill covid_lockdown_crime_landscape.ipynb /tmp/test_covid.ipynb -p FAST_MODE true --timeout 120 && echo "Headless execution successful"
```
</verify>
</task>

</tasks>

<must_haves>
- [ ] No hardcoded COVID dates (LOCKDOWN_DATE, period years from config)
- [ ] Parameter cell has `parameters` tag for papermill
- [ ] Notebook has Summary, Methods, Assumptions, Findings, Limitations sections
- [ ] Lockdown vertical line clearly visible at March 2020
- [ ] Three periods have distinct visual treatment (shading or colors)
- [ ] Displacement analysis: Residential vs Commercial burglary trends quantified
- [ ] Period comparison with percent changes: During vs Before, After vs During
- [ ] Statistical tests with p-values displayed
- [ ] All figures saved at 300 DPI with versioned filenames
- [ ] Markdown report with findings and displacement analysis
- [ ] Manifest JSON created with artifact hashes
- [ ] Papermill headless execution completes without errors
</must_haves>

<deliverables>
- Refactored notebooks/covid_lockdown_crime_landscape.ipynb
- reports/covid_timeline_v1.0.png
- reports/burglary_displacement_v1.0.png
- reports/period_comparison_v1.0.png
- reports/covid_report_v1.0.md
- reports/covid_manifest_v1.0.json
</deliverables>
