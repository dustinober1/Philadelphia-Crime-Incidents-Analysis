# Plan 03-05: Event Impact Analysis

**Phase:** 3 â€” Policy Deep Dives & Event Impacts
**Wave:** 2 (Core Analysis)
**Requirement:** HYP-EVENTS
**Depends on:** 03-01 (Infrastructure & External Data)

## Goal

Create a notebook that measures the impact of major events (sports games, holidays) on crime patterns using difference-in-means analysis with proper control days.

## Context

From 03-01, this plan will use:
- `config/phase3_config.yaml` for event definitions
- `data/external/event_calendar.parquet` for sports/holiday dates
- `analysis/event_utils.py` for event-day tagging and control selection

Implementation decisions from 03-CONTEXT.md:
- Event categories: Sports (Eagles, Phillies, 76ers, Flyers) and Holidays
- Control days: Same day-of-week in non-event weeks
- Test: Difference-in-means with confidence intervals
- Include spillover analysis (day before/after)

## Tasks

### 1. Create Notebook Structure

**1.1 Create `notebooks/event_impacts.ipynb`**

Standard notebook structure per AGENTS.md:
- Title: "Event Impact Analysis (HYP-EVENTS)"
- Overview: Measure crime pattern changes on event days vs control days
- Reproducibility cell with version info
- Imports: pandas, numpy, matplotlib, seaborn, scipy.stats

### 2. Data Loading

**2.1 Load Crime and Event Data**
```python
from analysis.utils import load_data, classify_crime_category
from analysis.phase3_config_loader import Phase3Config
from analysis.event_utils import identify_event_days, get_control_days

df = load_data(clean=True)
config = Phase3Config()

# Classify crimes
df = classify_crime_category(df)

# Load event calendar
repo_root = Path(__file__).resolve().parent.parent
events = pd.read_parquet(repo_root / 'data' / 'external' / 'event_calendar.parquet')
events['date'] = pd.to_datetime(events['date']).dt.normalize()

print(f"Total crime incidents: {len(df):,}")
print(f"Event calendar entries: {len(events)}")
print(f"Event types: {events['event_type'].value_counts().to_dict()}")
```

**2.2 Prepare Daily Crime Counts**
```python
# Parse date
df['date'] = pd.to_datetime(df['dispatch_date']).dt.normalize()

# Daily counts by category
daily_total = df.groupby('date').size().reset_index(name='total')
daily_violent = df[df['crime_category'] == 'Violent'].groupby('date').size().reset_index(name='violent')
daily_property = df[df['crime_category'] == 'Property'].groupby('date').size().reset_index(name='property')

daily = daily_total.merge(daily_violent, on='date', how='left')
daily = daily.merge(daily_property, on='date', how='left')
daily = daily.fillna(0)
daily['day_of_week'] = daily['date'].dt.dayofweek
daily['year'] = daily['date'].dt.year

# Filter to common analysis period
analysis_start = max(df['date'].min(), events['date'].min())
analysis_end = min(df['date'].max(), events['date'].max())
daily = daily[(daily['date'] >= analysis_start) & (daily['date'] <= analysis_end)]

print(f"Analysis period: {analysis_start.date()} to {analysis_end.date()}")
print(f"Total days: {len(daily):,}")
```

### 3. Tag Event Days

**3.1 Identify Event and Control Days**
```python
# Tag event days
event_dates = set(events['date'])
daily['is_event'] = daily['date'].isin(event_dates)

# Tag by specific event type
for event_type in events['event_type'].unique():
    type_dates = set(events[events['event_type'] == event_type]['date'])
    daily[f'is_{event_type}'] = daily['date'].isin(type_dates)

# Tag holidays specifically
holiday_df = events[events['event_type'] == 'holiday']
daily['is_holiday'] = daily['date'].isin(set(holiday_df['date']))

# Tag sports games
sports_df = events[events['event_type'] == 'sports']
daily['is_sports'] = daily['date'].isin(set(sports_df['date']))

# Tag by team
for team in ['Eagles', 'Phillies', '76ers', 'Flyers']:
    team_dates = set(sports_df[sports_df['event_name'].str.contains(team, na=False)]['date'])
    daily[f'is_{team.lower()}'] = daily['date'].isin(team_dates)

print(f"Event days: {daily['is_event'].sum():,}")
print(f"Holiday days: {daily['is_holiday'].sum():,}")
print(f"Sports days: {daily['is_sports'].sum():,}")
```

### 4. Difference-in-Means Analysis

**4.1 Define Analysis Function**
```python
from scipy import stats

def calculate_impact(daily_df, event_col, metric='total', control_weeks=4):
    """Calculate difference-in-means for event vs control days."""

    event_days = daily_df[daily_df[event_col]]
    control_days = daily_df[~daily_df['is_event']]  # Non-event days as controls

    # Get counts
    event_mean = event_days[metric].mean()
    control_mean = control_days[metric].mean()
    diff = event_mean - control_mean
    pct_change = (diff / control_mean * 100) if control_mean > 0 else 0

    # T-test
    t_stat, p_value = stats.ttest_ind(event_days[metric], control_days[metric])

    # Bootstrap 95% CI for difference
    n_bootstrap = 1000
    diffs = []
    for _ in range(n_bootstrap):
        e_sample = event_days[metric].sample(len(event_days), replace=True)
        c_sample = control_days[metric].sample(len(event_days), replace=True)
        diffs.append(e_sample.mean() - c_sample.mean())

    ci_lower = np.percentile(diffs, 2.5)
    ci_upper = np.percentile(diffs, 97.5)

    return {
        'event_type': event_col.replace('is_', ''),
        'metric': metric,
        'n_event_days': len(event_days),
        'n_control_days': len(control_days),
        'event_mean': event_mean,
        'control_mean': control_mean,
        'difference': diff,
        'pct_change': pct_change,
        'ci_lower': ci_lower,
        'ci_upper': ci_upper,
        'p_value': p_value,
        'significant': p_value < 0.05
    }
```

**4.2 Run Analysis for All Event Types**
```python
event_cols = ['is_holiday', 'is_sports', 'is_eagles', 'is_phillies', 'is_76ers', 'is_flyers']
metrics = ['total', 'violent', 'property']

results = []
for event_col in event_cols:
    if daily[event_col].sum() > 10:  # Minimum sample size
        for metric in metrics:
            result = calculate_impact(daily, event_col, metric)
            results.append(result)

results_df = pd.DataFrame(results)
print("\nEvent Impact Analysis Results:")
print(results_df[['event_type', 'metric', 'event_mean', 'control_mean', 'pct_change', 'p_value', 'significant']])
```

### 5. Visualizations

**5.1 Event Impact Forest Plot**
```python
fig, ax = plt.subplots(figsize=(12, 8))

# Filter to total crimes for main plot
total_results = results_df[results_df['metric'] == 'total'].copy()
total_results = total_results.sort_values('pct_change', ascending=True)

y_pos = range(len(total_results))
colors = ['#E63946' if sig else '#457B9D' for sig in total_results['significant']]

# Plot bars
ax.barh(y_pos, total_results['pct_change'], color=colors, alpha=0.7)

# Add confidence intervals
for i, (_, row) in enumerate(total_results.iterrows()):
    # Convert CI to pct change
    ci_low_pct = (row['ci_lower'] / row['control_mean'] * 100)
    ci_high_pct = (row['ci_upper'] / row['control_mean'] * 100)
    ax.plot([ci_low_pct, ci_high_pct], [i, i], 'k-', linewidth=2)

# Zero line
ax.axvline(x=0, color='black', linestyle='--', linewidth=1)

ax.set_yticks(y_pos)
ax.set_yticklabels([r['event_type'].title() for _, r in total_results.iterrows()])
ax.set_xlabel('% Change in Total Crime')
ax.set_title('Event Impact on Total Crime\n(Red = Statistically Significant)')

plt.tight_layout()
plt.savefig(REPORTS_DIR / 'event_impact_forest.png', dpi=300, bbox_inches='tight')
artifacts.append(('event_impact_forest.png', 'Event impact forest plot'))
plt.show()
```

**5.2 Crime Category Comparison**
```python
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

for i, metric in enumerate(['total', 'violent', 'property']):
    ax = axes[i]
    metric_results = results_df[results_df['metric'] == metric]

    x = range(len(metric_results))
    bars = ax.bar(x, metric_results['pct_change'],
                  color=['#E63946' if s else '#457B9D' for s in metric_results['significant']])

    ax.axhline(y=0, color='black', linestyle='--', linewidth=1)
    ax.set_xticks(x)
    ax.set_xticklabels([e.replace('is_', '').title() for e in metric_results['event_type']],
                       rotation=45, ha='right')
    ax.set_ylabel('% Change')
    ax.set_title(f'{metric.title()} Crime')

plt.suptitle('Event Impact by Crime Category', fontsize=14)
plt.tight_layout()
plt.savefig(REPORTS_DIR / 'event_impact_by_category.png', dpi=300, bbox_inches='tight')
artifacts.append(('event_impact_by_category.png', 'Impact by crime category'))
plt.show()
```

### 6. Time Pattern Analysis

**6.1 Hourly Patterns on Event Days**
```python
# Add hour to crime data
df['hour'] = pd.to_datetime(df['dispatch_date_time'], errors='coerce').dt.hour

# Merge event tags
df = df.merge(daily[['date', 'is_event', 'is_sports', 'is_holiday']], on='date', how='left')
df['is_event'] = df['is_event'].fillna(False)

# Compare hourly distribution
event_hourly = df[df['is_event']].groupby('hour').size()
control_hourly = df[~df['is_event']].groupby('hour').size()

# Normalize
event_hourly_pct = event_hourly / event_hourly.sum() * 100
control_hourly_pct = control_hourly / control_hourly.sum() * 100

fig, ax = plt.subplots(figsize=(12, 5))

hours = range(24)
width = 0.35

ax.bar([h - width/2 for h in hours], event_hourly_pct.reindex(hours, fill_value=0),
       width, label='Event Days', color='#E63946', alpha=0.7)
ax.bar([h + width/2 for h in hours], control_hourly_pct.reindex(hours, fill_value=0),
       width, label='Non-Event Days', color='#457B9D', alpha=0.7)

ax.set_xlabel('Hour of Day')
ax.set_ylabel('% of Daily Crime')
ax.set_title('Crime Distribution by Hour: Event vs Non-Event Days')
ax.legend()
ax.set_xticks(hours)

plt.tight_layout()
plt.savefig(REPORTS_DIR / 'event_hourly_pattern.png', dpi=300, bbox_inches='tight')
artifacts.append(('event_hourly_pattern.png', 'Hourly patterns on event days'))
plt.show()
```

### 7. Spillover Analysis

**7.1 Day Before/After Effects**
```python
# Check day before and after events
sports_dates = sorted(set(sports_df['date']))

spillover_results = []
for offset, label in [(-1, 'Day Before'), (0, 'Event Day'), (1, 'Day After')]:
    offset_dates = set([d + pd.Timedelta(days=offset) for d in sports_dates])
    daily['is_spillover'] = daily['date'].isin(offset_dates)

    if daily['is_spillover'].sum() > 0:
        result = calculate_impact(daily, 'is_spillover', 'total')
        result['period'] = label
        spillover_results.append(result)

spillover_df = pd.DataFrame(spillover_results)

fig, ax = plt.subplots(figsize=(8, 5))
periods = spillover_df['period']
changes = spillover_df['pct_change']
colors = ['#E63946' if s else '#457B9D' for s in spillover_df['significant']]

ax.bar(periods, changes, color=colors)
ax.axhline(y=0, color='black', linestyle='--')
ax.set_ylabel('% Change in Total Crime')
ax.set_title('Sports Event Spillover Effects')

plt.tight_layout()
plt.savefig(REPORTS_DIR / 'event_spillover.png', dpi=300, bbox_inches='tight')
artifacts.append(('event_spillover.png', 'Event spillover effects'))
plt.show()
```

### 8. Summary Report

**8.1 Generate Summary Report**
```python
# Find significant results
sig_results = results_df[results_df['significant']]
n_significant = len(sig_results)
n_tests = len(results_df)

report_content = f"""# Event Impact Analysis Report

## Executive Summary

This analysis examines the impact of major events (sports games, holidays) on crime patterns
in Philadelphia using difference-in-means testing with control days.

**Key Finding**: {n_significant} of {n_tests} tests showed statistically significant results (p < 0.05).

## Significant Impacts

| Event Type | Metric | % Change | 95% CI | p-value |
|------------|--------|----------|--------|---------|
"""

for _, row in sig_results.iterrows():
    ci = f"[{row['ci_lower']/row['control_mean']*100:.1f}%, {row['ci_upper']/row['control_mean']*100:.1f}%]"
    report_content += f"| {row['event_type'].title()} | {row['metric'].title()} | {row['pct_change']:+.1f}% | {ci} | {row['p_value']:.4f} |\n"

if len(sig_results) == 0:
    report_content += "| (No significant impacts detected) | | | | |\n"

report_content += f"""

## All Results Summary

| Event Type | Total Crime | Violent | Property |
|------------|-------------|---------|----------|
"""

for event_type in results_df['event_type'].unique():
    event_rows = results_df[results_df['event_type'] == event_type]
    total_pct = event_rows[event_rows['metric'] == 'total']['pct_change'].values[0]
    violent_pct = event_rows[event_rows['metric'] == 'violent']['pct_change'].values[0] if len(event_rows[event_rows['metric'] == 'violent']) > 0 else 'N/A'
    property_pct = event_rows[event_rows['metric'] == 'property']['pct_change'].values[0] if len(event_rows[event_rows['metric'] == 'property']) > 0 else 'N/A'

    report_content += f"| {event_type.title()} | {total_pct:+.1f}% | {violent_pct:+.1f}% | {property_pct:+.1f}% |\n"

report_content += f"""

## Methodology

- **Event types**: Sports (Eagles, Phillies, 76ers, Flyers), Holidays
- **Control days**: All non-event days in the analysis period
- **Statistical test**: Two-sample t-test with bootstrap confidence intervals
- **Significance level**: p < 0.05
- **Analysis period**: {analysis_start.date()} to {analysis_end.date()}

## Caveats

1. Sports schedules are approximate and may not perfectly match actual home games
2. Confounding factors (weather, concurrent events) not controlled
3. Multiple testing increases false positive risk

---
*Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')}*
*Notebook: event_impacts.ipynb*
"""

with open(REPORTS_DIR / 'event_impact_report.md', 'w') as f:
    f.write(report_content)

artifacts.append(('event_impact_report.md', 'Event impact summary report'))
```

### 9. Export Data

**9.1 Save Results**
```python
results_df.to_csv(REPORTS_DIR / 'event_impact_results.csv', index=False)
artifacts.append(('event_impact_results.csv', 'Full results table'))
```

### 10. Notebook Completion

**10.1 Artifact Summary Cell**
```python
print("\n" + "="*60)
print("NOTEBOOK COMPLETE: Event Impact Analysis (HYP-EVENTS)")
print("="*60)
print(f"\nSignificant results: {n_significant}/{n_tests}")
print(f"\nArtifacts generated:")
for name, desc in artifacts:
    print(f"  - {name}: {desc}")
print(f"\nRuntime: {time.time() - RUNTIME_START:.1f} seconds")
```

## Validation Criteria

- [ ] Notebook executes end-to-end without errors
- [ ] Reproducibility cell present with version info
- [ ] `reports/event_impact_forest.png` shows impact estimates with CIs
- [ ] `reports/event_impact_by_category.png` shows comparison across categories
- [ ] `reports/event_impact_report.md` contains results table
- [ ] `reports/event_impact_results.csv` contains all test results
- [ ] p-values and confidence intervals calculated correctly
- [ ] Both sports and holiday events analyzed

## Dependencies

- scipy (for statistical tests)
- matplotlib, seaborn (for visualizations)
- pandas, numpy (for data manipulation)
- 03-01 infrastructure: event_calendar.parquet, event_utils.py

## Estimated Time

- Notebook structure: 10 min
- Data loading & preparation: 15 min
- Event tagging: 10 min
- Impact analysis: 20 min
- Visualizations: 20 min
- Report generation: 10 min
- Testing & validation: 5 min
- **Total: ~90 min**

---
*Plan created: 2026-02-03*
