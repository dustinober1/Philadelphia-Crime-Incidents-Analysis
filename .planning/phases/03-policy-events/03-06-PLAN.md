# Plan 03-06: Integration & Validation

**Phase:** 3 — Policy Deep Dives & Event Impacts
**Wave:** 3 (Integration)
**Depends on:** 03-02, 03-03, 03-04, 03-05 (All Wave 2 notebooks)

## Goal

Integrate all Phase 3 analyses, validate artifacts, create a summary notebook, and update orchestration scripts for automated execution.

## Context

This plan validates and integrates the following Phase 3 deliverables:
- POLICY-01: Retail theft trend analysis with verdict
- POLICY-02: Vehicle crimes corridor analysis with quantification
- POLICY-03: Crime composition analysis with violent ratio trends
- HYP-EVENTS: Event impact analysis with statistical tests

## Tasks

### 1. Create Phase 3 Validation Script

**1.1 Create `analysis/validate_phase3.py`**
```python
"""Validation script for Phase 3 artifacts."""

from pathlib import Path
from typing import Dict, List, Tuple
import pandas as pd
import json

def validate_phase3_artifacts(repo_root: Path) -> Dict[str, List[Tuple[str, bool, str]]]:
    """Validate all Phase 3 artifacts.

    Returns dict with validation results by notebook.
    """
    reports_dir = repo_root / 'reports'
    data_dir = repo_root / 'data'

    results = {
        'retail_theft': [],
        'vehicle_crimes': [],
        'crime_composition': [],
        'event_impacts': []
    }

    # Retail Theft (POLICY-01)
    checks = [
        ('retail_theft_trend.png', 'PNG visualization exists'),
        ('retail_theft_monthly_heatmap.png', 'Monthly heatmap exists'),
        ('retail_theft_report.md', 'Summary report exists'),
        ('retail_theft_annual.csv', 'Annual data CSV exists'),
    ]
    for artifact, desc in checks:
        path = reports_dir / artifact
        exists = path.exists()
        results['retail_theft'].append((artifact, exists, desc))

    # Validate verdict in report
    report_path = reports_dir / 'retail_theft_report.md'
    if report_path.exists():
        content = report_path.read_text()
        has_verdict = 'SUPPORTED' in content or 'NOT SUPPORTED' in content
        results['retail_theft'].append(('verdict', has_verdict, 'Report contains verdict'))

    # Vehicle Crimes (POLICY-02)
    checks = [
        ('vehicle_crimes_corridors.png', 'Static map exists'),
        ('vehicle_crimes_corridors.html', 'Interactive map exists'),
        ('vehicle_crimes_corridor_report.md', 'Summary report exists'),
        ('vehicle_crimes_corridor_stats.csv', 'Corridor stats CSV exists'),
        ('vehicle_crimes_per_corridor.csv', 'Per-corridor breakdown exists'),
    ]
    for artifact, desc in checks:
        path = reports_dir / artifact
        exists = path.exists()
        results['vehicle_crimes'].append((artifact, exists, desc))

    # Validate quantification
    stats_path = reports_dir / 'vehicle_crimes_corridor_stats.csv'
    if stats_path.exists():
        stats = pd.read_csv(stats_path)
        has_pct = 'pct_of_crimes' in stats.columns
        pct_valid = stats['pct_of_crimes'].between(0, 100).all() if has_pct else False
        results['vehicle_crimes'].append(('quantification', has_pct and pct_valid, 'Valid % quantification'))

    # Crime Composition (POLICY-03)
    checks = [
        ('crime_composition_stacked.png', 'Stacked area chart exists'),
        ('crime_composition_pct.png', 'Percentage chart exists'),
        ('violent_ratio_trend.png', 'Violent ratio trend exists'),
        ('crime_composition_report.md', 'Summary report exists'),
        ('crime_composition_annual.csv', 'Annual data CSV exists'),
    ]
    for artifact, desc in checks:
        path = reports_dir / artifact
        exists = path.exists()
        results['crime_composition'].append((artifact, exists, desc))

    # Event Impacts (HYP-EVENTS)
    checks = [
        ('event_impact_forest.png', 'Forest plot exists'),
        ('event_impact_by_category.png', 'Category comparison exists'),
        ('event_impact_report.md', 'Summary report exists'),
        ('event_impact_results.csv', 'Results CSV exists'),
    ]
    for artifact, desc in checks:
        path = reports_dir / artifact
        exists = path.exists()
        results['event_impacts'].append((artifact, exists, desc))

    # Validate statistical results
    results_path = reports_dir / 'event_impact_results.csv'
    if results_path.exists():
        df = pd.read_csv(results_path)
        has_pvalue = 'p_value' in df.columns
        has_ci = 'ci_lower' in df.columns and 'ci_upper' in df.columns
        results['event_impacts'].append(('statistics', has_pvalue and has_ci, 'Has p-values and CIs'))

    return results

def print_validation_report(results: Dict) -> Tuple[int, int]:
    """Print validation report and return pass/fail counts."""
    total_pass = 0
    total_fail = 0

    print("\n" + "="*60)
    print("PHASE 3 ARTIFACT VALIDATION")
    print("="*60)

    for notebook, checks in results.items():
        print(f"\n{notebook.upper().replace('_', ' ')}")
        print("-" * 40)
        for artifact, passed, desc in checks:
            status = "PASS" if passed else "FAIL"
            icon = "✓" if passed else "✗"
            print(f"  {icon} [{status}] {desc}")
            if passed:
                total_pass += 1
            else:
                total_fail += 1

    print("\n" + "="*60)
    print(f"SUMMARY: {total_pass} passed, {total_fail} failed")
    print("="*60)

    return total_pass, total_fail

if __name__ == "__main__":
    repo_root = Path(__file__).resolve().parent.parent
    results = validate_phase3_artifacts(repo_root)
    passed, failed = print_validation_report(results)
    exit(0 if failed == 0 else 1)
```

### 2. Create Phase 3 Summary Notebook

**2.1 Create `notebooks/phase3_summary.ipynb`**
```python
# Cell 1: Title
"""
# Phase 3 Summary: Policy Deep Dives & Event Impacts

This notebook summarizes the findings from Phase 3 analyses:
- POLICY-01: Retail Theft Trend Analysis
- POLICY-02: Vehicle Crimes Corridor Analysis
- POLICY-03: Crime Composition Analysis
- HYP-EVENTS: Event Impact Analysis
"""

# Cell 2: Setup
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
from IPython.display import Markdown, Image

repo_root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()
REPORTS_DIR = repo_root / 'reports'

# Cell 3: POLICY-01 Summary
"""## POLICY-01: Retail Theft Trend Analysis"""
display(Image(str(REPORTS_DIR / 'retail_theft_trend.png'), width=800))
display(Markdown(open(REPORTS_DIR / 'retail_theft_report.md').read()[:2000]))

# Cell 4: POLICY-02 Summary
"""## POLICY-02: Vehicle Crimes Corridor Analysis"""
display(Image(str(REPORTS_DIR / 'vehicle_crimes_corridors.png'), width=800))
stats = pd.read_csv(REPORTS_DIR / 'vehicle_crimes_corridor_stats.csv')
display(stats)

# Cell 5: POLICY-03 Summary
"""## POLICY-03: Crime Composition Analysis"""
display(Image(str(REPORTS_DIR / 'crime_composition_stacked.png'), width=800))
display(Image(str(REPORTS_DIR / 'violent_ratio_trend.png'), width=800))

# Cell 6: HYP-EVENTS Summary
"""## HYP-EVENTS: Event Impact Analysis"""
display(Image(str(REPORTS_DIR / 'event_impact_forest.png'), width=800))
results = pd.read_csv(REPORTS_DIR / 'event_impact_results.csv')
sig_results = results[results['significant']]
print(f"Significant event impacts: {len(sig_results)}")
display(sig_results)

# Cell 7: Cross-Reference
"""## Cross-Reference Analysis"""
# Load all annual data for comparison
retail = pd.read_csv(REPORTS_DIR / 'retail_theft_annual.csv')
composition = pd.read_csv(REPORTS_DIR / 'crime_composition_annual.csv')

# Merge for comparison
merged = retail.merge(composition[['year', 'Violent', 'Total']],
                      left_on='year', right_index=True, how='left')
print("Retail theft as % of total crime:")
merged['theft_pct'] = merged['count'] / merged['Total'] * 100
print(merged[['year', 'count', 'Total', 'theft_pct']].tail())

# Cell 8: Key Takeaways
takeaways = """
## Key Takeaways

### POLICY-01: Retail Theft
- [Insert verdict from analysis]
- Key driver: [Insert key finding]

### POLICY-02: Vehicle Crimes
- [X]% of vehicle crimes occur within corridor buffers
- Highest concentration: [Insert corridor name]

### POLICY-03: Crime Composition
- Violent crime ratio trend: [stable/increasing/decreasing]
- COVID impact: [Insert finding]

### HYP-EVENTS: Event Impacts
- [X] significant impacts detected
- Most notable: [Insert event type and impact]
"""
print(takeaways)
```

### 3. Create Phase 3 Orchestrator

**3.1 Create `analysis/orchestrate_phase3.py`**
```python
"""Orchestration script for Phase 3 notebooks."""

import subprocess
import sys
from pathlib import Path
from datetime import datetime

def run_notebook(notebook_path: Path, timeout: int = 600) -> bool:
    """Execute a notebook via nbconvert."""
    cmd = [
        sys.executable, '-m', 'nbconvert',
        '--to', 'notebook',
        '--execute',
        '--inplace',
        '--ExecutePreprocessor.timeout=' + str(timeout),
        str(notebook_path)
    ]

    print(f"\nExecuting: {notebook_path.name}")
    print("-" * 40)

    try:
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=timeout + 60)
        if result.returncode == 0:
            print(f"  ✓ Success")
            return True
        else:
            print(f"  ✗ Failed: {result.stderr[:200]}")
            return False
    except subprocess.TimeoutExpired:
        print(f"  ✗ Timeout after {timeout}s")
        return False
    except Exception as e:
        print(f"  ✗ Error: {e}")
        return False

def main():
    repo_root = Path(__file__).resolve().parent.parent
    notebooks_dir = repo_root / 'notebooks'

    # Phase 3 notebooks in execution order
    notebooks = [
        'retail_theft_trend.ipynb',
        'vehicle_crimes_corridors.ipynb',
        'crime_composition.ipynb',
        'event_impacts.ipynb',
        'phase3_summary.ipynb',
    ]

    print("="*60)
    print("PHASE 3 ORCHESTRATION")
    print(f"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60)

    results = {}
    for notebook in notebooks:
        path = notebooks_dir / notebook
        if path.exists():
            results[notebook] = run_notebook(path)
        else:
            print(f"\n⚠ Notebook not found: {notebook}")
            results[notebook] = False

    # Run validation
    print("\n" + "="*60)
    print("RUNNING VALIDATION")
    print("="*60)

    from analysis.validate_phase3 import validate_phase3_artifacts, print_validation_report
    validation_results = validate_phase3_artifacts(repo_root)
    passed, failed = print_validation_report(validation_results)

    # Summary
    print("\n" + "="*60)
    print("ORCHESTRATION SUMMARY")
    print("="*60)
    print(f"\nNotebooks executed: {sum(results.values())}/{len(results)}")
    print(f"Validation: {passed} passed, {failed} failed")
    print(f"Finished: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    return 0 if all(results.values()) and failed == 0 else 1

if __name__ == "__main__":
    sys.exit(main())
```

### 4. Cross-Reference Validation

**4.1 Verify Data Consistency**
```python
# Add to validate_phase3.py or run separately

def cross_reference_checks(repo_root: Path) -> List[Tuple[str, bool, str]]:
    """Run cross-reference validation checks."""
    reports_dir = repo_root / 'reports'
    checks = []

    # Check 1: Retail theft counts match composition theft category
    try:
        retail = pd.read_csv(reports_dir / 'retail_theft_annual.csv')
        composition = pd.read_csv(reports_dir / 'crime_composition_annual.csv', index_col=0)

        # Compare 2023 counts (should be close, may differ due to filtering)
        retail_2023 = retail[retail['year'] == 2023]['count'].values[0]
        # Composition includes all theft (UCR 600), retail is just "Thefts" text code
        # So retail should be <= composition Property
        valid = retail_2023 <= composition.loc[2023, 'Property']
        checks.append(('retail_vs_composition', valid, 'Retail theft <= Property crimes'))
    except Exception as e:
        checks.append(('retail_vs_composition', False, f'Error: {e}'))

    # Check 2: Event impacts have consistent totals
    try:
        events = pd.read_csv(reports_dir / 'event_impact_results.csv')
        # All event types should have same n_control_days
        n_controls = events[events['metric'] == 'total']['n_control_days'].unique()
        valid = len(n_controls) == 1
        checks.append(('event_controls', valid, 'Consistent control day counts'))
    except Exception as e:
        checks.append(('event_controls', False, f'Error: {e}'))

    # Check 3: Vehicle crimes corridor percentages sum correctly
    try:
        stats = pd.read_csv(reports_dir / 'vehicle_crimes_corridor_stats.csv')
        any_pct = stats[stats['corridor_type'] == 'any']['pct_of_crimes'].values[0]
        highway_pct = stats[stats['corridor_type'] == 'highway']['pct_of_crimes'].values[0]
        transit_pct = stats[stats['corridor_type'] == 'transit']['pct_of_crimes'].values[0]
        # Any should be >= max of individual (due to overlap)
        valid = any_pct >= max(highway_pct, transit_pct)
        checks.append(('corridor_pct', valid, 'Corridor percentages consistent'))
    except Exception as e:
        checks.append(('corridor_pct', False, f'Error: {e}'))

    return checks
```

### 5. Update STATE.md Template

**5.1 Phase 3 STATE.md Update Template**
```markdown
## Current Position

Phase: 3 of 4 (Policy Deep Dives & Event Impacts) - COMPLETE
Plan: 6 of 6 in current phase
Status: Phase 3 complete, ready for Phase 4
Last activity: [DATE] - Completed 03-06-PLAN.md (Integration & Validation)

Progress: ██████████ 100% (Phase 3: 6/6 plans)

## Phase 3 Summary

**Artifacts Validated:** [X] passed, [Y] failed
**Cross-reference checks:** [status]
**Total artifacts:** [N] files across retail theft, vehicle crimes, composition, events

### Key Deliverables
- **POLICY-01**: Retail theft verdict: [SUPPORTED/NOT SUPPORTED], [X]% change from baseline
- **POLICY-02**: [X]% of vehicle crimes within [N]m of corridors
- **POLICY-03**: Violent ratio range [X]-[Y]%, COVID impact [described]
- **HYP-EVENTS**: [X] significant event impacts detected
```

### 6. Run Full Validation

**6.1 Execute All Checks**
```bash
# Run orchestrator
python analysis/orchestrate_phase3.py

# Verify all reports generated
ls -la reports/retail_theft* reports/vehicle_crimes* reports/crime_composition* reports/event_impact*
```

## Validation Criteria

- [ ] `analysis/validate_phase3.py` runs without errors
- [ ] All 4 notebooks execute successfully via orchestrator
- [ ] `notebooks/phase3_summary.ipynb` displays all key visualizations
- [ ] Cross-reference checks pass
- [ ] At least 20 artifacts generated in `reports/`
- [ ] STATE.md updated with Phase 3 completion status

## Dependencies

- nbconvert (for notebook execution)
- All Phase 3 notebook dependencies
- Previous plan artifacts (03-02 through 03-05)

## Estimated Time

- Validation script: 15 min
- Summary notebook: 20 min
- Orchestrator: 15 min
- Cross-reference checks: 10 min
- Full execution & testing: 15 min
- **Total: ~75 min**

---
*Plan created: 2026-02-03*
