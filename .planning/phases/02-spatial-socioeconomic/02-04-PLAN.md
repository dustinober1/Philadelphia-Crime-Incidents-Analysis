# Plan 02-04: District Severity Scoring

**Phase:** 2 â€” Spatial & Socioeconomic Analysis
**Wave:** 2 (Core Analysis)
**Requirement:** PATROL-03
**Depends on:** 02-01 (Infrastructure & Boundary Data)

## Goal

Create a district-level severity scoring notebook that calculates a multi-factor composite score for each police district, produces a choropleth map, and ranks districts by severity and per-capita crime rate for resource allocation decisions.

## Context

From 02-01, this plan will use:
- `data/boundaries/police_districts.geojson` for district boundaries
- `config/phase2_config.yaml` for UCR severity weights
- `analysis/spatial_utils.py` for severity calculation and spatial joins
- `analysis/phase2_config_loader.py` for config access

Implementation decisions from 02-CONTEXT.md:
- Use multi-factor composite score with four factors:
  - Total crime count
  - Violent crime ratio
  - Trend direction (year-over-year)
  - Per-capita rate
- Present as both choropleth map and ranked table with score breakdown
- Factor weights: Claude's discretion

## Tasks

### 1. Create Notebook Structure

**1.1 Create `notebooks/district_severity.ipynb`**

Standard notebook structure per AGENTS.md:
- Title: "District Severity Scoring (PATROL-03)"
- Overview: Calculate composite severity scores for police district resource prioritization
- Reproducibility cell with version info
- Imports: pandas, geopandas, numpy, matplotlib
- Data loading using analysis.utils.load_data()

### 2. Data Preparation

**2.1 Load Data**
```python
from analysis.utils import load_data, classify_crime_category
from analysis.spatial_utils import load_boundaries, calculate_severity_score
from analysis.phase2_config_loader import Phase2Config

df = load_data(clean=True)
df = classify_crime_category(df)
config = Phase2Config()

# Load district boundaries
districts_gdf = load_boundaries('police_districts')
print(f"Total crime records: {len(df):,}")
print(f"Police districts: {len(districts_gdf)}")
```

**2.2 Validate District Coverage**
```python
# Check district code mapping
df['dc_dist'] = df['dc_dist'].astype(str).str.strip()
crime_districts = set(df['dc_dist'].unique())
boundary_districts = set(districts_gdf['DISTRICT_'].astype(str).unique())  # Adjust column name as needed

print(f"Crime data districts: {len(crime_districts)}")
print(f"Boundary file districts: {len(boundary_districts)}")
print(f"Overlap: {len(crime_districts & boundary_districts)}")

# Map crimes to districts if using spatial join (alternative to dc_dist column)
```

### 3. Factor 1: Total Crime Count

**3.1 Calculate District Crime Counts**
```python
crime_counts = df.groupby('dc_dist').size().reset_index(name='total_crimes')
crime_counts['crime_count_score'] = crime_counts['total_crimes'] / crime_counts['total_crimes'].max()

print("\nCrime counts by district:")
print(crime_counts.sort_values('total_crimes', ascending=False).head(10))
```

### 4. Factor 2: Violent Crime Ratio

**4.1 Calculate Violent Crime Percentage**
```python
violent_counts = df[df['crime_category'] == 'Violent'].groupby('dc_dist').size().reset_index(name='violent_crimes')

district_stats = crime_counts.merge(violent_counts, on='dc_dist', how='left')
district_stats['violent_crimes'] = district_stats['violent_crimes'].fillna(0)
district_stats['violent_ratio'] = district_stats['violent_crimes'] / district_stats['total_crimes']
district_stats['violent_ratio_score'] = district_stats['violent_ratio'] / district_stats['violent_ratio'].max()

print("\nViolent crime ratio by district:")
print(district_stats[['dc_dist', 'violent_crimes', 'violent_ratio']].sort_values('violent_ratio', ascending=False).head(10))
```

### 5. Factor 3: Trend Direction (Year-over-Year)

**5.1 Calculate YoY Change**
```python
# Get year from dispatch_date
df['year'] = pd.to_datetime(df['dispatch_date']).dt.year

# Calculate most recent full year vs prior year
max_year = df['year'].max()
recent_year = max_year if df[df['year'] == max_year].shape[0] > 10000 else max_year - 1
prior_year = recent_year - 1

recent_crimes = df[df['year'] == recent_year].groupby('dc_dist').size().reset_index(name='recent')
prior_crimes = df[df['year'] == prior_year].groupby('dc_dist').size().reset_index(name='prior')

yoy = recent_crimes.merge(prior_crimes, on='dc_dist', how='outer').fillna(0)
yoy['yoy_change'] = (yoy['recent'] - yoy['prior']) / yoy['prior'].replace(0, 1)
yoy['trend_score'] = (yoy['yoy_change'] + 1) / 2  # Normalize to 0-1 (negative = good = low score)
yoy['trend_score'] = yoy['trend_score'].clip(0, 1)

district_stats = district_stats.merge(yoy[['dc_dist', 'yoy_change', 'trend_score']], on='dc_dist', how='left')

print(f"\nYear-over-year change ({prior_year} to {recent_year}):")
print(district_stats[['dc_dist', 'yoy_change']].sort_values('yoy_change', ascending=False).head(10))
```

### 6. Factor 4: Per-Capita Rate

**6.1 Aggregate Tract Population to Districts**
```python
# Load census tracts with population from 02-01
from analysis.spatial_utils import load_boundaries
tracts_gdf = load_boundaries('census_tracts')

# Get population column from config
pop_col = config.census['population_column']  # 'total_pop'

# Create tract centroids for assignment to districts
tracts_gdf['centroid'] = tracts_gdf.geometry.centroid
tracts_centroids = gpd.GeoDataFrame(
    tracts_gdf[[pop_col, 'GEOID']],
    geometry=tracts_gdf['centroid'],
    crs=tracts_gdf.crs
)

# Spatial join: assign each tract centroid to a district
tracts_in_districts = gpd.sjoin(tracts_centroids, districts_gdf[['DISTRICT_', 'geometry']],
                                 how='left', predicate='within')

# Aggregate population by district
district_pop = tracts_in_districts.groupby('DISTRICT_')[pop_col].sum().reset_index()
district_pop = district_pop.rename(columns={'DISTRICT_': 'dc_dist', pop_col: 'district_population'})
district_pop['dc_dist'] = district_pop['dc_dist'].astype(str)

print(f"\\nDistrict population summary:")
print(f"  Total: {district_pop['district_population'].sum():,.0f} (~1.6M expected)")
print(f"  Mean per district: {district_pop['district_population'].mean():,.0f}")
print(f"  Min: {district_pop['district_population'].min():,.0f}")
print(f"  Max: {district_pop['district_population'].max():,.0f}")
```

**6.2 Calculate Per-Capita Crime Rate**
```python
# Merge population to district stats
district_stats = district_stats.merge(district_pop, on='dc_dist', how='left')

# Calculate crimes per 100,000 residents (FBI UCR convention)
rate_per = 100000
district_stats['crimes_per_capita'] = (district_stats['total_crimes'] / district_stats['district_population']) * rate_per
district_stats['percapita_rate_score'] = district_stats['crimes_per_capita'] / district_stats['crimes_per_capita'].max()

print("\\nCrimes per 100,000 residents by district:")
print(district_stats[['dc_dist', 'district_population', 'crimes_per_capita']].sort_values('crimes_per_capita', ascending=False).head(10))
```

**6.3 Calculate Area-Based Rate (Secondary)**
```python
# Also compute area-based rate as secondary metric
districts_gdf['area_km2'] = districts_gdf.geometry.to_crs(epsg=32618).area / 1e6

district_area = districts_gdf[['DISTRICT_', 'area_km2']].rename(columns={'DISTRICT_': 'dc_dist'})
district_area['dc_dist'] = district_area['dc_dist'].astype(str)

district_stats = district_stats.merge(district_area, on='dc_dist', how='left')
district_stats['crimes_per_km2'] = district_stats['total_crimes'] / district_stats['area_km2']
district_stats['area_rate_score'] = district_stats['crimes_per_km2'] / district_stats['crimes_per_km2'].max()

print("\\nCrimes per sq km by district:")
print(district_stats[['dc_dist', 'crimes_per_km2']].sort_values('crimes_per_km2', ascending=False).head(10))
```

### 7. Composite Severity Score

**7.1 Calculate Weighted Composite**
```python
# Factor weights (Claude's discretion - balanced approach)
# Uses per-capita rate as primary density factor (true population-normalized)
WEIGHTS = {
    'crime_count': 0.25,        # Volume matters
    'violent_ratio': 0.30,      # Violence severity matters most
    'trend': 0.20,              # Growing problems need attention
    'percapita_rate': 0.25      # Per-capita rate (per 100,000) - population normalized
}

district_stats['composite_score'] = (
    WEIGHTS['crime_count'] * district_stats['crime_count_score'] +
    WEIGHTS['violent_ratio'] * district_stats['violent_ratio_score'] +
    WEIGHTS['trend'] * district_stats['trend_score'].fillna(0) +
    WEIGHTS['percapita_rate'] * district_stats['percapita_rate_score']
)

# Scale to 0-100
district_stats['severity_score'] = (district_stats['composite_score'] * 100).round(1)

print("\nDistrict Severity Scores:")
print(district_stats[['dc_dist', 'severity_score']].sort_values('severity_score', ascending=False))
```

### 8. Choropleth Map

**8.1 Merge Scores to Boundaries**
```python
districts_gdf['dc_dist'] = districts_gdf['DISTRICT_'].astype(str)
districts_scored = districts_gdf.merge(district_stats[['dc_dist', 'severity_score', 'total_crimes',
                                                        'violent_ratio', 'yoy_change', 'crimes_per_capita',
                                                        'district_population']],
                                        on='dc_dist', how='left')
```

**8.2 Create Choropleth**
```python
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap

fig, ax = plt.subplots(figsize=(14, 12))

# Yellow-Orange-Red colormap
colors = ['#FFFFE0', '#FFEDA0', '#FED976', '#FEB24C', '#FD8D3C', '#FC4E2A', '#E31A1C', '#B10026']
cmap = LinearSegmentedColormap.from_list('YlOrRd', colors)

districts_scored.plot(column='severity_score', cmap=cmap, linewidth=0.5,
                      edgecolor='black', legend=True, ax=ax,
                      legend_kwds={'label': 'Severity Score', 'orientation': 'horizontal'})

# Add district labels
for idx, row in districts_scored.iterrows():
    centroid = row.geometry.centroid
    ax.annotate(text=f"{row['dc_dist']}\n({row['severity_score']:.0f})",
                xy=(centroid.x, centroid.y), ha='center', fontsize=8, fontweight='bold')

ax.set_title('Philadelphia Police District Severity Scores', fontsize=16)
ax.set_axis_off()

plt.tight_layout()
plt.savefig(REPORTS_DIR / 'district_severity_choropleth.png', dpi=300, bbox_inches='tight')
artifacts.append(('district_severity_choropleth.png', 'District severity choropleth map'))
plt.show()
```

### 9. Ranked Table

**9.1 Create Ranking Table**
```python
ranking_table = district_stats[['dc_dist', 'severity_score', 'total_crimes',
                                 'violent_ratio', 'yoy_change', 'crimes_per_capita', 'district_population']].copy()

ranking_table['violent_ratio'] = (ranking_table['violent_ratio'] * 100).round(1)
ranking_table['yoy_change'] = (ranking_table['yoy_change'] * 100).round(1)
ranking_table['crimes_per_capita'] = ranking_table['crimes_per_capita'].round(0)
ranking_table['district_population'] = ranking_table['district_population'].round(0)

ranking_table = ranking_table.sort_values('severity_score', ascending=False)
ranking_table['rank'] = range(1, len(ranking_table) + 1)
ranking_table = ranking_table[['rank', 'dc_dist', 'severity_score', 'total_crimes',
                                'violent_ratio', 'yoy_change', 'crimes_per_capita', 'district_population']]

print("\\nDistrict Severity Ranking:")
print(ranking_table.to_string(index=False))
```

**9.2 Save Table**
```python
ranking_table.columns = ['Rank', 'District', 'Severity Score', 'Total Crimes',
                         'Violent %', 'YoY Change %', 'Rate per 100K', 'Population']
ranking_table.to_csv(REPORTS_DIR / 'district_severity_ranking.csv', index=False)
artifacts.append(('district_severity_ranking.csv', 'District severity ranking table'))

# Also save as markdown for reports
md_table = ranking_table.to_markdown(index=False)
with open(REPORTS_DIR / 'district_severity_ranking.md', 'w') as f:
    f.write("# District Severity Ranking\\n\\n")
    f.write(f"*Analysis period: {df['year'].min()}-{df['year'].max()}*\\n\\n")
    f.write("## Scoring Methodology\\n\\n")
    f.write("Composite score based on:\\n")
    f.write(f"- Crime count (weight: {WEIGHTS['crime_count']})\\n")
    f.write(f"- Violent crime ratio (weight: {WEIGHTS['violent_ratio']})\\n")
    f.write(f"- YoY trend (weight: {WEIGHTS['trend']})\\n")
    f.write(f"- Per-capita rate per 100,000 (weight: {WEIGHTS['percapita_rate']})\\n\\n")
    f.write("**Note:** Per-capita rate uses FBI UCR convention (crimes per 100,000 residents).\\n")
    f.write("District population aggregated from census tract data via spatial join.\\n\\n")
    f.write("## Ranking\\n\\n")
    f.write(md_table)

artifacts.append(('district_severity_ranking.md', 'Severity ranking with methodology'))
```

### 10. GeoJSON Export

**10.1 Export Scored Districts**
```python
# Export for downstream use
districts_scored.to_file(REPORTS_DIR / 'districts_scored.geojson', driver='GeoJSON')
artifacts.append(('districts_scored.geojson', 'GeoJSON with severity scores'))
```

### 11. Notebook Completion

**11.1 Artifact Summary Cell**
```python
print("\n" + "="*60)
print("NOTEBOOK COMPLETE: District Severity Scoring (PATROL-03)")
print("="*60)
print(f"\nArtifacts generated:")
for name, desc in artifacts:
    print(f"  - {name}: {desc}")
print(f"\nRuntime: {time.time() - RUNTIME_START:.1f} seconds")
```

**11.2 Markdown Conclusion Cell**
Document methodology, top-priority districts, and resource allocation recommendations in narrative format.

## Validation Criteria

- [ ] Notebook executes end-to-end without errors
- [ ] Reproducibility cell present with version info
- [ ] `reports/district_severity_choropleth.png` exists at 300 DPI
- [ ] All 25 districts colored and labeled on choropleth
- [ ] `reports/district_severity_ranking.csv` contains all districts
- [ ] Ranking includes all four factors (count, violent %, YoY, per-capita rate per 100K)
- [ ] Per-capita rate uses FBI UCR convention (per 100,000 residents)
- [ ] District population derived from census tract aggregation (sum ~1.6M total)
- [ ] `reports/districts_scored.geojson` loadable and has severity_score column
- [ ] Weights documented in ranking markdown file

## Dependencies

- geopandas (for choropleth)
- matplotlib (for visualization)
- 02-01 infrastructure: police_districts.geojson, census_tracts_pop.geojson, spatial_utils.py, phase2_config_loader.py

## Estimated Time

- Notebook structure: 10 min
- Factor calculations (4 factors): 30 min
- Composite score: 10 min
- Choropleth map: 15 min
- Ranking table: 10 min
- Testing & validation: 10 min
- **Total: ~85 min**

---
*Plan created: 2026-02-03*
