# Plan 02-03: Robbery Temporal Heatmap

**Phase:** 2 — Spatial & Socioeconomic Analysis
**Wave:** 2 (Core Analysis)
**Requirement:** PATROL-02
**Depends on:** 02-01 (Infrastructure & Boundary Data)

## Goal

Create a temporal heatmap notebook that visualizes Robbery incidents by Hour × Weekday to identify peak patrol timing, with actionable recommendations for shift allocation.

## Context

From 02-01, this plan will use:
- `config/phase2_config.yaml` for robbery UCR code range (300-399)
- `analysis/utils.py` for data loading and temporal feature extraction

Implementation decisions from 02-CONTEXT.md:
- Use 4-hour time bins × 7 weekdays (42 cells)
- Show both city-wide patterns and per-district breakdown if meaningful differences exist
- Combine all robbery types with subtype breakdown available if useful
- Present recommendations as both narrative summary and bullet-point actionable items

## Tasks

### 1. Create Notebook Structure

**1.1 Create `notebooks/robbery_temporal_heatmap.ipynb`**

Standard notebook structure per AGENTS.md:
- Title: "Robbery Temporal Patterns (PATROL-02)"
- Overview: Identify peak robbery times for patrol shift optimization
- Reproducibility cell with version info
- Imports: pandas, numpy, matplotlib, seaborn
- Data loading using analysis.utils.load_data()

### 2. Data Preparation

**2.1 Load and Filter Robbery Data**
```python
from analysis.utils import load_data, extract_temporal_features
from analysis.phase2_config_loader import Phase2Config

df = load_data(clean=True)
config = Phase2Config()

# Filter to robbery incidents (UCR 300-399)
robbery_range = config.heatmap['robbery_ucr_range']
df['ucr_general'] = pd.to_numeric(df['ucr_general'], errors='coerce')
df_robbery = df[(df['ucr_general'] >= robbery_range[0]) &
                (df['ucr_general'] < robbery_range[1])].copy()

print(f"Total robbery incidents: {len(df_robbery):,}")
```

**2.2 Extract Temporal Features**
```python
# Parse datetime and extract hour, day of week
df_robbery['dispatch_datetime'] = pd.to_datetime(df_robbery['dispatch_date_time'], errors='coerce')
df_robbery = df_robbery.dropna(subset=['dispatch_datetime'])

df_robbery['hour'] = df_robbery['dispatch_datetime'].dt.hour
df_robbery['day_of_week'] = df_robbery['dispatch_datetime'].dt.dayofweek
df_robbery['day_name'] = df_robbery['dispatch_datetime'].dt.day_name()

# Create 4-hour time bins
time_bins = [0, 4, 8, 12, 16, 20, 24]
time_labels = ['00-04', '04-08', '08-12', '12-16', '16-20', '20-24']
df_robbery['time_bin'] = pd.cut(df_robbery['hour'], bins=time_bins, labels=time_labels, right=False)

print(f"Records with valid temporal data: {len(df_robbery):,}")
print(f"Hour coverage: {df_robbery['hour'].notna().sum() / len(df_robbery) * 100:.1f}%")
```

### 3. City-Wide Heatmap

**3.1 Create Pivot Table**
```python
# Aggregate by time bin and day of week
day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
heatmap_data = df_robbery.pivot_table(
    values='objectid',
    index='time_bin',
    columns='day_name',
    aggfunc='count'
)[day_order]

print("City-wide robbery counts by time bin × day:")
print(heatmap_data)
```

**3.2 Create Heatmap Visualization**
```python
import matplotlib.pyplot as plt
import seaborn as sns

fig, ax = plt.subplots(figsize=(12, 8))

# Yellow-Orange-Red colormap per context decisions
cmap = sns.color_palette("YlOrRd", as_cmap=True)

sns.heatmap(heatmap_data, annot=True, fmt='.0f', cmap=cmap,
            linewidths=0.5, ax=ax, cbar_kws={'label': 'Incident Count'})

ax.set_title('Philadelphia Robbery Incidents: Hour × Weekday\n(All Years Combined)', fontsize=14)
ax.set_xlabel('Day of Week', fontsize=12)
ax.set_ylabel('Time of Day (4-hour bins)', fontsize=12)

plt.tight_layout()
plt.savefig(REPORTS_DIR / 'robbery_temporal_heatmap.png', dpi=300, bbox_inches='tight')
artifacts.append(('robbery_temporal_heatmap.png', 'City-wide robbery temporal heatmap'))
plt.show()
```

### 4. Per-District Breakdown

**4.1 Calculate District Variance**
```python
# Check if meaningful district differences exist
district_time = df_robbery.groupby(['dc_dist', 'time_bin', 'day_name']).size().reset_index(name='count')
district_peaks = district_time.groupby('dc_dist').apply(
    lambda x: x.loc[x['count'].idxmax(), ['time_bin', 'day_name', 'count']]
).reset_index()

# Calculate coefficient of variation across districts
district_cv = district_time.groupby(['time_bin', 'day_name'])['count'].std() / \
              district_time.groupby(['time_bin', 'day_name'])['count'].mean()

if district_cv.mean() > 0.5:  # High variance = meaningful district differences
    print("Significant district-level variation detected. Creating per-district breakdown.")
    create_district_heatmaps = True
else:
    print("District patterns largely consistent with city-wide. Skipping per-district breakdown.")
    create_district_heatmaps = False
```

**4.2 Optional Per-District Heatmaps**
```python
if create_district_heatmaps:
    # Get top 6 districts by robbery count
    top_districts = df_robbery['dc_dist'].value_counts().head(6).index.tolist()

    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    axes = axes.flatten()

    for idx, district in enumerate(top_districts):
        df_dist = df_robbery[df_robbery['dc_dist'] == district]
        pivot = df_dist.pivot_table(
            values='objectid', index='time_bin', columns='day_name', aggfunc='count'
        )[day_order]

        sns.heatmap(pivot, annot=True, fmt='.0f', cmap=cmap,
                   linewidths=0.5, ax=axes[idx], cbar=False)
        axes[idx].set_title(f'District {district}', fontsize=11)
        axes[idx].set_xlabel('')
        axes[idx].set_ylabel('')

    plt.suptitle('Robbery Temporal Patterns by District', fontsize=14, y=1.02)
    plt.tight_layout()
    plt.savefig(REPORTS_DIR / 'robbery_temporal_by_district.png', dpi=300, bbox_inches='tight')
    artifacts.append(('robbery_temporal_by_district.png', 'Per-district temporal heatmaps'))
    plt.show()
```

### 5. Peak Time Analysis

**5.1 Identify Peak Periods**
```python
# Find top 5 peak time-day combinations
flat_data = heatmap_data.stack().reset_index()
flat_data.columns = ['time_bin', 'day_name', 'count']
peaks = flat_data.nlargest(5, 'count')

print("\nTop 5 Peak Robbery Periods:")
for i, row in peaks.iterrows():
    print(f"  {row['day_name']} {row['time_bin']}: {int(row['count'])} incidents")

# Find lowest periods for comparison
lows = flat_data.nsmallest(5, 'count')
print("\nLowest 5 Robbery Periods:")
for i, row in lows.iterrows():
    print(f"  {row['day_name']} {row['time_bin']}: {int(row['count'])} incidents")
```

**5.2 Calculate Percentage Distribution**
```python
# Calculate percentage of robberies by time bin
time_pct = df_robbery['time_bin'].value_counts(normalize=True).sort_index() * 100
print("\nRobbery Distribution by Time of Day:")
for time, pct in time_pct.items():
    print(f"  {time}: {pct:.1f}%")

# Calculate percentage by day
day_pct = df_robbery['day_name'].value_counts(normalize=True)[day_order] * 100
print("\nRobbery Distribution by Day of Week:")
for day, pct in day_pct.items():
    print(f"  {day}: {pct:.1f}%")
```

### 6. Recommendations

**6.1 Generate Patrol Recommendations**
```python
# Determine shift recommendations based on peak analysis
peak_time = peaks.iloc[0]['time_bin']
peak_day = peaks.iloc[0]['day_name']

# Evening/night emphasis if 16-20 or 20-24 are peaks
evening_pct = time_pct.get('16-20', 0) + time_pct.get('20-24', 0)
weekend_pct = day_pct.get('Friday', 0) + day_pct.get('Saturday', 0) + day_pct.get('Sunday', 0)

recommendations = []
if evening_pct > 40:
    recommendations.append("Increase evening/night patrol staffing (16:00-24:00)")
if weekend_pct > 45:
    recommendations.append("Increase weekend patrol allocation")
if peaks.iloc[0]['count'] > peaks.iloc[-1]['count'] * 2:
    recommendations.append(f"Prioritize {peak_day} {peak_time} for robbery prevention patrols")

# Save recommendations
rec_text = "\n".join([f"- {r}" for r in recommendations])
print("\n" + "="*60)
print("PATROL TIMING RECOMMENDATIONS")
print("="*60)
print(rec_text)
```

**6.2 Create Recommendations Summary File**
```python
summary_content = f"""# Robbery Temporal Analysis Recommendations

## Key Findings

- Total robbery incidents analyzed: {len(df_robbery):,}
- Peak period: {peak_day} {peak_time}
- Evening/night robberies (16:00-24:00): {evening_pct:.1f}% of total
- Weekend robberies (Fri-Sun): {weekend_pct:.1f}% of total

## Actionable Recommendations

{rec_text}

## Peak Periods (Top 5)

| Day | Time | Incidents |
|-----|------|-----------|
"""

for _, row in peaks.iterrows():
    summary_content += f"| {row['day_name']} | {row['time_bin']} | {int(row['count'])} |\n"

with open(REPORTS_DIR / 'robbery_patrol_recommendations.md', 'w') as f:
    f.write(summary_content)

artifacts.append(('robbery_patrol_recommendations.md', 'Patrol timing recommendations'))
```

### 7. Notebook Completion

**7.1 Artifact Summary Cell**
```python
print("\n" + "="*60)
print("NOTEBOOK COMPLETE: Robbery Temporal Heatmap (PATROL-02)")
print("="*60)
print(f"\nArtifacts generated:")
for name, desc in artifacts:
    print(f"  - {name}: {desc}")
print(f"\nRuntime: {time.time() - RUNTIME_START:.1f} seconds")
```

**7.2 Markdown Conclusion Cell**
Document key findings, peak robbery times, and patrol shift recommendations in narrative format.

## Validation Criteria

- [ ] Notebook executes end-to-end without errors
- [ ] Reproducibility cell present with version info
- [ ] `reports/robbery_temporal_heatmap.png` exists at 300 DPI
- [ ] Heatmap shows 6 time bins × 7 days (42 cells)
- [ ] `reports/robbery_patrol_recommendations.md` contains actionable bullet points
- [ ] Peak periods identified and documented
- [ ] Per-district breakdown created if variance warrants it
- [ ] Recommendations include specific time ranges

## Dependencies

- matplotlib, seaborn (for heatmap)
- pandas (for pivot tables)
- 02-01 infrastructure: phase2_config_loader.py

## Estimated Time

- Notebook structure: 10 min
- Data filtering & temporal extraction: 15 min
- City-wide heatmap: 15 min
- Per-district analysis: 15 min
- Recommendations generation: 10 min
- Testing & validation: 10 min
- **Total: ~75 min**

---
*Plan created: 2026-02-03*
