# Plan 02-02: Hotspot Clustering

**Phase:** 2 â€” Spatial & Socioeconomic Analysis
**Wave:** 2 (Core Analysis)
**Requirement:** PATROL-01
**Depends on:** 02-01 (Infrastructure & Boundary Data)

## Goal

Create a spatial hotspot clustering notebook that identifies crime concentration areas using DBSCAN, outputs cluster centroids and labels, and produces both static PNG and interactive HTML heatmaps for patrol resource allocation.

## Context

From 02-01, this plan will use:
- `config/phase2_config.yaml` for clustering parameters (eps_degrees, min_samples)
- `analysis/spatial_utils.py` for coordinate cleaning (clean_coordinates)
- `analysis/phase2_config_loader.py` for config access

Implementation decisions from 02-CONTEXT.md:
- Output both static PNG (for reports) and interactive HTML (for exploration)
- Color scheme: Yellow-Orange-Red gradient for intensity
- Visualization method: Claude's discretion (DBSCAN for clustering, kernel density for heatmap)

## Tasks

### 1. Create Notebook Structure

**1.1 Create `notebooks/hotspot_clustering.ipynb`**

Standard notebook structure per AGENTS.md:
- Title: "Spatial Hotspot Analysis (PATROL-01)"
- Overview: Identify crime concentration areas for patrol resource allocation
- Reproducibility cell with version info
- Imports: pandas, geopandas, numpy, sklearn.cluster.DBSCAN, matplotlib, folium
- Data loading using analysis.utils.load_data()
- Data validation for coordinate coverage

### 2. Coordinate Preparation

**2.1 Load and Clean Data**
```python
from analysis.utils import load_data
from analysis.spatial_utils import clean_coordinates
from analysis.phase2_config_loader import Phase2Config

df = load_data(clean=True)
df_coords = clean_coordinates(df, x_col='point_x', y_col='point_y')

print(f"Records with valid coordinates: {len(df_coords):,} ({len(df_coords)/len(df)*100:.1f}%)")
```

**2.2 Extract Coordinates for Clustering**
```python
coords = df_coords[['point_y', 'point_x']].values  # lat, lon for sklearn
```

### 3. DBSCAN Clustering

**3.1 Load Config and Run DBSCAN**
```python
config = Phase2Config()
eps = config.clustering['eps_degrees']  # ~0.002 = 220m
min_samples = config.clustering['min_samples']  # 50

from sklearn.cluster import DBSCAN
clustering = DBSCAN(eps=eps, min_samples=min_samples, metric='haversine')
df_coords['cluster'] = clustering.fit_predict(np.radians(coords))

n_clusters = df_coords['cluster'].nunique() - 1  # -1 for noise
n_clustered = (df_coords['cluster'] >= 0).sum()
print(f"Identified {n_clusters} hotspot clusters")
print(f"Clustered points: {n_clustered:,} ({n_clustered/len(df_coords)*100:.1f}%)")
```

**3.2 Calculate Cluster Centroids**
```python
centroids = df_coords[df_coords['cluster'] >= 0].groupby('cluster').agg({
    'point_x': 'mean',
    'point_y': 'mean',
    'objectid': 'count'  # or any column for count
}).rename(columns={'objectid': 'incident_count'})
centroids = centroids.reset_index()
```

**3.3 Export Cluster Results**
```python
# Save centroids as GeoJSON
import geopandas as gpd
from shapely.geometry import Point

geometry = [Point(xy) for xy in zip(centroids['point_x'], centroids['point_y'])]
centroids_gdf = gpd.GeoDataFrame(centroids, geometry=geometry, crs="EPSG:4326")
centroids_gdf.to_file(REPORTS_DIR / 'hotspot_centroids.geojson', driver='GeoJSON')
artifacts.append(('hotspot_centroids.geojson', 'GeoJSON with cluster centroids'))

# Save full labeled dataset for downstream use
df_coords[['objectid', 'point_x', 'point_y', 'cluster']].to_parquet(
    repo_root / 'data' / 'processed' / 'crimes_with_clusters.parquet'
)
```

### 4. Static Heatmap (PNG)

**4.1 Create Kernel Density Heatmap**
```python
import matplotlib.pyplot as plt
from scipy.stats import gaussian_kde

fig, ax = plt.subplots(figsize=(12, 10))

# Sample if too large for KDE
sample = df_coords.sample(min(50000, len(df_coords)), random_state=42)
xy = np.vstack([sample['point_x'], sample['point_y']])
kde = gaussian_kde(xy, bw_method=0.02)

# Create grid for visualization
xmin, xmax = df_coords['point_x'].quantile([0.001, 0.999])
ymin, ymax = df_coords['point_y'].quantile([0.001, 0.999])
xx, yy = np.mgrid[xmin:xmax:200j, ymin:ymax:200j]
positions = np.vstack([xx.ravel(), yy.ravel()])
density = np.reshape(kde(positions), xx.shape)

# Plot with Yellow-Orange-Red colormap
from matplotlib.colors import LinearSegmentedColormap
colors = ['#FFFFE0', '#FFEDA0', '#FED976', '#FEB24C', '#FD8D3C', '#FC4E2A', '#E31A1C', '#B10026']
cmap = LinearSegmentedColormap.from_list('YlOrRd', colors)

im = ax.imshow(np.rot90(density), cmap=cmap, extent=[xmin, xmax, ymin, ymax], aspect='auto')
plt.colorbar(im, label='Crime Density')

# Overlay cluster centroids
ax.scatter(centroids['point_x'], centroids['point_y'], 
           c='blue', s=50, marker='x', label='Cluster Centroids', zorder=5)

ax.set_title('Philadelphia Crime Hotspots (Kernel Density)')
ax.set_xlabel('Longitude')
ax.set_ylabel('Latitude')
ax.legend()

plt.tight_layout()
plt.savefig(REPORTS_DIR / 'hotspot_heatmap.png', dpi=300, bbox_inches='tight')
artifacts.append(('hotspot_heatmap.png', 'Static heatmap PNG'))
plt.show()
```

### 5. Interactive HTML Map

**5.1 Create Folium Heatmap**
```python
import folium
from folium.plugins import HeatMap

# Center on Philadelphia
center_lat = df_coords['point_y'].mean()
center_lon = df_coords['point_x'].mean()

m = folium.Map(location=[center_lat, center_lon], zoom_start=12, tiles='CartoDB positron')

# Sample for performance
heat_data = df_coords.sample(min(20000, len(df_coords)), random_state=42)[['point_y', 'point_x']].values.tolist()
HeatMap(heat_data, radius=10, blur=15, gradient={
    0.2: '#FFFFE0', 0.4: '#FED976', 0.6: '#FD8D3C', 0.8: '#E31A1C', 1.0: '#B10026'
}).add_to(m)

# Add centroid markers
for _, row in centroids.iterrows():
    folium.CircleMarker(
        location=[row['point_y'], row['point_x']],
        radius=8,
        color='blue',
        fill=True,
        popup=f"Cluster {int(row['cluster'])}: {int(row['incident_count'])} incidents"
    ).add_to(m)

m.save(str(REPORTS_DIR / 'hotspot_heatmap.html'))
artifacts.append(('hotspot_heatmap.html', 'Interactive heatmap HTML'))
```

### 6. Summary Statistics

**6.1 Cluster Summary Table**
```python
# Create summary table
summary = centroids.sort_values('incident_count', ascending=False).head(20)
summary['lat'] = summary['point_y'].round(4)
summary['lon'] = summary['point_x'].round(4)
print("\nTop 20 Hotspot Clusters by Incident Count:")
print(summary[['cluster', 'lat', 'lon', 'incident_count']].to_string(index=False))
```

**6.2 Save Summary**
```python
centroids.to_csv(REPORTS_DIR / 'hotspot_cluster_summary.csv', index=False)
artifacts.append(('hotspot_cluster_summary.csv', 'Cluster summary CSV'))
```

### 7. Notebook Completion

**7.1 Artifact Summary Cell**
```python
print("\n" + "="*60)
print("NOTEBOOK COMPLETE: Hotspot Clustering (PATROL-01)")
print("="*60)
print(f"\nArtifacts generated:")
for name, desc in artifacts:
    print(f"  - {name}: {desc}")
print(f"\nRuntime: {time.time() - RUNTIME_START:.1f} seconds")
```

**7.2 Markdown Conclusion Cell**
Document findings, top hotspots, and recommendations for patrol resource allocation.

## Validation Criteria

- [ ] Notebook executes end-to-end without errors
- [ ] Reproducibility cell present with version info
- [ ] `reports/hotspot_heatmap.png` exists at 300 DPI
- [ ] `reports/hotspot_heatmap.html` opens in browser and shows interactive map
- [ ] `reports/hotspot_centroids.geojson` contains cluster centroids with incident counts
- [ ] `data/processed/crimes_with_clusters.parquet` exists with cluster labels
- [ ] At least 10 clusters identified (indicates reasonable clustering parameters)
- [ ] Cluster centroids display correctly on maps

## Dependencies

- geopandas, folium (for maps)
- scikit-learn (for DBSCAN)
- scipy (for KDE)
- 02-01 infrastructure: spatial_utils.py, phase2_config_loader.py

## Estimated Time

- Notebook structure: 10 min
- DBSCAN implementation: 20 min
- Static heatmap: 15 min
- Interactive HTML: 15 min
- Testing & validation: 15 min
- **Total: ~75 min**

---
*Plan created: 2026-02-03*
