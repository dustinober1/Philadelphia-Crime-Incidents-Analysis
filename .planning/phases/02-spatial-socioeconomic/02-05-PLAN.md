# Plan 02-05: Census Tract Crime Rates

**Phase:** 2 â€” Spatial & Socioeconomic Analysis
**Wave:** 2 (Core Analysis)
**Requirement:** HYP-SOCIO
**Depends on:** 02-01 (Infrastructure & Boundary Data)

## Goal

Create a census tract analysis notebook that spatially joins crime incidents to Census tracts, computes per-100,000-resident crime rates, and flags tracts with unreliable population data for future socioeconomic hypothesis testing.

## Context

From 02-01, this plan will use:
- `data/boundaries/census_tracts_pop.geojson` for tract boundaries with population
- `config/phase2_config.yaml` for rate_per (100,000) and min_population threshold
- `analysis/spatial_utils.py` for coordinate cleaning and spatial join functions
- `analysis/phase2_config_loader.py` for config access

Implementation decisions from 02-CONTEXT.md:
- Use per 100,000 residents (matches FBI UCR convention)
- **Note:** Original roadmap text mentioned "per-1000" but per-100,000 is the FBI UCR standard and was selected as the correct convention. Config updated to rate_per: 100000.
- Output includes both crime rates and raw counts for context
- Census tract boundary handling: Claude's discretion
- Low-population tract handling: Claude's discretion

## Tasks

### 1. Create Notebook Structure

**1.1 Create `notebooks/census_tract_rates.ipynb`**

Standard notebook structure per AGENTS.md:
- Title: "Census Tract Crime Rates (HYP-SOCIO)"
- Overview: Compute population-normalized crime rates at census tract level
- Reproducibility cell with version info
- Imports: pandas, geopandas, numpy, matplotlib
- Data loading using analysis.utils.load_data()

### 2. Data Preparation

**2.1 Load Data**
```python
from analysis.utils import load_data, classify_crime_category
from analysis.spatial_utils import load_boundaries, clean_coordinates, spatial_join_tracts
from analysis.phase2_config_loader import Phase2Config

df = load_data(clean=True)
df = classify_crime_category(df)
config = Phase2Config()

# Load tract boundaries with population
tracts_gdf = load_boundaries('census_tracts')

print(f"Total crime records: {len(df):,}")
print(f"Census tracts: {len(tracts_gdf)}")
```

**2.2 Validate Population Data**
```python
pop_col = config.census['population_column']  # 'total_pop'
min_pop = config.census['min_population']     # 100

print(f"\nPopulation column: {pop_col}")
print(f"Population statistics:")
print(tracts_gdf[pop_col].describe())

# Check for missing/zero population
zero_pop = (tracts_gdf[pop_col] == 0).sum()
low_pop = (tracts_gdf[pop_col] < min_pop).sum()
null_pop = tracts_gdf[pop_col].isna().sum()

print(f"\nTracts with zero population: {zero_pop}")
print(f"Tracts with population < {min_pop}: {low_pop}")
print(f"Tracts with null population: {null_pop}")
```

### 3. Spatial Join

**3.1 Clean Coordinates and Create GeoDataFrame**
```python
df_coords = clean_coordinates(df, x_col='point_x', y_col='point_y')
print(f"Records with valid coordinates: {len(df_coords):,}")

# Create GeoDataFrame
from shapely.geometry import Point

geometry = [Point(xy) for xy in zip(df_coords['point_x'], df_coords['point_y'])]
crimes_gdf = gpd.GeoDataFrame(df_coords, geometry=geometry, crs="EPSG:4326")
```

**3.2 Perform Spatial Join**
```python
# Join crimes to tracts
crimes_with_tract = gpd.sjoin(crimes_gdf, tracts_gdf[['GEOID', pop_col, 'geometry']], 
                               how='left', predicate='within')

# Check join success rate
joined_pct = crimes_with_tract['GEOID'].notna().sum() / len(crimes_with_tract) * 100
print(f"Crimes joined to tracts: {joined_pct:.1f}%")

# Handle unjoined (may be outside Philadelphia boundaries or in water)
unjoined = crimes_with_tract['GEOID'].isna().sum()
if unjoined > 0:
    print(f"Unjoined crimes (outside tract boundaries): {unjoined:,}")
```

### 4. Calculate Crime Counts by Tract

**4.1 Aggregate Crimes**
```python
# Total crimes per tract
tract_crimes = crimes_with_tract.groupby('GEOID').size().reset_index(name='total_crimes')

# Crimes by category
tract_category = crimes_with_tract.groupby(['GEOID', 'crime_category']).size().unstack(fill_value=0)
tract_category.columns = [f'{col.lower()}_crimes' for col in tract_category.columns]
tract_category = tract_category.reset_index()

# Merge
tract_stats = tract_crimes.merge(tract_category, on='GEOID', how='left')

print(f"\nTracts with crime data: {len(tract_stats)}")
```

### 5. Calculate Crime Rates

**5.1 Merge Population and Calculate Rates**
```python
rate_per = config.census['rate_per']  # 100000 per UCR convention

tract_stats = tract_stats.merge(
    tracts_gdf[['GEOID', pop_col]], 
    on='GEOID', 
    how='left'
)

# Calculate rate per 100,000
tract_stats['crime_rate'] = (tract_stats['total_crimes'] / tract_stats[pop_col]) * rate_per

# Calculate category-specific rates
for col in [c for c in tract_stats.columns if c.endswith('_crimes') and c != 'total_crimes']:
    rate_col = col.replace('_crimes', '_rate')
    tract_stats[rate_col] = (tract_stats[col] / tract_stats[pop_col]) * rate_per

print(f"\nCrime rate statistics (per {rate_per:,}):")
print(tract_stats['crime_rate'].describe())
```

### 6. Flag Unreliable Tracts

**6.1 Identify Low-Population Tracts**
```python
# Flag tracts below minimum population threshold
tract_stats['low_population'] = tract_stats[pop_col] < min_pop
tract_stats['zero_population'] = tract_stats[pop_col] == 0

# Calculate reliability flag
tract_stats['rate_reliable'] = ~tract_stats['low_population']

unreliable_count = tract_stats['low_population'].sum()
print(f"\nTracts flagged as unreliable (pop < {min_pop}): {unreliable_count}")

# Handle infinite rates from zero population
tract_stats.loc[tract_stats['zero_population'], 'crime_rate'] = np.nan
for col in [c for c in tract_stats.columns if c.endswith('_rate')]:
    tract_stats.loc[tract_stats['zero_population'], col] = np.nan
```

**6.2 Document Flagged Tracts**
```python
flagged_tracts = tract_stats[tract_stats['low_population']][['GEOID', pop_col, 'total_crimes']]
print("\nFlagged tracts (unreliable rates):")
print(flagged_tracts.to_string(index=False))
```

### 7. Choropleth Map

**7.1 Merge Rates to Boundaries**
```python
tracts_with_rates = tracts_gdf.merge(tract_stats, on='GEOID', how='left')
```

**7.2 Create Rate Choropleth**
```python
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import numpy as np

fig, ax = plt.subplots(figsize=(14, 12))

# Filter to reliable tracts for color scaling
reliable_rates = tracts_with_rates[tracts_with_rates['rate_reliable'] == True]['crime_rate']
vmin, vmax = reliable_rates.quantile(0.05), reliable_rates.quantile(0.95)

# Yellow-Orange-Red colormap
colors = ['#FFFFE0', '#FFEDA0', '#FED976', '#FEB24C', '#FD8D3C', '#FC4E2A', '#E31A1C', '#B10026']
cmap = LinearSegmentedColormap.from_list('YlOrRd', colors)

# Plot reliable tracts
tracts_with_rates[tracts_with_rates['rate_reliable'] == True].plot(
    column='crime_rate', cmap=cmap, linewidth=0.3, 
    edgecolor='gray', legend=True, ax=ax,
    vmin=vmin, vmax=vmax,
    legend_kwds={'label': f'Crime Rate (per {rate_per:,})', 'orientation': 'horizontal'}
)

# Plot unreliable tracts in gray
tracts_with_rates[tracts_with_rates['rate_reliable'] == False].plot(
    color='lightgray', linewidth=0.3, edgecolor='gray', ax=ax
)

ax.set_title('Philadelphia Crime Rates by Census Tract\n(Gray = low population, rates unreliable)', fontsize=14)
ax.set_axis_off()

plt.tight_layout()
plt.savefig(REPORTS_DIR / 'tract_crime_rates.png', dpi=300, bbox_inches='tight')
artifacts.append(('tract_crime_rates.png', 'Census tract crime rate choropleth'))
plt.show()
```

### 8. Summary Statistics

**8.1 Top/Bottom Tracts**
```python
# Filter to reliable tracts only
reliable_tracts = tract_stats[tract_stats['rate_reliable'] == True].copy()

print("\nTop 10 Tracts by Crime Rate:")
top_10 = reliable_tracts.nlargest(10, 'crime_rate')[['GEOID', pop_col, 'total_crimes', 'crime_rate']]
print(top_10.to_string(index=False))

print("\nBottom 10 Tracts by Crime Rate:")
bottom_10 = reliable_tracts.nsmallest(10, 'crime_rate')[['GEOID', pop_col, 'total_crimes', 'crime_rate']]
print(bottom_10.to_string(index=False))
```

**8.2 Distribution Summary**
```python
# Rate distribution for reliable tracts
rate_stats = {
    'Total tracts': len(tracts_gdf),
    'Tracts with crimes': len(tract_stats),
    'Reliable tracts': reliable_tracts['rate_reliable'].sum(),
    'Flagged tracts': unreliable_count,
    'Mean rate': reliable_tracts['crime_rate'].mean(),
    'Median rate': reliable_tracts['crime_rate'].median(),
    'Std rate': reliable_tracts['crime_rate'].std(),
    'Min rate': reliable_tracts['crime_rate'].min(),
    'Max rate': reliable_tracts['crime_rate'].max()
}

print("\nRate Distribution Summary:")
for k, v in rate_stats.items():
    if isinstance(v, float):
        print(f"  {k}: {v:,.1f}")
    else:
        print(f"  {k}: {v:,}")
```

### 9. Export Results

**9.1 Save Tract Statistics**
```python
# Export full results
output_cols = ['GEOID', pop_col, 'total_crimes', 'crime_rate', 
               'violent_crimes', 'violent_rate', 'property_crimes', 'property_rate',
               'low_population', 'rate_reliable']
               
# Filter to columns that exist
output_cols = [c for c in output_cols if c in tract_stats.columns]
tract_export = tract_stats[output_cols].copy()

tract_export.to_csv(REPORTS_DIR / 'tract_crime_rates.csv', index=False)
artifacts.append(('tract_crime_rates.csv', 'Tract crime rates and counts'))

# Save as parquet for downstream analysis
tract_export.to_parquet(repo_root / 'data' / 'processed' / 'tract_crime_rates.parquet')
```

**9.2 Save GeoJSON for Mapping**
```python
# Export as GeoJSON for interactive mapping
tracts_with_rates.to_file(REPORTS_DIR / 'tracts_with_rates.geojson', driver='GeoJSON')
artifacts.append(('tracts_with_rates.geojson', 'GeoJSON with crime rates'))
```

**9.3 Save Flagged Tracts Report**
```python
flagged_report = f"""# Flagged Census Tracts Report

## Summary

- Total census tracts: {len(tracts_gdf)}
- Tracts with reliable population (>= {min_pop}): {len(reliable_tracts)}
- Tracts flagged as unreliable: {unreliable_count}

## Flagged Tracts (population < {min_pop})

| GEOID | Population | Total Crimes | Note |
|-------|------------|--------------|------|
"""

for _, row in flagged_tracts.iterrows():
    note = "Zero pop" if row[pop_col] == 0 else f"Pop: {row[pop_col]}"
    flagged_report += f"| {row['GEOID']} | {row[pop_col]} | {row['total_crimes']} | {note} |\n"

flagged_report += f"""
## Recommendation

Exclude flagged tracts from rate-based analyses. Use raw counts instead for these tracts.
"""

with open(REPORTS_DIR / 'flagged_tracts_report.md', 'w') as f:
    f.write(flagged_report)
    
artifacts.append(('flagged_tracts_report.md', 'Unreliable tract documentation'))
```

### 10. Notebook Completion

**10.1 Artifact Summary Cell**
```python
print("\n" + "="*60)
print("NOTEBOOK COMPLETE: Census Tract Crime Rates (HYP-SOCIO)")
print("="*60)
print(f"\nArtifacts generated:")
for name, desc in artifacts:
    print(f"  - {name}: {desc}")
print(f"\nRuntime: {time.time() - RUNTIME_START:.1f} seconds")
```

**10.2 Markdown Conclusion Cell**
Document methodology, rate distribution findings, flagged tracts, and recommendations for socioeconomic analysis.

## Validation Criteria

- [ ] Notebook executes end-to-end without errors
- [ ] Reproducibility cell present with version info
- [ ] `reports/tract_crime_rates.png` exists at 300 DPI
- [ ] Choropleth shows reliable tracts in color, unreliable in gray
- [ ] `reports/tract_crime_rates.csv` contains GEOID, population, counts, and rates
- [ ] `data/processed/tract_crime_rates.parquet` exists for downstream use
- [ ] `reports/flagged_tracts_report.md` documents unreliable tracts
- [ ] Rate per 100,000 used (matching FBI UCR convention)
- [ ] Spatial join success rate > 95%

## Dependencies

- geopandas (for spatial join and choropleth)
- shapely (for geometry creation)
- 02-01 infrastructure: census_tracts_pop.geojson, spatial_utils.py, phase2_config_loader.py

## Estimated Time

- Notebook structure: 10 min
- Spatial join: 20 min
- Rate calculation: 15 min
- Flagging logic: 10 min
- Choropleth: 15 min
- Export and documentation: 15 min
- Testing & validation: 10 min
- **Total: ~95 min**

---
*Plan created: 2026-02-03*
