---
phase: 10-test-infrastructure-&-baseline
plan: 03
type: execute
wave: 2
depends_on: ["10-01"]
files_modified:
  - .planning/phases/10-test-infrastructure-&-baseline/coverage-baseline.txt
  - .planning/phases/10-test-infrastructure-&-baseline/uncovered-modules.txt
autonomous: true

must_haves:
  truths:
    - "Current coverage baseline is measured accurately with per-module breakdown"
    - "Uncovered and under-covered modules are documented with coverage percentages"
    - "Baseline documentation identifies 56 modules requiring tests"
    - "Coverage baseline snapshot saved for future comparison"
  artifacts:
    - path: ".planning/phases/10-test-infrastructure-&-baseline/coverage-baseline.txt"
      provides: "Full coverage report with per-module breakdown"
      contains: "coverage report output with module percentages"
    - path: ".planning/phases/10-test-infrastructure-&-baseline/uncovered-modules.txt"
      provides: "List of modules requiring tests sorted by priority"
      contains: "Module names with coverage < 80%"
  key_links:
    - from: "pytest --cov"
      to: "coverage baseline"
      via: "coverage report generation"
      pattern: "pytest.*--cov.*--cov-report"
---

<objective>
Measure and document the current coverage baseline with per-module breakdown. This establishes the starting point for tracking progress toward 95% coverage and identifies which modules need tests most urgently.

Purpose: Get accurate baseline measurement (verifying the 16% vs 60% discrepancy) and create prioritized list of modules needing tests.
Output: Coverage baseline report and uncovered modules list for test writing prioritization.
</objective>

<execution_context>
@/Users/dustinober/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dustinober/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/REQUIREMENTS.md
@.planning/milestones/v1.3-ROADMAP.md
@.planning/phases/10-test-infrastructure-&-baseline/10-RESEARCH.md
@/Users/dustinober/Projects/Crime Incidents Philadelphia/pyproject.toml
@/Users/dustinober/Projects/Crime Incidents Philadelphia/tests/conftest.py
</context>

<tasks>

<task type="auto">
  <name>Run fresh coverage baseline measurement</name>
  <files>.planning/phases/10-test-infrastructure-&-baseline/coverage-baseline.txt</files>
  <action>
    Run pytest with full coverage configuration to measure accurate baseline.

    Execute:
    ```bash
    pytest --cov=analysis --cov=api --cov=pipeline \
      --cov-report=term-missing \
      --cov-report=xml \
      --cov-report=html \
      --cov-report=json:.planning/phases/10-test-infrastructure-&-baseline/coverage-baseline.json \
      -v 2>&1 | tee .planning/phases/10-test-infrastructure-&-baseline/coverage-baseline.txt
    ```

    Then generate detailed per-module report:
    ```bash
    coverage report --sort=cover > .planning/phases/10-test-infrastructure-&-baseline/coverage-modules.txt
    ```

    This will:
    - Run all tests with coverage tracking
    - Generate terminal output showing missing lines per file
    - Create XML report for diff-cover
    - Create HTML report for visual review
    - Create JSON baseline for programmatic comparison
    - Sort modules by coverage percentage (highest to lowest)

    Note: The exit code will be 2 (fail) since coverage is below 95%. This is expected and acceptable for baseline measurement.
  </action>
  <verify>test -f .planning/phases/10-test-infrastructure-&-baseline/coverage-baseline.txt && test -f .planning/phases/10-test-infrastructure-&-baseline/coverage-modules.txt</verify>
  <done>Coverage baseline files exist with full coverage report and per-module breakdown</done>
</task>

<task type="auto">
  <name>Document uncovered and under-covered modules</name>
  <files>.planning/phases/10-test-infrastructure-&-baseline/uncovered-modules.txt</files>
  <action>
    Parse coverage report to identify modules requiring tests and create prioritized list.

    Create uncovered-modules.txt with:
    1. Header with date and baseline summary
    2. Categories by coverage tier (0%, 1-50%, 51-80%, 81-95%)
    3. Count of modules in each tier
    4. Full list of modules under 95% with their coverage percentage

    Format:
    ```
    Coverage Baseline - [DATE]
    ==============================

    Overall Coverage: X%
    Total Statements: N
    Covered Statements: M
    Missed Statements: K

    Coverage Distribution:
    - 0% coverage (N modules): module1, module2, ...
    - 1-50% coverage (N modules): module3 (X%), module4 (Y%), ...
    - 51-80% coverage (N modules): ...
    - 81-95% coverage (N modules): ...
    - 95%+ coverage (N modules): ... (already达标)

    Priority List (modules needing tests, sorted by coverage ascending):
    1. analysis/module_name.py - 0% - [statement count]
    2. api/another_module.py - 15.5% - [statement count]
    ...

    Total modules requiring tests: N
    ```

    Use the coverage-modules.txt file as source data.
  </action>
  <verify>test -f .planning/phases/10-test-infrastructure-&-baseline/uncovered-modules.txt && grep -E "Coverage Baseline|Total modules requiring" .planning/phases/10-test-infrastructure-&-baseline/uncovered-modules.txt</verify>
  <done>uncovered-modules.txt contains categorized list with total count of modules needing tests</done>
</task>

<task type="auto">
  <name>Create coverage baseline snapshot for comparison</name>
  <files>.planning/phases/10-test-infrastructure-&-baseline/.coverage.baseline</files>
  <action>
    Save coverage data snapshot for future progress comparison.

    Copy coverage data files to baseline location:
    ```bash
    cp .coverage .planning/phases/10-test-infrastructure-&-baseline/.coverage.baseline
    cp coverage.xml .planning/phases/10-test-infrastructure-&-baseline/coverage.baseline.xml 2>/dev/null || true
    ```

    These baseline files allow future comparison:
    - Compare .coverage files to see which lines were added
    - Compare coverage.xml to track percentage improvements
    - Use diff-cover against baseline to measure progress

    Also create a summary file with key metrics:
    ```bash
    cat > .planning/phases/10-test-infrastructure-&-baseline/BASELINE_SUMMARY.md << 'EOF'
    # Phase 10 Coverage Baseline

    **Measured:** [DATE from coverage run]

    ## Overall Metrics

    - Total Coverage: [X]%
    - Total Statements: [N]
    - Covered Statements: [M]
    - Missed Statements: [K]
    - Coverage Gap to Target: [95 - X]%

    ## Per-Module Breakdown

    ### Analysis Modules
    - analysis/data/loading.py: X%
    - analysis/data/preprocessing.py: X%
    ... (full list)

    ### API Modules
    - api/main.py: X%
    - api/routers/trends.py: X%
    ... (full list)

    ### Pipeline Modules
    - pipeline/export_data.py: X%
    - pipeline/refresh_data.py: X%
    ... (full list)

    ## Testing Priorities

    1. **Tier 1 (0% coverage)**: [N] modules requiring initial tests
    2. **Tier 2 (1-50% coverage)**: [N] modules needing expansion
    3. **Tier 3 (51-80% coverage)**: [N] modules near completion

    Total modules requiring tests: [N]
    EOF
    ```

    Fill in the summary with actual data from coverage report.
  </action>
  <verify>test -f .planning/phases/10-test-infrastructure-&-baseline/.coverage.baseline && test -f .planning/phases/10-test-infrastructure-&-baseline/BASELINE_SUMMARY.md</verify>
  <done>Baseline snapshot files exist for future comparison</done>
</task>

</tasks>

<verification>
After completing all tasks:

1. Verify coverage-baseline.txt exists with full pytest coverage output
2. Verify coverage-modules.txt exists with per-module breakdown sorted by coverage
3. Verify uncovered-modules.txt has categorized tiers and priority list
4. Verify .coverage.baseline snapshot exists
5. Verify BASELINE_SUMMARY.md documents key metrics and module breakdown
</verification>

<success_criteria>
1. Accurate baseline coverage measured (resolving 16% vs 60% discrepancy)
2. Per-module coverage breakdown documented
3. Uncovered modules categorized by coverage tier (0%, 1-50%, 51-80%, 81-95%)
4. Priority list created for test writing
5. Baseline snapshot saved for future progress tracking
</success_criteria>

<output>
After completion, create `.planning/phases/10-test-infrastructure-&-baseline/10-03-SUMMARY.md`
</output>
