---
phase: 01-data-exploration
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/analysis/profiler.py
  - src/analysis/__init__.py
autonomous: true
must_haves:
  truths:
    - "Profiler can identify missing values"
    - "Profiler can identify duplicates"
    - "Profiler can detect numerical outliers"
    - "Profiler can calculate numerical correlations"
  artifacts:
    - path: "src/analysis/profiler.py"
      provides: "DataProfiler class"
      exports: ["DataProfiler"]
  key_links:
    - from: "src/analysis/profiler.py"
      to: "pandas.DataFrame"
      via: "Type hinting and method calls"
---

<objective>
Implement the core data profiling logic.

Purpose: Encapsulate the "business logic" of data exploration (quality checks, type inspection, outlier detection) into a reusable class.
Output: A DataProfiler class with methods for each analysis requirement.
</objective>

<execution_context>
@~/.config/opencode/get-shit-done/workflows/execute-plan.md
@~/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@requirements.txt
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create DataProfiler Class Structure</name>
  <files>src/analysis/profiler.py, src/analysis/__init__.py</files>
  <action>
    Create `src/analysis/profiler.py` with a `DataProfiler` class.
    - Constructor accepts `df: pd.DataFrame`.
    - Implement `get_summary()`: returns shape, columns, memory usage, and basic numerical stats (min, max, mean) for numeric columns.
    - Implement `check_types()`: returns dtypes series.
  </action>
  <verify>python -c "import pandas as pd; from src.analysis.profiler import DataProfiler; df = pd.DataFrame({'a': [1,2]}); p = DataProfiler(df); print(p.get_summary())"</verify>
  <done>Class exists and basic summary method works</done>
</task>

<task type="auto">
  <name>Task 2: Implement Quality Checks</name>
  <files>src/analysis/profiler.py</files>
  <action>
    Add quality assessment methods to `DataProfiler`.
    - `check_missing_values()`: returns count/percentage of nulls per column.
    - `check_duplicates()`: returns count of duplicate rows.
  </action>
  <verify>python -c "import pandas as pd; import numpy as np; from src.analysis.profiler import DataProfiler; df = pd.DataFrame({'a': [1, np.nan, 1]}); p = DataProfiler(df); print(p.check_missing_values()); print(p.check_duplicates())"</verify>
  <done>Correctly identifies missing values and duplicates</done>
</task>

<task type="auto">
  <name>Task 3: Implement Outlier and Relationship Checks</name>
  <files>src/analysis/profiler.py</files>
  <action>
    Add advanced checks.
    - `check_outliers(threshold=1.5)`: For numerical columns, calculate IQR and count outliers. Return summary dataframe.
    - `check_categorical_breakdown(top_n=5)`: For object/category columns, return value counts for top N items.
    - `check_correlations()`: Calculate correlation matrix for numerical columns to identify relationships.
  </action>
  <verify>python -c "import pandas as pd; from src.analysis.profiler import DataProfiler; df = pd.DataFrame({'num': [1, 2, 3, 100], 'cat': ['a', 'a', 'b', 'c']}); p = DataProfiler(df); print(p.check_outliers()); print(p.check_categorical_breakdown()); print(p.check_correlations())"</verify>
  <done>Outliers (100) detected, categorical counts returned, correlation matrix printed</done>
</task>

</tasks>

<verification>
Run unit tests via python -c commands to verify logic on dummy data.
</verification>

<success_criteria>
- DataProfiler class implements all required checks (DATA-02, DATA-03, DATA-04, DATA-05)
- Methods return structured data (Series/DataFrame/Dict) rather than just printing, allowing flexible usage
</success_criteria>

<output>
After completion, create `.planning/phases/01-data-exploration/01-02-SUMMARY.md`
</output>
