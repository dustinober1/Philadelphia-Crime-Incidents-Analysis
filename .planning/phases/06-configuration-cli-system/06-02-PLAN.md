---
phase: 06-configuration-cli-system
plan: 02
type: execute
wave: 1
depends_on: ["06-01"]
files_modified:
  - analysis/config/__init__.py
  - analysis/config/settings.py
  - analysis/config/schemas/__init__.py
  - analysis/config/schemas/chief.py
  - analysis/config/schemas/patrol.py
  - analysis/config/schemas/policy.py
  - analysis/config/schemas/forecasting.py
  - config/global.yaml
  - config/chief.yaml
  - config/patrol.yaml
  - config/policy.yaml
  - config/forecasting.yaml
autonomous: true

must_haves:
  truths:
    - "Developer can import BaseSettings from analysis.config.settings"
    - "Developer can create a config instance from YAML with TrendsConfig()"
    - "YAML files exist in config/ directory (global.yaml, chief.yaml, patrol.yaml, policy.yaml, forecasting.yaml)"
    - "Pydantic validation works for all config schemas"
  artifacts:
    - path: "analysis/config/settings.py"
      provides: "Base configuration class with pydantic-settings"
      exports: ["BaseConfig", "GlobalConfig"]
    - path: "analysis/config/schemas/chief.py"
      provides: "Chief analysis schemas (TrendsConfig, SeasonalityConfig, COVIDConfig)"
      exports: ["TrendsConfig", "SeasonalityConfig", "COVIDConfig"]
    - path: "config/global.yaml"
      provides: "Global shared configuration (paths, output settings)"
      contains: "output_dir"
  key_links:
    - from: "analysis/config/schemas/chief.py"
      to: "config/chief.yaml"
      via: "YamlConfigSettingsSource"
      pattern: "yaml_file.*chief"
    - from: "analysis/config/settings.py"
      to: "pydantic-settings"
      via: "BaseSettings inheritance"
      pattern: "class.*BaseSettings"
---

<objective>
Create configuration system with pydantic-settings schemas for all 13 analyses and corresponding YAML configuration files.

Purpose: Establish a type-safe configuration system that loads defaults from YAML files, supports environment variable overrides, and provides validation. This creates the foundation for CLI argument integration in later plans.

Output: Pydantic settings classes for all analysis schemas, 5 YAML config files (global + 4 phase configs), working config loading with validation.
</objective>

<execution_context>
@/Users/dustinober/.claude/get-shit-done/workflows/execute-plan.md
@/Users/dustinober/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/06-configuration-cli-system/06-RESEARCH.md
@.planning/phases/06-configuration-cli-system/06-01-SUMMARY.md
@.planning/REQUIREMENTS.md

# Existing config structure
@analysis/config.py
@config/phase1_config.yaml
@config/phase2_config.yaml
@config/phase3_config.yaml

# Phase 5 summary for data layer patterns
@.planning/phases/05-foundation-architecture/05-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create analysis/config package structure</name>
  <files>
    - analysis/config/__init__.py
    - analysis/config/settings.py
    - analysis/config/schemas/__init__.py
  </files>
  <action>
    Create the configuration package structure:

    1. Create `analysis/config/__init__.py` with package exports:
       ```python
       """Configuration system for crime analysis CLI.

       Uses pydantic-settings for multi-source configuration:
       - YAML files (defaults)
       - Environment variables (overrides)
       - CLI arguments (highest priority)
       """

       from analysis.config.settings import BaseConfig, GlobalConfig
       from analysis.config.schemas.chief import TrendsConfig, SeasonalityConfig, COVIDConfig
       from analysis.config.schemas.patrol import HotspotsConfig, RobberyConfig, DistrictConfig, CensusConfig
       from analysis.config.schemas.policy import RetailTheftConfig, VehicleCrimesConfig, CompositionConfig, EventsConfig
       from analysis.config.schemas.forecasting import TimeSeriesConfig, ClassificationConfig

       __all__ = [
           "BaseConfig",
           "GlobalConfig",
           "TrendsConfig",
           "SeasonalityConfig",
           "COVIDConfig",
           "HotspotsConfig",
           "RobberyConfig",
           "DistrictConfig",
           "CensusConfig",
           "RetailTheftConfig",
           "VehicleCrimesConfig",
           "CompositionConfig",
           "EventsConfig",
           "TimeSeriesConfig",
           "ClassificationConfig",
       ]
       ```

    2. Create `analysis/config/settings.py` with base configuration classes:
       ```python
       """Base configuration settings using pydantic-settings."""

       from pathlib import Path
       from typing import Tuple
       from pydantic import Field
       from pydantic_settings import BaseSettings, SettingsConfigDict, PydanticBaseSettingsSource, YamlConfigSettingsSource

       # Resolve repo root
       _REPO_ROOT = Path(__file__).resolve().parent.parent.parent


       class GlobalConfig(BaseSettings):
           """Global shared configuration for all analyses."""

           model_config = SettingsConfigDict(
               yaml_file="config/global.yaml",
               env_prefix="CRIME_",
               env_nested_delimiter="__",
           )

           # Data paths
           crime_data_path: Path = Field(default=_REPO_ROOT / "data" / "crime_incidents_combined.parquet")
           boundaries_dir: Path = Field(default=_REPO_ROOT / "data" / "boundaries")
           external_dir: Path = Field(default=_REPO_ROOT / "data" / "external")

           # Output settings
           output_dir: Path = Field(default=_REPO_ROOT / "reports")
           dpi: int = Field(default=300, ge=72, le=600)
           output_format: str = Field(default="png", pattern="^(png|svg|html|json)$")

           # Performance
           fast_sample_frac: float = Field(default=0.1, ge=0.01, le=1.0)
           cache_enabled: bool = True

           # Logging
           log_level: str = Field(default="INFO", pattern="^(DEBUG|INFO|WARNING|ERROR)$")

           @classmethod
           def settings_customise_sources(
               cls,
               settings_cls: type[BaseSettings],
               init_settings: PydanticBaseSettingsSource,
               env_settings: PydanticBaseSettingsSource,
               dotenv_settings: PydanticBaseSettingsSource,
               file_secret_settings: PydanticBaseSettingsSource,
           ) -> Tuple[PydanticBaseSettingsSource, ...]:
               """Configure source priority: CLI > env > YAML > defaults."""
               return (
                   init_settings,  # CLI arguments (highest priority)
                   env_settings,   # Environment variables
                   YamlConfigSettingsSource(settings_cls),  # YAML files
                   dotenv_settings,  # .env files (lowest priority)
               )


       class BaseConfig(BaseSettings):
           """Base class for all analysis-specific configs."""

           model_config = SettingsConfigDict(
               env_prefix="CRIME_",
               env_nested_delimiter="__",
           )

           # Global settings (inherited from GlobalConfig)
           output_dir: Path
           dpi: int
           output_format: str
           fast_sample_frac: float
           cache_enabled: bool
           log_level: str

           # Analysis version
           version: str = "v1.0"

           @classmethod
           def settings_customise_sources(
               cls,
               settings_cls: type[BaseSettings],
               init_settings: PydanticBaseSettingsSource,
               env_settings: PydanticBaseSettingsSource,
               dotenv_settings: PydanticBaseSettingsSource,
               file_secret_settings: PydanticBaseSettingsSource,
           ) -> Tuple[PydanticBaseSettingsSource, ...]:
               """Configure source priority: CLI > env > YAML > defaults."""
               return (
                   init_settings,
                   env_settings,
                   YamlConfigSettingsSource(settings_cls),
                   dotenv_settings,
               )
       ```

    3. Create `analysis/config/schemas/__init__.py` to export all schema modules:
       ```python
       """Pydantic schema definitions for each analysis."""

       from analysis.config.schemas.chief import (
           TrendsConfig,
           SeasonalityConfig,
           COVIDConfig,
       )
       from analysis.config.schemas.patrol import (
           HotspotsConfig,
           RobberyConfig,
           DistrictConfig,
           CensusConfig,
       )
       from analysis.config.schemas.policy import (
           RetailTheftConfig,
           VehicleCrimesConfig,
           CompositionConfig,
           EventsConfig,
       )
       from analysis.config.schemas.forecasting import (
           TimeSeriesConfig,
           ClassificationConfig,
       )

       __all__ = [
           "TrendsConfig",
           "SeasonalityConfig",
           "COVIDConfig",
           "HotspotsConfig",
           "RobberyConfig",
           "DistrictConfig",
           "CensusConfig",
           "RetailTheftConfig",
           "VehicleCrimesConfig",
           "CompositionConfig",
           "EventsConfig",
           "TimeSeriesConfig",
           "ClassificationConfig",
       ]
       ```
  </action>
  <verify>
    - `python -c "from analysis.config import BaseConfig, GlobalConfig"` succeeds
    - `python -c "from analysis.config.settings import GlobalConfig; g = GlobalConfig(); print(g.output_dir)"` prints path
  </verify>
  <done>
    Base configuration classes exist and can be imported. GlobalConfig can be instantiated and provides default values.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create Chief analysis schemas</name>
  <files>analysis/config/schemas/chief.py</files>
  <action>
    Create `analysis/config/schemas/chief.py` with three configuration classes matching the Chief analyses (trends, seasonality, COVID):

    ```python
    """Configuration schemas for Chief-level analyses."""

    from pathlib import Path
    from pydantic import Field
    from analysis.config.settings import BaseConfig

    # Import global config for shared values
    from analysis.config.settings import GlobalConfig


    class TrendsConfig(BaseConfig):
        """Configuration for annual crime trends analysis."""

        model_config = {"yaml_file": "config/chief.yaml"}

        # Analysis parameters
        start_year: int = Field(default=2015, ge=2006, le=2026)
        end_year: int = Field(default=2024, ge=2006, le=2026)
        min_complete_months: int = Field(default=12, ge=1, le=12)

        # Output
        report_name: str = "annual_trends_report"


    class SeasonalityConfig(BaseConfig):
        """Configuration for seasonal crime patterns analysis."""

        model_config = {"yaml_file": "config/chief.yaml"}

        # Season definitions
        summer_months: list[int] = Field(default=[6, 7, 8])
        winter_months: list[int] = Field(default=[12, 1, 2])

        # Statistical parameters
        significance_level: float = Field(default=0.05, ge=0.01, le=0.1)

        # Output
        report_name: str = "seasonality_report"


    class COVIDConfig(BaseConfig):
        """Configuration for COVID impact analysis."""

        model_config = {"yaml_file": "config/chief.yaml"}

        # COVID period definition
        lockdown_date: str = Field(default="2020-03-01")
        before_years: list[int] = Field(default=[2018, 2019])
        after_years: list[int] = Field(default=[2021, 2022])

        # Output
        report_name: str = "covid_impact_report"
    ```

    Reference existing phase1_config.yaml for parameter values. Ensure field types match typer CLI argument types (int, str, bool, list).
  </action>
  <verify>
    `python -c "from analysis.config.schemas.chief import TrendsConfig, SeasonalityConfig, COVIDConfig; t = TrendsConfig(); print(t.start_year)"` prints 2015 (or default value)
  </verify>
  <done>
    All three Chief config classes exist, can be imported, and instantiate with correct default values.
  </done>
</task>

<task type="auto">
  <name>Task 3: Create Patrol analysis schemas</name>
  <files>analysis/config/schemas/patrol.py</files>
  <action>
    Create `analysis/config/schemas/patrol.py` with four configuration classes for Patrol analyses (hotspots, robbery heatmap, district severity, census rates):

    ```python
    """Configuration schemas for Patrol operations analyses."""

    from pathlib import Path
    from pydantic import Field
    from analysis.config.settings import BaseConfig


    class HotspotsConfig(BaseConfig):
        """Configuration for crime hotspot clustering analysis."""

        model_config = {"yaml_file": "config/patrol.yaml"}

        # Clustering parameters
        eps_degrees: float = Field(default=0.002, ge=0.0001, le=0.01)
        min_samples: int = Field(default=50, ge=10, le=500)
        algorithm: str = Field(default="DBSCAN")

        # Spatial filtering
        lon_min: float = -75.30
        lon_max: float = -74.95
        lat_min: float = 39.85
        lat_max: float = 40.15

        # Output
        report_name: str = "hotspots_report"


    class RobberyConfig(BaseConfig):
        """Configuration for robbery temporal hotspot analysis."""

        model_config = {"yaml_file": "config/patrol.yaml"}

        # Time binning
        time_bin_size: int = Field(default=60, ge=15, le=240)  # minutes

        # Heatmap settings
        grid_size: int = Field(default=20, ge=10, le=50)

        # Output
        report_name: str = "robbery_heatmap_report"


    class DistrictConfig(BaseConfig):
        """Configuration for district severity scoring analysis."""

        model_config = {"yaml_file": "config/patrol.yaml"}

        # Severity weights (optional override of defaults)
        enable_custom_weights: bool = False
        # If enable_custom_weights is True, load from YAML

        # District filtering
        districts: list[int] | None = Field(default=None)  # None = all districts

        # Output
        report_name: str = "district_severity_report"


    class CensusConfig(BaseConfig):
        """Configuration for census tract crime rate analysis."""

        model_config = {"yaml_file": "config/patrol.yaml"}

        # Census data source
        census_file: str = "census_tracts.geojson"

        # Rate normalization
        population_threshold: int = Field(default=100, ge=0)  # Minimum population

        # Output
        report_name: str = "census_rates_report"
    ```

    Reference existing phase2_config.yaml for parameter values.
  </action>
  <verify>
    `python -c "from analysis.config.schemas.patrol import HotspotsConfig, RobberyConfig, DistrictConfig, CensusConfig"` succeeds without ImportError
  </verify>
  <done>
    All four Patrol config classes exist and can be imported.
  </done>
</task>

<task type="auto">
  <name>Task 4: Create Policy and Forecasting schemas</name>
  <files>
    - analysis/config/schemas/policy.py
    - analysis/config/schemas/forecasting.py
  </files>
  <action>
    Create two schema files:

    1. `analysis/config/schemas/policy.py`:
       ```python
       """Configuration schemas for Policy evaluation analyses."""

       from pathlib import Path
       from pydantic import Field
       from analysis.config.settings import BaseConfig


       class RetailTheftConfig(BaseConfig):
           """Configuration for retail theft trend analysis."""

           model_config = {"yaml_file": "config/policy.yaml"}

           # Focus stores (optional)
           focus_stores: list[str] | None = Field(default=None)

           # Comparison period
           baseline_start: str = "2019-01-01"
           baseline_end: str = "2020-02-01"

           # Output
           report_name: str = "retail_theft_report"


       class VehicleCrimesConfig(BaseConfig):
           """Configuration for vehicle crimes analysis."""

           model_config = {"yaml_file": "config/policy.yaml"}

           # UCR codes for vehicle crimes
           ucr_codes: list[int] = Field(default=[700])

           # Date range
           start_date: str = "2019-01-01"
           end_date: str = "2023-12-31"

           # Output
           report_name: str = "vehicle_crimes_report"


       class CompositionConfig(BaseConfig):
           """Configuration for crime composition analysis."""

           model_config = {"yaml_file": "config/policy.yaml"}

           # Grouping parameters
           group_by_ucr_hundred: bool = True

           # Output top N categories
           top_n: int = Field(default=10, ge=5, le=20)

           # Output
           report_name: str = "composition_report"


       class EventsConfig(BaseConfig):
           """Configuration for event impact analysis."""

           model_config = {"yaml_file": "config/policy.yaml"}

           # Event window
           days_before: int = Field(default=7, ge=1, le=30)
           days_after: int = Field(default=7, ge=1, le=30)

           # Event types (from existing event_utils.py)
           event_types: list[str] = Field(default=["Eagles_Home", "Phillies_Home", "Sixers_Home", "Flyers_Home"])

           # Output
           report_name: str = "events_impact_report"
       ```

    2. `analysis/config/schemas/forecasting.py`:
       ```python
       """Configuration schemas for Forecasting analyses."""

       from pathlib import Path
       from pydantic import Field
       from analysis.config.settings import BaseConfig


       class TimeSeriesConfig(BaseConfig):
           """Configuration for time series forecasting analysis."""

           model_config = {"yaml_file": "config/forecasting.yaml"}

           # Forecasting parameters
           forecast_horizon: int = Field(default=12, ge=1, le=52)  # weeks/months
           test_size: float = Field(default=0.2, ge=0.1, le=0.5)

           # Model selection
           model_type: str = Field(default="prophet", pattern="^(prophet|arima|ets)$")

           # Output
           report_name: str = "forecast_report"


       class ClassificationConfig(BaseConfig):
           """Configuration for violence classification analysis."""

           model_config = {"yaml_file": "config/forecasting.yaml"}

           # Target definition
           violent_ucr_codes: list[int] = Field(default=[100, 200, 300, 400])

           # Model parameters
           test_size: float = Field(default=0.25, ge=0.1, le=0.5)
           random_state: int = 42

           # Feature importance threshold
       importance_threshold: float = Field(default=0.01, ge=0.001, le=0.1)

           # Output
           report_name: str = "classification_report"
       ```

    Reference existing phase3_config.yaml and phase4 (forecasting) notebooks for parameter values.
  </action>
  <verify>
    `python -c "from analysis.config.schemas.policy import RetailTheftConfig, VehicleCrimesConfig, CompositionConfig, EventsConfig; from analysis.config.schemas.forecasting import TimeSeriesConfig, ClassificationConfig"` succeeds
  </verify>
  <done>
    All Policy and Forecasting config classes exist and can be imported. Total of 13 config classes for 13 analyses.
  </done>
</task>

<task type="auto">
  <name>Task 5: Create YAML configuration files</name>
  <files>
    - config/global.yaml
    - config/chief.yaml
    - config/patrol.yaml
    - config/policy.yaml
    - config/forecasting.yaml
  </files>
  <action>
    Create 5 YAML configuration files in the config/ directory:

    1. `config/global.yaml`:
       ```yaml
       # Global shared configuration for all crime analyses
       # These values can be overridden by environment variables (CRIME_* prefix)
       # or CLI arguments (highest priority)

       # Data paths (relative to project root)
       crime_data_path: data/crime_incidents_combined.parquet
       boundaries_dir: data/boundaries
       external_dir: data/external

       # Output settings
       output_dir: reports
       dpi: 300
       output_format: png

       # Performance options
       fast_sample_frac: 0.1
       cache_enabled: true

       # Logging
       log_level: INFO
       ```

    2. `config/chief.yaml`:
       ```yaml
       # Chief-level trend analysis configurations

       # Annual trends analysis
       start_year: 2015
       end_year: 2024
       min_complete_months: 12
       version: v1.0

       # Seasonality analysis
       summer_months: [6, 7, 8]
       winter_months: [12, 1, 2]
       significance_level: 0.05

       # COVID impact analysis
       lockdown_date: "2020-03-01"
       before_years: [2018, 2019]
       after_years: [2021, 2022]
       ```

    3. `config/patrol.yaml`:
       ```yaml
       # Patrol operations analysis configurations

       # Hotspot clustering
       eps_degrees: 0.002
       min_samples: 50
       algorithm: DBSCAN

       # Spatial bounds for Philadelphia
       lon_min: -75.30
       lon_max: -74.95
       lat_min: 39.85
       lat_max: 40.15

       # Robbery heatmap
       time_bin_size: 60  # minutes
       grid_size: 20

       # District severity
       enable_custom_weights: false
       districts: null  # null = all districts

       # Census tract rates
       census_file: census_tracts.geojson
       population_threshold: 100
       ```

    4. `config/policy.yaml`:
       ```yaml
       # Policy evaluation analysis configurations

       # Retail theft trend
       focus_stores: null
       baseline_start: "2019-01-01"
       baseline_end: "2020-02-01"

       # Vehicle crimes
       ucr_codes: [700]
       start_date: "2019-01-01"
       end_date: "2023-12-31"

       # Crime composition
       group_by_ucr_hundred: true
       top_n: 10

       # Event impact
       days_before: 7
       days_after: 7
       event_types:
         - Eagles_Home
         - Phillies_Home
         - Sixers_Home
         - Flyers_Home
       ```

    5. `config/forecasting.yaml`:
       ```yaml
       # Forecasting and predictive modeling configurations

       # Time series forecasting
       forecast_horizon: 12  # periods
       test_size: 0.2
       model_type: prophet

       # Violence classification
       violent_ucr_codes: [100, 200, 300, 400]
       test_size: 0.25
       random_state: 42
       importance_threshold: 0.01
       ```

    Use existing config files (phase1_config.yaml, phase2_config.yaml, phase3_config.yaml) as reference for parameter values.
  </action>
  <verify>
    - `ls config/*.yaml` shows global.yaml, chief.yaml, patrol.yaml, policy.yaml, forecasting.yaml
    - `python -c "from analysis.config.settings import GlobalConfig; g = GlobalConfig(); print('output_dir:', g.output_dir)"` prints "reports"
  </verify>
  <done>
    All 5 YAML files exist in config/ directory. GlobalConfig loads successfully from global.yaml with correct values.
  </done>
</task>

</tasks>

<verification>
After completing this plan:

1. Verify all schema modules import:
   `python -c "from analysis.config import TrendsConfig, HotspotsConfig, RetailTheftConfig, TimeSeriesConfig"`

2. Verify YAML loading works:
   `python -c "from analysis.config import GlobalConfig, TrendsConfig; g = GlobalConfig(); t = TrendsConfig(); print('OK:', g.output_dir, t.start_year)"`

3. Verify pydantic validation works:
   `python -c "from analysis.config import TrendsConfig; t = TrendsConfig(start_year=300); print(t.start_year)"` should raise ValidationError

4. Verify all 13 config classes exist:
   `python -c "import analysis.config; print([x for x in dir(analysis.config) if 'Config' in x])"` should list 13 classes

Expected outcome: 5 config files, 13 schema classes, all importing and loading correctly with validation.
</verification>

<success_criteria>
1. analysis/config package exists with __init__.py, settings.py, and schemas/ subpackage
2. All 13 analysis config classes can be imported and instantiated
3. YAML files exist in config/ for global, chief, patrol, policy, forecasting
4. Configuration loads from YAML with pydantic validation
5. Invalid values raise pydantic.ValidationError
</success_criteria>

<output>
After completion, create `.planning/phases/06-configuration-cli-system/06-02-SUMMARY.md` with:
- Package structure created (analysis/config/ and schemas/)
- All 13 config classes listed
- YAML files created with key parameters
- Verification test results
- Any deviations from research recommendations
</output>
